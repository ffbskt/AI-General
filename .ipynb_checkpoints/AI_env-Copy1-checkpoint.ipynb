{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 583,
     "status": "ok",
     "timestamp": 1566885518185,
     "user": {
      "displayName": "Денис Волконский",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCa88QtBa4ugmPsmDvN8iDihIvOioJ15g-G0Qpx=s64",
      "userId": "09425448476864996625"
     },
     "user_tz": -180
    },
    "id": "cSytdP8poSs2",
    "outputId": "50030209-d46e-48eb-f5cc-6acbc35f57c9"
   },
   "outputs": [],
   "source": [
    "# for colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "znp4kWzNoS2L"
   },
   "outputs": [],
   "source": [
    "project_dir = '/content/gdrive/My Drive/ColabNotebooks/AI'\n",
    "import sys\n",
    "sys.path.insert(0, project_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step by step mcts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from models import Model, Trainer\n",
    "from env_test import Env\n",
    "from mcts import MCTS\n",
    "\n",
    "class dotdict(dict):\n",
    "    def __getattr__(self, name):\n",
    "        return self[name]\n",
    "\n",
    "model =Model()# LSTMTagger()#Model()\n",
    "env = Env(1,1)\n",
    "\n",
    "args = dotdict({'cpuct':0.5, 'iters':1000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1876\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mcts2 = MCTS(env, model, args)\n",
    "val = list(mcts2.sampling())\n",
    "print(len(val))\n",
    "#val = [v for v in val if v.parent and v.parent.times_visited > 2]\n",
    "#print(len(val))\n",
    "t = Trainer(env, batch_size=5)\n",
    "#t.train_model(val, model, batch_size=10, net_iters=300)\n",
    "#examples = deque([], maxlen=1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = t.get_batch(val, batch_size=5)\n",
    "b = t.transform_bach_as_input(batch, model)\n",
    "print(b[0])#'dataX\\n', b[0].shape)#, '\\n rew, prob, result\\n', b[1:])\n",
    "#    print(b[0])\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "#plt.plot(t.loss_backet)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def env_high_dificult(Env, agent, Trainer):\n",
    "    \n",
    "    epoch = iter_lim = 10\n",
    "    stat = {}\n",
    "    ind_dificult = 1\n",
    "    env = Env(1, ind_dificult)\n",
    "    while epoch:\n",
    "        epoch -= 1\n",
    "        print(stat)\n",
    "        if agent.sum_reward > 10:\n",
    "            stat[ind_dificult] = [iter_lim - epoch, agent.sum_reward]\n",
    "            agent.sum_reward = 0\n",
    "            ind_dificult += 1\n",
    "            epoch = iter_lim\n",
    "            env = Env(1, ind_dificult)\n",
    "            agent.env = env\n",
    "        \n",
    "        val = list(agent.sampling())\n",
    "        val = Trainer.clean_unpredict_node(val)\n",
    "        X, yv, yp = get_linear_out(val)\n",
    "        lossb = train_model(X, yv, yp, agent.model, net_iters=500)\n",
    "        plt.plot(lossb)\n",
    "        plt.show()\n",
    "        \n",
    "    return stat\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "mcts2 = MCTS(env, model, args)\n",
    "env_high_dificult(Env, mcts2, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train = {'1o1':[]}#, '1o2':[], '1o3':[]}\n",
    "test = {'1o1':[]}#, '1o2':[], '1o3':[]}\n",
    "for k in train:\n",
    "    env = Env(1,int(k[2]))\n",
    "    mcts2 = MCTS(env, model, args)\n",
    "    X = list(mcts2.sampling())\n",
    "    val = t.clean_unpredict_node(X)\n",
    "    print(len(X), len(val))\n",
    "    train_cur, test_cur = train_test_split(val)\n",
    "    train[k] = train_cur\n",
    "    test[k] = test_cur\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_linear_out(samples):\n",
    "    X, yv, yp, cresult = t.transform_bach_as_input(samples, model)\n",
    "    return X, yv, yp\n",
    "\n",
    "k = '1o1'\n",
    "X, yv, yp = get_linear_out(train[k])\n",
    "Xt, yvt, ypt = get_linear_out(test[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_rew(tr, pr):\n",
    "    return np.sum((tr - pr)**2) / len(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression().fit(X, yv)\n",
    "loss_rew(yvt, reg.predict(Xt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_rew(yvt, model.predict(Xt)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_rew(yvt, np.mean(yv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regr = RandomForestRegressor(max_depth=5, random_state=0, n_estimators=300)#, criterion='mae')\n",
    "regr.fit(X, yv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_rew(yvt, regr.predict(Xt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "clf = KNeighborsRegressor()\n",
    "clf.fit(X, yv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_rew(yvt, clf.predict(Xt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor, nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.cnv1 = nn.Conv1d(1,6,8)\n",
    "        self.fc1 = nn.Linear(18, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.action_prob_out = nn.Linear(64, 8)\n",
    "        #self.val0 = nn.Linear(40, 80)\n",
    "        self.val = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        #x = x.view(-1,17)\n",
    "        #x = self.cnv1(x.view(1, 1,-1))\n",
    "        # print(x.shape)\n",
    "        #x = torch.flatten(x, start_dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        act_prob = F.softmax(self.action_prob_out(x), dim=-1)\n",
    "        #val = F.tanh(self.val(x))\n",
    "        val = self.val(x)\n",
    "        #val_sum = self.val_sum_out(val)\n",
    "\n",
    "        return act_prob, val\n",
    "\n",
    "    def predict(self, x):\n",
    "        self.eval()\n",
    "        #x = Variable(Tensor(x))\n",
    "        act_prob, val = self.forward(x)\n",
    "        return act_prob.data.numpy(), val.data.numpy()\n",
    "\n",
    "\n",
    "def get_batch(nodes_buc, batch_size=20):\n",
    "    \"\"\"remove all nodes that have not history\"\"\"\n",
    "    n = len(nodes_buc)\n",
    "    index = [\n",
    "        np.random.randint(0, n - 1)\n",
    "        for _ in range(batch_size)\n",
    "    ]\n",
    "    #print(len(self.replay), index, [self.replay[i] for i in index]   )\n",
    "    return index#[nodes_buc[i] for i in index]\n",
    "\n",
    "\n",
    "def train_model(Xa,yr,yp, model, batch_size=10, net_iters=200):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.1)#, momentum=0.03, weight_decay=0.1)\n",
    "    loss_backet = []\n",
    "    for i in range(net_iters):\n",
    "        #batch = #self.get_batch(nodes_buc, batch_size=batch_size or self.batch_size)\n",
    "        # print(batch)\n",
    "        ind = get_batch(Xa)\n",
    "\n",
    "        X, real_reward, real_prob = Xa[ind], yr[ind], yp[ind]#self.transform_bach_as_input(batch, model)\n",
    "\n",
    "\n",
    "        #print(i, real_prob.shape)\n",
    "        model.train()\n",
    "        #for x, rr, rp in zip(X, real_reward, real_prob):\n",
    "            #print(xx, rrr,rpp)\n",
    "        optimizer.zero_grad()\n",
    "        #print(X)\n",
    "        p_pred, v_pred = model(X)\n",
    "        # print('pr  ', probability, 'pp  ', p_pred)\n",
    "        val_loss = torch.mean((Variable(Tensor(real_reward)) - v_pred) ** 2)  # , Variable(Tensor([10]))\n",
    "        loss = val_loss - torch.mean(Variable(Tensor(real_prob)) * torch.log(p_pred))\n",
    "        #loss = - torch.mean(Variable(Tensor(real_prob)) * torch.log(p_pred))\n",
    "        #print(loss, rpp, p_pred)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_backet.append(loss.data.numpy())\n",
    "        \n",
    "    return loss_backet\n",
    "\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossb = train_model(X, yv, yp, model, net_iters=500)\n",
    "plt.plot(lossb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import LSTMmodel\n",
    "#from  import LSTMModel, mctsTrainer\n",
    "model = LSTMmodel.LSTMModel(32, 64, 8, 8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = LSTMmodel.mctsTrainer(env, mcts2, batch_size=20)\n",
    "trainer.train_model(train[k], model, net_iters=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trainer.loss_backet)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lstm, _, _, _ = trainer.transform_bach_as_input(test[k], model)\n",
    "test_lstm = test_lstm.view(-1, len(test_lstm))\n",
    "loss_rew(yvt, model(test_lstm)[1].data.numpy())\n",
    "#get_loss_from(test_lstm, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "#importlib.reload(LSTMmodel)\n",
    "importlib.reload(env_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeding actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "treegramm_count = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "treegramm_count\n",
    "\n",
    "def delta(dict1, dict2):\n",
    "    #print(np.sum(list(dict1.values()), dict1.values())\n",
    "    return np.sum(list(dict1.values())) - np.sum(list(dict2.values()))\n",
    "\n",
    "def betreegrams(val, env, treegramm_count):\n",
    "    results = {}\n",
    "    treegramm_count = defaultdict(lambda: defaultdict(int))\n",
    "    for v in val[:100]:\n",
    "        #print(env.result, v.formula)\n",
    "        env.calc_formula(v.formula)\n",
    "        results[v.formula] = env.result.copy()\n",
    "        if env.result['o'] == env.out: print(v.formula)\n",
    "    #print(results)\n",
    "    for v in val[:100]:\n",
    "        # beegram\n",
    "        for i in range(len(v.formula)-2):\n",
    "            # beegram\n",
    "            #print(i, results[v.formula[:i]], v.formula[:i])\n",
    "            if i > 0 and delta(results[v.formula[:i]], results[v.formula[:i + 1]]) != 0:\n",
    "                \n",
    "                treegramm_count[v.formula[i-1]][v.formula[i]] += 1\n",
    "                treegramm_count[v.formula[i-1:i+1]][v.formula[i+1]] += 1\n",
    "            if i > 0 and delta(results[v.formula[:i]], results[v.formula[:i + 2]]) != 0:\n",
    "                # ?? peace of sheet!! eB1 in 1ABCieB1e we could remove it...\n",
    "                #print('aa', v.formula, v.formula[:i+1], results[v.formula[:i]], results[v.formula[:i+2]],\n",
    "                #      v.formula[i-1], v.formula[i-1:i+2]\n",
    "                #     )\n",
    "                treegramm_count[v.formula[i-1]][v.formula[i]] += 1\n",
    "                treegramm_count[v.formula[i-1:i+1]][v.formula[i+1]] += 1\n",
    "        i = len(v.formula) - 1\n",
    "        if i >= 0 and delta(results[v.formula[:i]], results[v.formula[:i + 1]]) != 0:\n",
    "            treegramm_count[v.formula[i-1]][v.formula[i]] += 1\n",
    "    return treegramm_count, results\n",
    "    \n",
    "            \n",
    "t, r = betreegrams(val, env, treegramm_count)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_grams(val, env, treegramm_count):\n",
    "    results = {}\n",
    "    treegramm_count = defaultdict(lambda: defaultdict(int))\n",
    "    treegramm_list = []\n",
    "    for v in val:\n",
    "        #print(env.result, v.formula)\n",
    "        env.calc_formula(v.formula)\n",
    "        results[v.formula] = env.result.copy()\n",
    "        if env.result['o'] == env.out: print(v.formula)\n",
    "    #print(results)\n",
    "    for v in val:\n",
    "        # beegram\n",
    "        for i in range(len(v.formula)-2):\n",
    "            if i>0 and delta(results[v.formula[:i+1]], results[v.formula[:i+2]]):\n",
    "                #print(v.formula)\n",
    "                #treegramm_count[v.formula[i:i+1]][v.formula[i+1:i+2]] += 1\n",
    "                treegramm_count[v.formula[i-1:i+1]][v.formula[i+1:i+2]] += 1\n",
    "                #treegramm_list.append([list(v.formula[i-1:i+1]), v.formula[i+1:i+2]])\n",
    "                treegramm_list.append([list(v.formula[i-1:i]), v.formula[i:i+1]])\n",
    "                treegramm_list.append([list(v.formula[i:i+1]), v.formula[i+1:i+2]])\n",
    "            # beegram\n",
    "            \n",
    "        #i = len(v.formula) - 1\n",
    "        #if i >= 0 and delta(results[v.formula[:i]], results[v.formula[:i + 1]]) != 0:\n",
    "            #treegramm_count[v.formula[i-1]][v.formula[i]] += 1\n",
    "    return treegramm_count, treegramm_list, results\n",
    "\n",
    "t, tl, r = count_grams(val, env, treegramm_count)   \n",
    "#tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_SIZE = 1\n",
    "EMBEDDING_DIM = 10\n",
    "trigrams = tl#[([test_sentence[i], test_sentence[i + 1]], test_sentence[i + 2])\n",
    "           # for i in range(len(test_sentence) - 2)]\n",
    "# print the first 3, just so you can see what they look like\n",
    "print(trigrams[:3])\n",
    "\n",
    "vocab = set(env.action_space)\n",
    "word_to_ix = {word: i for i, word in enumerate(env.action_space)}\n",
    "\n",
    "\n",
    "class NGramLanguageModeler(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(NGramLanguageModeler, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).view((1, -1))\n",
    "        out = F.relu(self.linear1(embeds))\n",
    "        out = self.linear2(out)\n",
    "        log_probs = F.log_softmax(out, dim=1)\n",
    "        return log_probs\n",
    "\n",
    "\n",
    "losses = []\n",
    "loss_function = nn.NLLLoss()\n",
    "model = NGramLanguageModeler(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    for context, target in trigrams:\n",
    "\n",
    "        # Step 1. Prepare the inputs to be passed to the model (i.e, turn the words\n",
    "        # into integer indices and wrap them in tensors)\n",
    "        context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
    "\n",
    "        # Step 2. Recall that torch *accumulates* gradients. Before passing in a\n",
    "        # new instance, you need to zero out the gradients from the old\n",
    "        # instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 3. Run the forward pass, getting log probabilities over next\n",
    "        # words\n",
    "        log_probs = model(context_idxs)\n",
    "\n",
    "        # Step 4. Compute your loss function. (Again, Torch wants the target\n",
    "        # word wrapped in a tensor)\n",
    "        loss = loss_function(log_probs, torch.tensor([word_to_ix[target]], dtype=torch.long))\n",
    "\n",
    "        # Step 5. Do the backward pass and update the gradient\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Get the Python number from a 1-element Tensor by calling tensor.item()\n",
    "        total_loss += loss.item()\n",
    "    losses.append(total_loss)\n",
    "print(losses)  # The loss decreased every iteration over the training data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = np.vstack([model.embeddings(torch.tensor([i])).data.numpy() for i in range(8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "#dataframe = np.concatenate([samples, test], axis=0)#[train, test, samples], axis=0)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_feature_reduced = pca.fit(dataframe).transform(dataframe)\n",
    "# map word vectors onto 2d plane with PCA. Use good old sklearn api (fit, transform)\n",
    "# after that, normalize vectors to make sure they have zero mean and unit variance\n",
    "#word_vectors_pca = # YOUR CODE\n",
    "\n",
    "# and maybe MORE OF YOUR CODE here :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=X_feature_reduced[:,0], y=X_feature_reduced[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bokeh.models as bm, bokeh.plotting as pl\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()\n",
    "\n",
    "def draw_vectors(x, y, radius=10, alpha=0.25, color='blue',\n",
    "                 width=600, height=400, show=True, **kwargs):\n",
    "    \"\"\" draws an interactive plot for data points with auxilirary info on hover \"\"\"\n",
    "    if isinstance(color, str): color = [color] * len(x)\n",
    "    data_source = bm.ColumnDataSource({ 'x' : x, 'y' : y, 'color': color, **kwargs })\n",
    "\n",
    "    fig = pl.figure(active_scroll='wheel_zoom', width=width, height=height)\n",
    "    fig.scatter('x', 'y', size=radius, color='color', alpha=alpha, source=data_source)\n",
    "\n",
    "    fig.add_tools(bm.HoverTool(tooltips=[(key, \"@\" + key) for key in kwargs.keys()]))\n",
    "    if show: pl.show(fig)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_vectors(X_feature_reduced[:, 0], X_feature_reduced[:, 1], token=list(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class def_zer():\n",
    "    def __init__(self):\n",
    "        return np.zeros([8])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "j= defaultdict(int)\n",
    "prj = np.zeros([8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clval = t.clean_unpredict_node(val)\n",
    "sm.train(clval)\n",
    "for f in clval:\n",
    "    last = -1\n",
    "    if f.formula and f.formula[-1:]=='e' and len(f.history_data['next_node_ind']) > last:\n",
    "        print(f.times_visited, f.formula, f.history_data['next_node_ind'][last])                                       \n",
    "        j[f.history_data['next_node_ind'][last]] += 1\n",
    "        x = model.get_observation(f.formula, env)\n",
    "        prj += model.predict(x)[0].reshape([8])\n",
    "        \n",
    "\n",
    "#[(f.formula, f.history_data['next_node_ind'][0], j[f.history_data['next_node_ind'][0]] += 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[f.formula for f in val]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class StModel:\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        self.stat = np.random.rand(8, 8)\n",
    "        self.vstat = np.random.rand(8)\n",
    "        \n",
    "    def train(self, val):\n",
    "        self.stat = np.zeros([8, 8])\n",
    "        self.predvst = defaultdict(list)\n",
    "        self.vstat = np.zeros([8])\n",
    "        for node in val:\n",
    "            if node.formula:\n",
    "                v = self.env.action_space.index(node.formula[0])\n",
    "                nv = node.history_data['next_node_ind'][-1]\n",
    "                nr = node.history_data['next_node_val'][-1]\n",
    "                self.stat[v][nv] += 1\n",
    "                self.predvst[v].append(nr)\n",
    "        self.stat /= np.sum(self.stat, axis=0) + 0.0001\n",
    "        for i, k in enumerate(self.predvst):\n",
    "            self.vstat[i] = sum(self.predvst[k]) / len(self.predvst[k])\n",
    "         \n",
    "            \n",
    "    def predict(self, formula):\n",
    "        v = self.env.action_space.index(formula[-1])\n",
    "        return self.stat[:, v], self.vstat[v]\n",
    "    \n",
    "    def get_observation(self, formula, env, time=0):\n",
    "        return formula\n",
    "            \n",
    "sm = StModel(env)\n",
    "#sm.train(val)\n",
    "sm.predict('Ai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.train(train[k][0])\n",
    "sm.predict('Ai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss_from(test, model):\n",
    "    ans = np.zeros_like(yvt)\n",
    "    for i, f in enumerate(test):\n",
    "    #print('===', f.formula)    \n",
    "        if f.formula:\n",
    "            ans[i] = model.predict(f.formula)[1]\n",
    "        else:\n",
    "            ans[i] = 1\n",
    "    return loss_rew(yvt, ans)\n",
    "\n",
    "get_loss_from(test[k][0], sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_rew(yvt, ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = mctsTrainer(env, mcts, batch_size=20)\n",
    "\n",
    "def get_sorted_batch(val, batch_size=20):\n",
    "    sort_val = sorted(val, key=lambda x: len(x.formula))\n",
    "    i = np.random.randint(len(val) - batch_size)\n",
    "    yield sort_val[i:i + batch_size]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sbach = list(get_sorted_batch(val))\n",
    "#print(sbach[0])\n",
    "#for i in sbach[0]: \n",
    "#    print(i.formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    batch = list(get_sorted_batch(val))\n",
    "    \n",
    "    torch.cat([model.get_observation(n.formula, env) for n in batch]).view(t.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_SIZE = 1\n",
    "EMBEDDING_DIM = 10\n",
    "trigrams = [([test_sentence[i], test_sentence[i + 1]], test_sentence[i + 2])\n",
    "            for i in range(len(test_sentence) - 2)]\n",
    "# print the first 3, just so you can see what they look like\n",
    "print(trigrams[:3])\n",
    "\n",
    "vocab = set(env.action_space)\n",
    "word_to_ix = {word: i for i, word in enumerate(env.action_space)}\n",
    "\n",
    "\n",
    "class NGramLanguageModeler(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(NGramLanguageModeler, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).view((1, -1))\n",
    "        out = F.relu(self.linear1(embeds))\n",
    "        out = self.linear2(out)\n",
    "        log_probs = F.log_softmax(out, dim=1)\n",
    "        return log_probs\n",
    "\n",
    "\n",
    "losses = []\n",
    "loss_function = nn.NLLLoss()\n",
    "model = NGramLanguageModeler(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    for context, target in trigrams:\n",
    "\n",
    "        # Step 1. Prepare the inputs to be passed to the model (i.e, turn the words\n",
    "        # into integer indices and wrap them in tensors)\n",
    "        context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
    "\n",
    "        # Step 2. Recall that torch *accumulates* gradients. Before passing in a\n",
    "        # new instance, you need to zero out the gradients from the old\n",
    "        # instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 3. Run the forward pass, getting log probabilities over next\n",
    "        # words\n",
    "        log_probs = model(context_idxs)\n",
    "\n",
    "        # Step 4. Compute your loss function. (Again, Torch wants the target\n",
    "        # word wrapped in a tensor)\n",
    "        loss = loss_function(log_probs, torch.tensor([word_to_ix[target]], dtype=torch.long))\n",
    "\n",
    "        # Step 5. Do the backward pass and update the gradient\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Get the Python number from a 1-element Tensor by calling tensor.item()\n",
    "        total_loss += loss.item()\n",
    "    losses.append(total_loss)\n",
    "print(losses)  # The loss decreased every iteration over the training data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_data(val):\n",
    "    print(val.formula, val.fin_prob, val.ucb_score())\n",
    "\n",
    "shuffle(val)\n",
    "for i in range(30):\n",
    "    val_data(val[i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcts.Nodes['i1iBo'].times_visited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.transform_bach_as_input(t.get_batch(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = {'1': 1, 'i': 0, 'o': 0, 'A': 0, 'B': 0, 'C': 0}\n",
    "keys=list(values) + ['s', 'e']\n",
    "\n",
    "dd = {'formula':[], 'val_sum':[]}\n",
    "for i in replay_buffer.replay:\n",
    "    dd['formula'].append(i[2])\n",
    "    dd['val_sum'].append(i[3].value_sum)\n",
    "    \n",
    "    for j, k in enumerate(keys):\n",
    "        #print('j', j, i[4])\n",
    "        #print(i, i[4][j])\n",
    "        dd[k] = i[4][j]\n",
    "\n",
    "df = pd.DataFrame(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['formula']=='']#['ucb'].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['formula']=='ie']#['ucb'].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer.get_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "F.softmax(Tensor([0,0,0])).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FHT8MKGkKgMZ"
   },
   "outputs": [],
   "source": [
    "test_env.reset()\n",
    "Vocab, Vocab[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vF4aIxxZKgMd"
   },
   "outputs": [],
   "source": [
    "j.select_best_leaf().action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FOQXFnS1KgMi"
   },
   "outputs": [],
   "source": [
    "j.select_best_leaf().rollout(env, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JIrncnZsKgMm"
   },
   "outputs": [],
   "source": [
    "test_env.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e-cTCUZ1KgMs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NidVAYKCKgMw"
   },
   "outputs": [],
   "source": [
    "test_env.step(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JMg5FKlQKgM4"
   },
   "outputs": [],
   "source": [
    "test_env.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bkCYSESeKgM_"
   },
   "outputs": [],
   "source": [
    "test_env.step(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aI3S4cplKgNJ"
   },
   "outputs": [],
   "source": [
    "test_env.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X0cm_RpRKgNN"
   },
   "outputs": [],
   "source": [
    "test_env.step(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TeL1SNw8KgNQ"
   },
   "source": [
    "# Imetation learning \n",
    "### if we already know answer we should show it to mcts tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M3OmftFqKgNS",
    "outputId": "ce5b2f36-6702-4124-b61e-3ac00cdc1b79"
   },
   "outputs": [],
   "source": [
    "#text = \"input_eq_A A[2]_eq_out\"\n",
    "def text_to_actions(text, vocab=Vocab):\n",
    "    action_seq = []\n",
    "    i = 0\n",
    "    operator = ''\n",
    "    while i < len(text):\n",
    "        if text[i] in Vocab:\n",
    "            action_seq.append(Vocab.index(text[i]))\n",
    "        else:\n",
    "            operator += text[i]\n",
    "            #print('ss', text[i], operator)\n",
    "            if operator == 'input':\n",
    "                operator = ''\n",
    "                \n",
    "            if operator in Vocab:\n",
    "                action_seq.append(Vocab.index(operator))\n",
    "                operator = ''\n",
    "\n",
    "\n",
    "        i += 1\n",
    "    return action_seq\n",
    "\n",
    "for i in text_to_actions(text):\n",
    "    print(Vocab[i])\n",
    "text_to_actions(text)\n",
    "        #print(Vocab.index(i))\n",
    "        #print(env.step(1))\n",
    "        #print(env.step(Vocab.index(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dVYXJY8CKgNX"
   },
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SyISzsg9KgNa"
   },
   "outputs": [],
   "source": [
    "#text = \"input_sum_A\" \n",
    "for i in text_to_actions(text):\n",
    "    print(i)\n",
    "    print(Vocab[i])\n",
    "    print(env.step(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fq8wx-GIKgNe",
    "outputId": "c2bc22a2-11d0-47fb-ae78-de64f7916297"
   },
   "outputs": [],
   "source": [
    "text = \"input_eq_A A[2]_const_AA AA_eq_out\" \n",
    "c = CalcNode(text)\n",
    "c.calc(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8HvILK6NKgNi",
    "outputId": "b06ec81a-9728-4fb8-e463-764bb2c402d8"
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "#import mcts\n",
    "importlib.reload(mcts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uGE-MtmQKgNm"
   },
   "outputs": [],
   "source": [
    "root_observation = env.reset()\n",
    "root_snapshot = env.get_snapshot()\n",
    "root = mcts.Root(root_snapshot,root_observation)\n",
    "\n",
    "#plan_mcts(root, env, n_iters=10000, t_max=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dcktRK9PKgNr",
    "outputId": "8a97b6ff-9d2b-4f4c-f71f-07ca8ba61cb3"
   },
   "outputs": [],
   "source": [
    "root.is_leaf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dobGrIBhKgNw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z4tbTs7QKgN1"
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    is_done = env.step(env.action_space.sample())[2]\n",
    "    if is_done: \n",
    "        print(\"Whoops! We died!\")\n",
    "        break\n",
    "        \n",
    "print(\"final state:\")\n",
    "plt.imshow(env.render('rgb_array'))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YCfndGRvKgN7"
   },
   "outputs": [],
   "source": [
    "def teach_mcts(root, env, action_seq):\n",
    "    \"\"\"\n",
    "    builds tree with monte-carlo tree search for n_iters iterations\n",
    "    :param root: tree node to plan from\n",
    "    :param n_iters: how many select-expand-simulate-propagete loops to make\n",
    "    \"\"\"\n",
    "    #node = root\n",
    "    #node = mcts.Node(root, action_seq[0], env)\n",
    "    #root.children.add(node)\n",
    "    for action in action_seq:\n",
    "        #print(action)\n",
    "        #print(node.is_done)\n",
    "        \n",
    "        #next_node = mcts.Node(next_node, action, env)\n",
    "        #node.children.add(mcts.Node(node, action, env))\n",
    "        #node = next_node\n",
    "        \n",
    "        #print(node.is_done)\n",
    "        node = root.select_best_leaf()\n",
    "        \n",
    "        #print(Vocab[node.action])\n",
    "        \n",
    "        if node.is_done:\n",
    "            if node.immediate_reward > 0:\n",
    "                print(\"get_reward mcts plan!\", node.immediate_reward)  \n",
    "            \n",
    "            node.propagate(0)\n",
    "            #env.reset()\n",
    "       \n",
    "        else: #node is not terminal\n",
    "            \n",
    "            #print(_)\n",
    "            #env.reset()\n",
    "            #self.env.close()\n",
    "            #self.render()\n",
    "            node.expand(env)\n",
    "            #print(Vocab[node.action])\n",
    "            for i in node.children:\n",
    "                print('dd', )#Vocab[node.action], node.parent.action)\n",
    "            ## value = node.rollout(env, 10)\n",
    "            #if value >0:\n",
    "            #    print('plan after rolout', value, node.action)\n",
    "            ##node.propagate(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9wpJsyD4KgN_",
    "outputId": "b072c7e6-6701-47ce-e7d5-88fb46a0de64"
   },
   "outputs": [],
   "source": [
    "teach_mcts(root, env, text_to_actions(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rDYbBZD1KgOD"
   },
   "outputs": [],
   "source": [
    "p = mcts.Node(root, 2, env)\n",
    "#p.is_leaf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6LmjGfWZKgOI"
   },
   "outputs": [],
   "source": [
    "mcts.plan_mcts(root,env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nHYw3ZLhKgOa",
    "outputId": "f7f5c650-8cdc-4f57-ceff-5b7b0f12f0eb"
   },
   "outputs": [],
   "source": [
    "for i in root.children:\n",
    "    print(Vocab[i.action], i.value_sum, len(i.children))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y4urPh38KgOi",
    "outputId": "4ecbf4f9-e351-4d1e-9710-bbc1c3e504fc"
   },
   "outputs": [],
   "source": [
    "j = root\n",
    "while j.children:\n",
    "    j = j.children.pop()\n",
    "    print(j.action, len(j.children))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cPmBVHd9KgOm"
   },
   "source": [
    "# Try learn something again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<mcts.Node object at 0x7fa489cb7828>, <mcts.Node object at 0x7fa48973dc18>, <mcts.Node object at 0x7fa48a127a20>, <mcts.Node object at 0x7fa48a264828>, <mcts.Node object at 0x7fa4897ae668>]\n"
     ]
    }
   ],
   "source": [
    "batch = t.get_batch(val, batch_size=5)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch[0].history_data, batch[0].formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_nodes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ff158e64bb5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mplt_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-ff158e64bb5e>\u001b[0m in \u001b[0;36mplt_history\u001b[0;34m(node_formula)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplt_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_formula\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mNODE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_nodes\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformula\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnode_formula\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_nodes' is not defined"
     ]
    }
   ],
   "source": [
    "values = {'1': 1, 'i': 0, 'o': 0, 'A': 0, 'B': 0, 'C': 0}\n",
    "actions = list(values) + ['s', 'e']\n",
    "\n",
    "def plt_history(node_formula=''):\n",
    "    NODE = [i for i in all_nodes if i.formula == node_formula][0]\n",
    "    for k in range(8):\n",
    "        dt = []\n",
    "        for i, t in enumerate(NODE.history_data['time']):\n",
    "\n",
    "            if NODE.history_data['next_node_ind'][i] == k:\n",
    "                dt.append(NODE.history_data['next_node_val'][i])\n",
    "        print(len(dt), end=',')\n",
    "        plt.plot(range(len(dt)), dt, label=actions[k])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "plt_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_nodes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-bc8e7df480af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mplt_historyP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-bc8e7df480af>\u001b[0m in \u001b[0;36mplt_historyP\u001b[0;34m(node_formula)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplt_historyP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_formula\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mNODE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_nodes\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformula\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnode_formula\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_nodes' is not defined"
     ]
    }
   ],
   "source": [
    "fprob = np.zeros(8)\n",
    "def plt_historyP(node_formula=''):\n",
    "    NODE = [i for i in all_nodes if i.formula == node_formula][0]\n",
    "    for k in range(8):\n",
    "        dt = [0]\n",
    "        tt = [0]\n",
    "        for i, t in enumerate(NODE.history_data['time']):\n",
    "\n",
    "            if NODE.history_data['next_node_ind'][i] == k:\n",
    "                dt.append(dt[-1]+1)\n",
    "                tt.append(t)\n",
    "        print(len(dt), end=',')\n",
    "        fprob[k] = dt[-1]\n",
    "        plt.plot(tt, dt, label=actions[k])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "plt_historyP('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_nodes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d8897b088317>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformula\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfin_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_nodes' is not defined"
     ]
    }
   ],
   "source": [
    "for i in all_nodes[:10]:\n",
    "    print(i.formula, i.fin_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denis/anaconda3/envs/tourch_gym/lib/python3.7/site-packages/ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([nan, nan, nan, nan, nan, nan, nan, nan]), nan)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fprob /= np.sum(fprob)\n",
    "fprob, np.sum(fprob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_nodes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-6feacf5c2d83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt_historyP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-bc8e7df480af>\u001b[0m in \u001b[0;36mplt_historyP\u001b[0;34m(node_formula)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplt_historyP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_formula\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mNODE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_nodes\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformula\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnode_formula\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_nodes' is not defined"
     ]
    }
   ],
   "source": [
    "plt_historyP('i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_nodes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-b58a007fa6e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt_historyP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ie'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-bc8e7df480af>\u001b[0m in \u001b[0;36mplt_historyP\u001b[0;34m(node_formula)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplt_historyP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_formula\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mNODE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_nodes\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformula\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnode_formula\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_nodes' is not defined"
     ]
    }
   ],
   "source": [
    "plt_historyP('ie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play adverserial game\n",
    "try to solve problem with big value for loosing formulas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    " def sampling(self):\n",
    "        i, r = 0, 0\n",
    "        while (self.args.iters > i and not r) or 2 * self.args.iters > i:\n",
    "            node = self.select_best_leaf()\n",
    "            #if node.parent is not None: print(node.formula, node.immediate_reward)\n",
    "            r = node.immediate_reward\n",
    "            #if r: print('R', node.formula)\n",
    "            self.Nodes[node.formula] = node\n",
    "            if r:\n",
    "                self.propagate(node)\n",
    "            else:\n",
    "\n",
    "                pred_P, pred_R = self.model.predict(self.model.get_observation(node.formula, self.env, self.iter_timer)) # if simple model self.env.observation\n",
    "                self.expand(node, pred_P)\n",
    "\n",
    "            r = max(0, r)\n",
    "            i += 1\n",
    "\n",
    "        self.compute_p_real()\n",
    "        return  self.Nodes.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 =Model()# LSTMTagger()#Model()\n",
    "model2 =Model()\n",
    "env1 = Env(1,1)\n",
    "env2 = Env(1,1)\n",
    "\n",
    "args = dotdict({'cpuct':0.5, 'iters':1000})\n",
    "mcts1 = MCTS(env1, model, args)\n",
    "mcts2 = MCTS(env2, model, args)\n",
    "\n",
    "\n",
    "def play_game(mcts1, mcts2):\n",
    "    game_end = 0\n",
    "    score = [0, 0]\n",
    "    while not game_end:\n",
    "        node1 = mcts1.select_best_leaf()\n",
    "        r1 = node1.immediate_reward\n",
    "\n",
    "        node2 = mcts2.select_best_leaf()\n",
    "        r2 = node2.immediate_reward\n",
    "        #print(len(mcts1.Nodes) == len(mcts2.Nodes))\n",
    "        \n",
    "\n",
    "        \n",
    "        if r1 < 0 or r2 < 0:\n",
    "            mcts1.propagate(node1)\n",
    "            mcts2.propagate(node2)\n",
    "        elif r1 > 0 and r2 > 0:\n",
    "            mcts1.propagate(node1)\n",
    "            mcts2.propagate(node2)\n",
    "        elif r1 > 0:\n",
    "            node2.immediate_reward = -1\n",
    "            mcts1.propagate(node1)\n",
    "            mcts2.propagate(node2)\n",
    "        elif r2 > 0:\n",
    "            node1.immediate_reward = -1\n",
    "            mcts1.propagate(node1)\n",
    "            mcts2.propagate(node2)\n",
    "        \n",
    "        #if r1>0 or r2>0:\n",
    "        #    print(node1.formula, game_end)\n",
    "        #    print(node2.formula, game_end)\n",
    "\n",
    "        mcts1.Nodes[node1.formula] = node1\n",
    "        mcts2.Nodes[node2.formula] = node2\n",
    "\n",
    "        pred_P, pred_R = mcts1.model.predict(mcts1.model.get_observation(node1.formula, mcts1.env, mcts1.iter_timer)) # if simple model self.env.observation\n",
    "        mcts1.expand(node1, pred_P)\n",
    "\n",
    "        pred_P, pred_R = mcts2.model.predict(mcts2.model.get_observation(node2.formula, mcts2.env, mcts2.iter_timer)) # if simple model self.env.observation\n",
    "        mcts2.expand(node2, pred_P)\n",
    "    \n",
    "    return score, r1, r2\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "#val = list(mcts2.sampling())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-9a789fd38c9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplay_game\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmcts1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmcts2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m's'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-374790db0b6e>\u001b[0m in \u001b[0;36mplay_game\u001b[0;34m(mcts1, mcts2)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mpred_P\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_R\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmcts1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmcts1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_observation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformula\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmcts1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmcts1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_timer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# if simple model self.env.observation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mmcts1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_P\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mpred_P\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_R\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmcts2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmcts2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_observation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformula\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmcts2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmcts2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_timer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# if simple model self.env.observation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program/AI0/AI-General/mcts.py\u001b[0m in \u001b[0;36mexpand\u001b[0;34m(self, node, action_priors)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_priors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_priors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mnext_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimmediate_reward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program/AI0/AI-General/mcts.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, parent, action, prob, env)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimmediate_reward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformula\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformula\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0;31m#if self.immediate_reward > 0: print(\"!!-----------------------------\", self.formula)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program/AI0/AI-General/env_test.py\u001b[0m in \u001b[0;36mdo_move\u001b[0;34m(self, formula, action)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mformula\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m#self.calc_formula(formula)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformula\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformula\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# print('env', self.formula, self.err, calc_formula(self.formula, self.inp)[1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program/AI0/AI-General/env_test.py\u001b[0m in \u001b[0;36mgame_end\u001b[0;34m(self, formula)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgame_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformula\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;31m# return err, rew\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_formula\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformula\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program/AI0/AI-General/env_test.py\u001b[0m in \u001b[0;36mcalc_formula\u001b[0;34m(self, formula)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcalc_formula\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformula\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomand\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformula\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program/AI0/AI-General/env_test.py\u001b[0m in \u001b[0;36minit_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_nodes = []\n",
    "v = [0,0]\n",
    "for i in range(1):\n",
    "    mcts1 = MCTS(env1, model1, args)\n",
    "    mcts2 = MCTS(env2, model2, args)\n",
    "    score = [0, 0]\n",
    "    for j in range(20):\n",
    "        print(j, end=' ')\n",
    "\n",
    "        res = play_game(mcts1, mcts2)[0]\n",
    "        #print('s')\n",
    "        score[0] += res[0]\n",
    "        score[1] += res[1]\n",
    "    #if score[0] > score[1]:\n",
    "    all_nodes += list(mcts1.Nodes.values())\n",
    "    #else:\n",
    "    all_nodes += list(mcts2.Nodes.values())\n",
    "    v[0] += (score[0]-score[1])\n",
    "    v[1] += score[0]\n",
    "\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val1 = list(all_nodes.values())\n",
    "#val2 = list(mcts2.Nodes.values())\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_nodes))\n",
    "for i in all_nodes:\n",
    "    if i.parent:\n",
    "        if np.max(i.parent.history_data['next_node_val']) > 0:\n",
    "            print(i.parent.history_data['next_node_val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1 learn values&probs by NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in all_nodes:\n",
    "    act_count = np.zeros(8)\n",
    "    i.fin_prob = act_count + 1/8\n",
    "    #print(i.formula, len(i.history_data['next_node_ind']))\n",
    "    for act in i.history_data['next_node_ind']:\n",
    "        act_count[act] += 1\n",
    "    if len(i.history_data['next_node_ind']):\n",
    "        i.fin_prob = act_count / len(i.history_data['next_node_ind'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "val = t.clean_unpredict_node(all_nodes) # from deep down\n",
    "print(len(all_nodes), len(val))\n",
    "train_cur, test_cur = val, val#train_test_split(val, shuffle=True)\n",
    "#train[k] = train_cur\n",
    "#test[k] = test_cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batching most recent nodes\n",
    "def get_node_probs(all_nodes):\n",
    "    n_node_entrances = 0\n",
    "    prob_of_node = np.zeros(len(all_nodes))\n",
    "    for i in all_nodes:\n",
    "        n_node_entrances += len(i.history_data['next_node_ind'])\n",
    "    for i, node in enumerate(all_nodes):\n",
    "        prob_of_node[i] = len(node.history_data['next_node_ind']) / n_node_entrances\n",
    "        if node.formula == 'B1ieCe1BC1i':\n",
    "            print(node.formula, node.fin_prob, len(node.history_data['next_node_ind']), prob_of_node[i])\n",
    "    return prob_of_node\n",
    "prob_of_node = get_node_probs(val)\n",
    "\n",
    "def get_batch(nodes_buc, batch_size=20):\n",
    "    indexes = range(len(nodes_buc))\n",
    "    return np.random.choice(indexes, batch_size, replace=True, p=prob_of_node)\n",
    "#for i in np.random.choice(all_nodes, 20, replace=True, p=prob_of_node):\n",
    "#    print(i.formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_linear_out(samples):\n",
    "    X, yv, yp, cresult = t.transform_bach_as_input(samples, model)\n",
    "    return X, yv, yp\n",
    "\n",
    "k = '1o1'\n",
    "X, yv, yp = get_linear_out(train_cur)\n",
    "Xt, yvt, ypt = get_linear_out(test_cur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, yv.shape, yp.shape, np.max(yv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_rew(tr, pr):\n",
    "    return np.sum((tr - pr)**2) / len(tr)\n",
    "\n",
    "plt.plot(yp[:200,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression().fit(X, yv)\n",
    "loss_rew(yvt, reg.predict(Xt)), loss_rew(yv, reg.predict(X)), loss_rew(yvt, np.mean(yv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric on Prob!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nmodel = Model()\n",
    "lossb = train_model(X, yv, yp, nmodel, net_iters=500)\n",
    "plt.plot(lossb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_rew(yvt, nmodel.predict(Xt)[1]), loss_rew(yv, nmodel.predict(X)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_rew(yvt, model1.predict(Xt)[1]), loss_rew(yv, model1.predict(X)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_score = 0\n",
    "points = 0\n",
    "dopp = 0\n",
    "games = 30\n",
    "for i in range(games):\n",
    "    mcts1 = MCTS(env1, nmodel, args)\n",
    "    mcts2 = MCTS(env2, model1, args)\n",
    "    score = [0, 0]\n",
    "    for j in range(100):\n",
    "        \n",
    "\n",
    "        res, r1, r2 = play_game(mcts1, mcts2)\n",
    "        score[0] += res[0]\n",
    "        score[1] += res[1]\n",
    "        dopp += r1 - r2\n",
    "    #all_nodes ={**mcts1.Nodes, **mcts2.Nodes}\n",
    "    #print(score)\n",
    "    points += score[0] - score[1]\n",
    "    fin_score += score[0] > score[1]\n",
    "    games -= score[0] == score[1]\n",
    "    \n",
    "print('old vs new', fin_score, games - fin_score, 'points=', points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model1 = nmodel\n",
    "#model2 = nmodel\n",
    "nmodel = Model()\n",
    "#dopp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor, nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Modelx(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.cnv1 = nn.Conv1d(1,6,8)\n",
    "        self.fc1 = nn.Linear(18, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.action_prob_out = nn.Linear(64, 8)\n",
    "        #self.val0 = nn.Linear(40, 80)\n",
    "        self.val = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        #x = x.view(-1,17)\n",
    "        #x = self.cnv1(x.view(1, 1,-1))\n",
    "        # print(x.shape)\n",
    "        #x = torch.flatten(x, start_dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        act_prob = F.softmax(self.action_prob_out(x), dim=-1)\n",
    "        #val = F.tanh(self.val(x))\n",
    "        val = self.val(x)\n",
    "        #val_sum = self.val_sum_out(val)\n",
    "\n",
    "        return act_prob, val\n",
    "\n",
    "    def predict(self, x):\n",
    "        self.eval()\n",
    "        #x = Variable(Tensor(x))\n",
    "        act_prob, val = self.forward(x)\n",
    "        return act_prob.data.numpy(), val.data.numpy()\n",
    "\n",
    "\n",
    "def get_batchX(nodes_buc, batch_size=20):\n",
    "    \"\"\"remove all nodes that have not history\"\"\"\n",
    "    n = len(nodes_buc)\n",
    "    index = [\n",
    "        np.random.randint(0, n - 1)\n",
    "        for _ in range(batch_size)\n",
    "    ]\n",
    "    #print(len(self.replay), index, [self.replay[i] for i in index]   )\n",
    "    return index#[nodes_buc[i] for i in index]\n",
    "\n",
    "\n",
    "def train_model(Xa,yr,yp, model, batch_size=30, net_iters=200):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.1)#, momentum=0.03, weight_decay=0.1)\n",
    "    loss_backet = []\n",
    "    #validate_back = []\n",
    "    for i in range(net_iters):\n",
    "        #batch = #self.get_batch(nodes_buc, batch_size=batch_size or self.batch_size)\n",
    "        # print(batch)\n",
    "        ind = get_batch(Xa)\n",
    "\n",
    "        X, real_reward, real_prob = Xa[ind], yr[ind], yp[ind]#self.transform_bach_as_input(batch, model)\n",
    "\n",
    "\n",
    "        #print(i, real_prob.shape)\n",
    "        model.train()\n",
    "        #for x, rr, rp in zip(X, real_reward, real_prob):\n",
    "            #print(xx, rrr,rpp)\n",
    "        optimizer.zero_grad()\n",
    "        #print(X)\n",
    "        p_pred, v_pred = model(X)\n",
    "        # print('pr  ', probability, 'pp  ', p_pred)\n",
    "        val_loss = torch.mean((Variable(Tensor(real_reward)) - v_pred) ** 2)  # , Variable(Tensor([10]))\n",
    "        #loss = val_loss - torch.mean(Variable(Tensor(real_prob)) * torch.log(p_pred))\n",
    "        loss = - torch.mean(Variable(Tensor(real_prob)) * torch.log(p_pred))\n",
    "        #print(loss, rpp, p_pred)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_backet.append(loss.data.numpy())\n",
    "        \n",
    "    return loss_backet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, node in enumerate(val):\n",
    "    if node.formula == 'i':\n",
    "        print(node.formula, node.fin_prob, len(node.history_data['next_node_ind']), prob_of_node[i])#, i.ucb_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, node in enumerate(val):\n",
    "    if node.formula == 'i':\n",
    "        print(node.formula, node.fin_prob, len(node.history_data['next_node_ind']), prob_of_node[i])#, i.ucb_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = nmodel.get_observation('ie', env1, 500)\n",
    "nmodel.predict(X0), model1.predict(X0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in get_batch(val):\n",
    "    print(val[ind].formula, val[ind].fin_prob, val[ind].immediate_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nodes = list(mcts1.sampling())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in Nodes:\n",
    "    if node.immediate_reward > 0:\n",
    "        print(node.formula, node.immediate_reward)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN from deeplearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, yv, yp, np.max(yv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AGAIN STAT MODEL AND DEEPLEARNING BOOK bless me!\n",
    "\n",
    "Run first 3 cells from \"Step by step mcts\"\n",
    "Run all sampling 3 cells from \"Play adverserial game\" Run4 cells from \"Step1 learn values&probs by NN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class stat_model():\n",
    "    def __init__(self, X_tr, y_vtr, y_ptr):\n",
    "        self.all_X = defaultdict(int)\n",
    "        self.ypX = defaultdict(lambda: defaultdict(int))\n",
    "        self.yvX = defaultdict(lambda: defaultdict(int))\n",
    "        for x, yv, yp in zip(X_tr, y_vtr, y_ptr):\n",
    "            #yv, yp = map(str, [yv, yp])\n",
    "            #print(yv, yp)\n",
    "            x = tuple(x.data.numpy())\n",
    "            self.all_X[x] += 1\n",
    "            self.ypX[x][tuple(yp)] += 1\n",
    "            self.yvX[x][yv[0]] += 1\n",
    "        \n",
    "    def predict(self, x):\n",
    "        x = str(list(x.data.numpy()))\n",
    "        yv_pred = self.yvX[x][1]/self.all_X[x] # prob of 1\n",
    "        \n",
    "        return yv_pred\n",
    "        \n",
    "        \n",
    "SM = stat_model(X, yv, yp)\n",
    "SM.all_X[X[0]], X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SM.predict(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SM.all_X[X[0]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuple(X[0].data.numpy())#.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SM.all_X[str(list(X[0].data.numpy()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = 0\n",
    "for x, y, yp in zip(X, yv, yp):\n",
    "    err += (y + 1) / 2 * np.log(SM.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "AI_env.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
