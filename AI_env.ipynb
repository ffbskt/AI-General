{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 583,
     "status": "ok",
     "timestamp": 1566885518185,
     "user": {
      "displayName": "Денис Волконский",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCa88QtBa4ugmPsmDvN8iDihIvOioJ15g-G0Qpx=s64",
      "userId": "09425448476864996625"
     },
     "user_tz": -180
    },
    "id": "cSytdP8poSs2",
    "outputId": "50030209-d46e-48eb-f5cc-6acbc35f57c9"
   },
   "outputs": [],
   "source": [
    "# for colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "znp4kWzNoS2L"
   },
   "outputs": [],
   "source": [
    "project_dir = '/content/gdrive/My Drive/ColabNotebooks/AI'\n",
    "import sys\n",
    "sys.path.insert(0, project_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step by step mcts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from models import Model, Trainer\n",
    "from env_test import Env\n",
    "from mcts import MCTS\n",
    "\n",
    "class dotdict(dict):\n",
    "    def __getattr__(self, name):\n",
    "        return self[name]\n",
    "\n",
    "model =Model()# LSTMTagger()#Model()\n",
    "env = Env(1,1)\n",
    "\n",
    "args = dotdict({'cpuct':0.5, 'iters':1000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i1ii i1iiB 0\n",
      "i1iiB i1iiB1 0\n",
      "1924\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "low >= high",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3bf197f7a774>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_bach_as_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program/AI0/AI-General/models.py\u001b[0m in \u001b[0;36mtransform_bach_as_input\u001b[0;34m(self, batch, model)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;31m#if not len(node.history_data['time']):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0;31m#if node.parent:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;31m#self.env.calc_formula(node.parent.formula)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.randint\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: low >= high"
     ]
    }
   ],
   "source": [
    "\n",
    "mcts2 = MCTS(env, model, args)\n",
    "val = list(mcts2.sampling())\n",
    "print(len(val))\n",
    "#val = [v for v in val if v.parent and v.parent.times_visited > 2]\n",
    "#print(len(val))\n",
    "t = Trainer(env, batch_size=50)\n",
    "#t.train_model(val, model, batch_size=10, net_iters=300)\n",
    "#examples = deque([], maxlen=1000)\n",
    "\n",
    "batch = t.get_batch(val, batch_size=5)\n",
    "for b in t.transform_bach_as_input(batch, model):\n",
    "    print(b)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#plt.plot(t.loss_backet)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "ieiB ieiB1 0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_linear_out' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-81d7636a9242>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mmcts2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMCTS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0menv_high_dificult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEnv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmcts2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-81d7636a9242>\u001b[0m in \u001b[0;36menv_high_dificult\u001b[0;34m(Env, agent, Trainer)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_unpredict_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linear_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mlossb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlossb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_linear_out' is not defined"
     ]
    }
   ],
   "source": [
    "def env_high_dificult(Env, agent, Trainer):\n",
    "    \n",
    "    epoch = iter_lim = 10\n",
    "    stat = {}\n",
    "    ind_dificult = 1\n",
    "    env = Env(1, ind_dificult)\n",
    "    while epoch:\n",
    "        epoch -= 1\n",
    "        print(stat)\n",
    "        if agent.sum_reward > 10:\n",
    "            stat[ind_dificult] = [iter_lim - epoch, agent.sum_reward]\n",
    "            agent.sum_reward = 0\n",
    "            ind_dificult += 1\n",
    "            epoch = iter_lim\n",
    "            env = Env(1, ind_dificult)\n",
    "            agent.env = env\n",
    "        \n",
    "        val = list(agent.sampling())\n",
    "        val = Trainer.clean_unpredict_node(val)\n",
    "        X, yv, yp = get_linear_out(val)\n",
    "        lossb = train_model(X, yv, yp, agent.model, net_iters=500)\n",
    "        plt.plot(lossb)\n",
    "        plt.show()\n",
    "        \n",
    "    return stat\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "mcts2 = MCTS(env, model, args)\n",
    "env_high_dificult(Env, mcts2, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denis/anaconda3/envs/tourch_gym/lib/python3.7/site-packages/torch/nn/functional.py:1320: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACe ACeB 0\n",
      "1930 1572\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train = {'1o1':[]}#, '1o2':[], '1o3':[]}\n",
    "test = {'1o1':[]}#, '1o2':[], '1o3':[]}\n",
    "for k in train:\n",
    "    env = Env(1,int(k[2]))\n",
    "    mcts2 = MCTS(env, model, args)\n",
    "    X = list(mcts2.sampling())\n",
    "    val = t.clean_unpredict_node(X)\n",
    "    print(len(X), len(val))\n",
    "    train_cur, test_cur = train_test_split(val)\n",
    "    train[k] = train_cur\n",
    "    test[k] = test_cur\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_linear_out(samples):\n",
    "    X, yv, yp, cresult = t.transform_bach_as_input(samples, model)\n",
    "    return X, yv, yp\n",
    "\n",
    "k = '1o1'\n",
    "X, yv, yp = get_linear_out(train[k])\n",
    "Xt, yvt, ypt = get_linear_out(test[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1179"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_rew(tr, pr):\n",
    "    return np.sum((tr - pr)**2) / len(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6894408804338947"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression().fit(X, yv)\n",
    "loss_rew(yvt, reg.predict(Xt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7279698141836474"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_rew(yvt, model.predict(Xt)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7543373810413975"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_rew(yvt, np.mean(yv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regr = RandomForestRegressor(max_depth=4, random_state=0, n_estimators=300)#, criterion='mae')\n",
    "regr.fit(X, yv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_rew(yvt, regr.predict(Xt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "clf = KNeighborsRegressor()\n",
    "clf.fit(X, yv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_rew(yvt, clf.predict(Xt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor, nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.cnv1 = nn.Conv1d(1,6,8)\n",
    "        self.fc1 = nn.Linear(18, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.action_prob_out = nn.Linear(64, 8)\n",
    "        #self.val0 = nn.Linear(40, 80)\n",
    "        self.val = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        #x = x.view(-1,17)\n",
    "        #x = self.cnv1(x.view(1, 1,-1))\n",
    "        # print(x.shape)\n",
    "        #x = torch.flatten(x, start_dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #x = F.relu(self.fc2(x))\n",
    "        act_prob = F.softmax(self.action_prob_out(x), dim=-1)\n",
    "        val = F.tanh(self.val(x))\n",
    "        #val_sum = self.val_sum_out(val)\n",
    "\n",
    "        return act_prob, val\n",
    "\n",
    "    def predict(self, x):\n",
    "        self.eval()\n",
    "        #x = Variable(Tensor(x))\n",
    "        act_prob, val = self.forward(x)\n",
    "        return act_prob.data.numpy(), val.data.numpy()\n",
    "\n",
    "\n",
    "def get_batch(nodes_buc, batch_size=20):\n",
    "    \"\"\"remove all nodes that have not history\"\"\"\n",
    "    n = len(nodes_buc)\n",
    "    index = [\n",
    "        np.random.randint(0, n - 1)\n",
    "        for _ in range(batch_size)\n",
    "    ]\n",
    "    #print(len(self.replay), index, [self.replay[i] for i in index]   )\n",
    "    return index#[nodes_buc[i] for i in index]\n",
    "\n",
    "\n",
    "def train_model(Xa,yr,yp, model, batch_size=10, net_iters=200):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.1)#, momentum=0.03, weight_decay=0.1)\n",
    "    loss_backet = []\n",
    "    for i in range(net_iters):\n",
    "        #batch = #self.get_batch(nodes_buc, batch_size=batch_size or self.batch_size)\n",
    "        # print(batch)\n",
    "        ind = get_batch(Xa)\n",
    "\n",
    "        X, real_reward, real_prob = Xa[ind], yr[ind], yp[ind]#self.transform_bach_as_input(batch, model)\n",
    "\n",
    "\n",
    "        #print(i, real_prob.shape)\n",
    "        model.train()\n",
    "        #for x, rr, rp in zip(X, real_reward, real_prob):\n",
    "            #print(xx, rrr,rpp)\n",
    "        optimizer.zero_grad()\n",
    "        #print(X)\n",
    "        p_pred, v_pred = model(X)\n",
    "        # print('pr  ', probability, 'pp  ', p_pred)\n",
    "        val_loss = torch.mean((Variable(Tensor(real_reward)) - v_pred) ** 2)  # , Variable(Tensor([10]))\n",
    "        loss = val_loss - torch.mean(Variable(Tensor(real_prob)) * torch.log(p_pred))\n",
    "        #loss = - torch.mean(Variable(Tensor(real_prob)) * torch.log(p_pred))\n",
    "        #print(loss, rpp, p_pred)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_backet.append(loss.data.numpy())\n",
    "        \n",
    "    return loss_backet\n",
    "\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lossb = train_model(X, yv, yp, model, net_iters=500)\n",
    "plt.plot(lossb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import LSTMmodel\n",
    "#from  import LSTMModel, mctsTrainer\n",
    "model = LSTMmodel.LSTMModel(32, 64, 8, 8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = LSTMmodel.mctsTrainer(env, mcts2, batch_size=20)\n",
    "trainer.train_model(train[k], model, net_iters=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trainer.loss_backet)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lstm, _, _, _ = trainer.transform_bach_as_input(test[k], model)\n",
    "test_lstm = test_lstm.view(-1, len(test_lstm))\n",
    "loss_rew(yvt, model(test_lstm)[1].data.numpy())\n",
    "#get_loss_from(test_lstm, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(LSTMmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeding actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "treegramm_count = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "treegramm_count\n",
    "\n",
    "def delta(dict1, dict2):\n",
    "    #print(np.sum(list(dict1.values()), dict1.values())\n",
    "    return np.sum(list(dict1.values())) - np.sum(list(dict2.values()))\n",
    "\n",
    "def betreegrams(val, env, treegramm_count):\n",
    "    results = {}\n",
    "    treegramm_count = defaultdict(lambda: defaultdict(int))\n",
    "    for v in val[:100]:\n",
    "        #print(env.result, v.formula)\n",
    "        env.calc_formula(v.formula)\n",
    "        results[v.formula] = env.result.copy()\n",
    "        if env.result['o'] == env.out: print(v.formula)\n",
    "    #print(results)\n",
    "    for v in val[:100]:\n",
    "        # beegram\n",
    "        for i in range(len(v.formula)-2):\n",
    "            # beegram\n",
    "            #print(i, results[v.formula[:i]], v.formula[:i])\n",
    "            if i > 0 and delta(results[v.formula[:i]], results[v.formula[:i + 1]]) != 0:\n",
    "                \n",
    "                treegramm_count[v.formula[i-1]][v.formula[i]] += 1\n",
    "                treegramm_count[v.formula[i-1:i+1]][v.formula[i+1]] += 1\n",
    "            if i > 0 and delta(results[v.formula[:i]], results[v.formula[:i + 2]]) != 0:\n",
    "                # ?? peace of sheet!! eB1 in 1ABCieB1e we could remove it...\n",
    "                #print('aa', v.formula, v.formula[:i+1], results[v.formula[:i]], results[v.formula[:i+2]],\n",
    "                #      v.formula[i-1], v.formula[i-1:i+2]\n",
    "                #     )\n",
    "                treegramm_count[v.formula[i-1]][v.formula[i]] += 1\n",
    "                treegramm_count[v.formula[i-1:i+1]][v.formula[i+1]] += 1\n",
    "        i = len(v.formula) - 1\n",
    "        if i >= 0 and delta(results[v.formula[:i]], results[v.formula[:i + 1]]) != 0:\n",
    "            treegramm_count[v.formula[i-1]][v.formula[i]] += 1\n",
    "    return treegramm_count, results\n",
    "    \n",
    "            \n",
    "t, r = betreegrams(val, env, treegramm_count)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_grams(val, env, treegramm_count):\n",
    "    results = {}\n",
    "    treegramm_count = defaultdict(lambda: defaultdict(int))\n",
    "    treegramm_list = []\n",
    "    for v in val:\n",
    "        #print(env.result, v.formula)\n",
    "        env.calc_formula(v.formula)\n",
    "        results[v.formula] = env.result.copy()\n",
    "        if env.result['o'] == env.out: print(v.formula)\n",
    "    #print(results)\n",
    "    for v in val:\n",
    "        # beegram\n",
    "        for i in range(len(v.formula)-2):\n",
    "            if i>0 and delta(results[v.formula[:i+1]], results[v.formula[:i+2]]):\n",
    "                #print(v.formula)\n",
    "                #treegramm_count[v.formula[i:i+1]][v.formula[i+1:i+2]] += 1\n",
    "                treegramm_count[v.formula[i-1:i+1]][v.formula[i+1:i+2]] += 1\n",
    "                #treegramm_list.append([list(v.formula[i-1:i+1]), v.formula[i+1:i+2]])\n",
    "                treegramm_list.append([list(v.formula[i-1:i]), v.formula[i:i+1]])\n",
    "                treegramm_list.append([list(v.formula[i:i+1]), v.formula[i+1:i+2]])\n",
    "            # beegram\n",
    "            \n",
    "        #i = len(v.formula) - 1\n",
    "        #if i >= 0 and delta(results[v.formula[:i]], results[v.formula[:i + 1]]) != 0:\n",
    "            #treegramm_count[v.formula[i-1]][v.formula[i]] += 1\n",
    "    return treegramm_count, treegramm_list, results\n",
    "\n",
    "t, tl, r = count_grams(val, env, treegramm_count)   \n",
    "#tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_SIZE = 1\n",
    "EMBEDDING_DIM = 10\n",
    "trigrams = tl#[([test_sentence[i], test_sentence[i + 1]], test_sentence[i + 2])\n",
    "           # for i in range(len(test_sentence) - 2)]\n",
    "# print the first 3, just so you can see what they look like\n",
    "print(trigrams[:3])\n",
    "\n",
    "vocab = set(env.action_space)\n",
    "word_to_ix = {word: i for i, word in enumerate(env.action_space)}\n",
    "\n",
    "\n",
    "class NGramLanguageModeler(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(NGramLanguageModeler, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).view((1, -1))\n",
    "        out = F.relu(self.linear1(embeds))\n",
    "        out = self.linear2(out)\n",
    "        log_probs = F.log_softmax(out, dim=1)\n",
    "        return log_probs\n",
    "\n",
    "\n",
    "losses = []\n",
    "loss_function = nn.NLLLoss()\n",
    "model = NGramLanguageModeler(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    for context, target in trigrams:\n",
    "\n",
    "        # Step 1. Prepare the inputs to be passed to the model (i.e, turn the words\n",
    "        # into integer indices and wrap them in tensors)\n",
    "        context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
    "\n",
    "        # Step 2. Recall that torch *accumulates* gradients. Before passing in a\n",
    "        # new instance, you need to zero out the gradients from the old\n",
    "        # instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 3. Run the forward pass, getting log probabilities over next\n",
    "        # words\n",
    "        log_probs = model(context_idxs)\n",
    "\n",
    "        # Step 4. Compute your loss function. (Again, Torch wants the target\n",
    "        # word wrapped in a tensor)\n",
    "        loss = loss_function(log_probs, torch.tensor([word_to_ix[target]], dtype=torch.long))\n",
    "\n",
    "        # Step 5. Do the backward pass and update the gradient\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Get the Python number from a 1-element Tensor by calling tensor.item()\n",
    "        total_loss += loss.item()\n",
    "    losses.append(total_loss)\n",
    "print(losses)  # The loss decreased every iteration over the training data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = np.vstack([model.embeddings(torch.tensor([i])).data.numpy() for i in range(8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "#dataframe = np.concatenate([samples, test], axis=0)#[train, test, samples], axis=0)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_feature_reduced = pca.fit(dataframe).transform(dataframe)\n",
    "# map word vectors onto 2d plane with PCA. Use good old sklearn api (fit, transform)\n",
    "# after that, normalize vectors to make sure they have zero mean and unit variance\n",
    "#word_vectors_pca = # YOUR CODE\n",
    "\n",
    "# and maybe MORE OF YOUR CODE here :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=X_feature_reduced[:,0], y=X_feature_reduced[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bokeh.models as bm, bokeh.plotting as pl\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()\n",
    "\n",
    "def draw_vectors(x, y, radius=10, alpha=0.25, color='blue',\n",
    "                 width=600, height=400, show=True, **kwargs):\n",
    "    \"\"\" draws an interactive plot for data points with auxilirary info on hover \"\"\"\n",
    "    if isinstance(color, str): color = [color] * len(x)\n",
    "    data_source = bm.ColumnDataSource({ 'x' : x, 'y' : y, 'color': color, **kwargs })\n",
    "\n",
    "    fig = pl.figure(active_scroll='wheel_zoom', width=width, height=height)\n",
    "    fig.scatter('x', 'y', size=radius, color='color', alpha=alpha, source=data_source)\n",
    "\n",
    "    fig.add_tools(bm.HoverTool(tooltips=[(key, \"@\" + key) for key in kwargs.keys()]))\n",
    "    if show: pl.show(fig)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_vectors(X_feature_reduced[:, 0], X_feature_reduced[:, 1], token=list(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class def_zer():\n",
    "    def __init__(self):\n",
    "        return np.zeros([8])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "j= defaultdict(int)\n",
    "prj = np.zeros([8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clval = t.clean_unpredict_node(val)\n",
    "sm.train(clval)\n",
    "for f in clval:\n",
    "    last = -1\n",
    "    if f.formula and f.formula[-1:]=='e' and len(f.history_data['next_node_ind']) > last:\n",
    "        print(f.times_visited, f.formula, f.history_data['next_node_ind'][last])                                       \n",
    "        j[f.history_data['next_node_ind'][last]] += 1\n",
    "        x = model.get_observation(f.formula, env)\n",
    "        prj += model.predict(x)[0].reshape([8])\n",
    "        \n",
    "\n",
    "#[(f.formula, f.history_data['next_node_ind'][0], j[f.history_data['next_node_ind'][0]] += 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[f.formula for f in val]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class StModel:\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        self.stat = np.random.rand(8, 8)\n",
    "        self.vstat = np.random.rand(8)\n",
    "        \n",
    "    def train(self, val):\n",
    "        self.stat = np.zeros([8, 8])\n",
    "        self.predvst = defaultdict(list)\n",
    "        self.vstat = np.zeros([8])\n",
    "        for node in val:\n",
    "            if node.formula:\n",
    "                v = self.env.action_space.index(node.formula[0])\n",
    "                nv = node.history_data['next_node_ind'][-1]\n",
    "                nr = node.history_data['next_node_val'][-1]\n",
    "                self.stat[v][nv] += 1\n",
    "                self.predvst[v].append(nr)\n",
    "        self.stat /= np.sum(self.stat, axis=0) + 0.0001\n",
    "        for i, k in enumerate(self.predvst):\n",
    "            self.vstat[i] = sum(self.predvst[k]) / len(self.predvst[k])\n",
    "         \n",
    "            \n",
    "    def predict(self, formula):\n",
    "        v = self.env.action_space.index(formula[-1])\n",
    "        return self.stat[:, v], self.vstat[v]\n",
    "    \n",
    "    def get_observation(self, formula, env, time=0):\n",
    "        return formula\n",
    "            \n",
    "sm = StModel(env)\n",
    "#sm.train(val)\n",
    "sm.predict('Ai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.train(train[k][0])\n",
    "sm.predict('Ai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss_from(test, model):\n",
    "    ans = np.zeros_like(yvt)\n",
    "    for i, f in enumerate(test):\n",
    "    #print('===', f.formula)    \n",
    "        if f.formula:\n",
    "            ans[i] = model.predict(f.formula)[1]\n",
    "        else:\n",
    "            ans[i] = 1\n",
    "    return loss_rew(yvt, ans)\n",
    "\n",
    "get_loss_from(test[k][0], sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_rew(yvt, ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = mctsTrainer(env, mcts, batch_size=20)\n",
    "\n",
    "def get_sorted_batch(val, batch_size=20):\n",
    "    sort_val = sorted(val, key=lambda x: len(x.formula))\n",
    "    i = np.random.randint(len(val) - batch_size)\n",
    "    yield sort_val[i:i + batch_size]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sbach = list(get_sorted_batch(val))\n",
    "#print(sbach[0])\n",
    "#for i in sbach[0]: \n",
    "#    print(i.formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    batch = list(get_sorted_batch(val))\n",
    "    \n",
    "    torch.cat([model.get_observation(n.formula, env) for n in batch]).view(t.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_SIZE = 1\n",
    "EMBEDDING_DIM = 10\n",
    "trigrams = [([test_sentence[i], test_sentence[i + 1]], test_sentence[i + 2])\n",
    "            for i in range(len(test_sentence) - 2)]\n",
    "# print the first 3, just so you can see what they look like\n",
    "print(trigrams[:3])\n",
    "\n",
    "vocab = set(env.action_space)\n",
    "word_to_ix = {word: i for i, word in enumerate(env.action_space)}\n",
    "\n",
    "\n",
    "class NGramLanguageModeler(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(NGramLanguageModeler, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).view((1, -1))\n",
    "        out = F.relu(self.linear1(embeds))\n",
    "        out = self.linear2(out)\n",
    "        log_probs = F.log_softmax(out, dim=1)\n",
    "        return log_probs\n",
    "\n",
    "\n",
    "losses = []\n",
    "loss_function = nn.NLLLoss()\n",
    "model = NGramLanguageModeler(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    for context, target in trigrams:\n",
    "\n",
    "        # Step 1. Prepare the inputs to be passed to the model (i.e, turn the words\n",
    "        # into integer indices and wrap them in tensors)\n",
    "        context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
    "\n",
    "        # Step 2. Recall that torch *accumulates* gradients. Before passing in a\n",
    "        # new instance, you need to zero out the gradients from the old\n",
    "        # instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 3. Run the forward pass, getting log probabilities over next\n",
    "        # words\n",
    "        log_probs = model(context_idxs)\n",
    "\n",
    "        # Step 4. Compute your loss function. (Again, Torch wants the target\n",
    "        # word wrapped in a tensor)\n",
    "        loss = loss_function(log_probs, torch.tensor([word_to_ix[target]], dtype=torch.long))\n",
    "\n",
    "        # Step 5. Do the backward pass and update the gradient\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Get the Python number from a 1-element Tensor by calling tensor.item()\n",
    "        total_loss += loss.item()\n",
    "    losses.append(total_loss)\n",
    "print(losses)  # The loss decreased every iteration over the training data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_data(val):\n",
    "    print(val.formula, val.fin_prob, val.ucb_score())\n",
    "\n",
    "shuffle(val)\n",
    "for i in range(30):\n",
    "    val_data(val[i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcts.Nodes['i1iBo'].times_visited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.transform_bach_as_input(t.get_batch(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = {'1': 1, 'i': 0, 'o': 0, 'A': 0, 'B': 0, 'C': 0}\n",
    "keys=list(values) + ['s', 'e']\n",
    "\n",
    "dd = {'formula':[], 'val_sum':[]}\n",
    "for i in replay_buffer.replay:\n",
    "    dd['formula'].append(i[2])\n",
    "    dd['val_sum'].append(i[3].value_sum)\n",
    "    \n",
    "    for j, k in enumerate(keys):\n",
    "        #print('j', j, i[4])\n",
    "        #print(i, i[4][j])\n",
    "        dd[k] = i[4][j]\n",
    "\n",
    "df = pd.DataFrame(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['formula']=='']#['ucb'].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['formula']=='ie']#['ucb'].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer.get_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "F.softmax(Tensor([0,0,0])).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FHT8MKGkKgMZ"
   },
   "outputs": [],
   "source": [
    "test_env.reset()\n",
    "Vocab, Vocab[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vF4aIxxZKgMd"
   },
   "outputs": [],
   "source": [
    "j.select_best_leaf().action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FOQXFnS1KgMi"
   },
   "outputs": [],
   "source": [
    "j.select_best_leaf().rollout(env, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JIrncnZsKgMm"
   },
   "outputs": [],
   "source": [
    "test_env.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e-cTCUZ1KgMs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NidVAYKCKgMw"
   },
   "outputs": [],
   "source": [
    "test_env.step(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JMg5FKlQKgM4"
   },
   "outputs": [],
   "source": [
    "test_env.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bkCYSESeKgM_"
   },
   "outputs": [],
   "source": [
    "test_env.step(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aI3S4cplKgNJ"
   },
   "outputs": [],
   "source": [
    "test_env.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X0cm_RpRKgNN"
   },
   "outputs": [],
   "source": [
    "test_env.step(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TeL1SNw8KgNQ"
   },
   "source": [
    "# Imetation learning \n",
    "### if we already know answer we should show it to mcts tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M3OmftFqKgNS",
    "outputId": "ce5b2f36-6702-4124-b61e-3ac00cdc1b79"
   },
   "outputs": [],
   "source": [
    "#text = \"input_eq_A A[2]_eq_out\"\n",
    "def text_to_actions(text, vocab=Vocab):\n",
    "    action_seq = []\n",
    "    i = 0\n",
    "    operator = ''\n",
    "    while i < len(text):\n",
    "        if text[i] in Vocab:\n",
    "            action_seq.append(Vocab.index(text[i]))\n",
    "        else:\n",
    "            operator += text[i]\n",
    "            #print('ss', text[i], operator)\n",
    "            if operator == 'input':\n",
    "                operator = ''\n",
    "                \n",
    "            if operator in Vocab:\n",
    "                action_seq.append(Vocab.index(operator))\n",
    "                operator = ''\n",
    "\n",
    "\n",
    "        i += 1\n",
    "    return action_seq\n",
    "\n",
    "for i in text_to_actions(text):\n",
    "    print(Vocab[i])\n",
    "text_to_actions(text)\n",
    "        #print(Vocab.index(i))\n",
    "        #print(env.step(1))\n",
    "        #print(env.step(Vocab.index(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dVYXJY8CKgNX"
   },
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SyISzsg9KgNa"
   },
   "outputs": [],
   "source": [
    "#text = \"input_sum_A\" \n",
    "for i in text_to_actions(text):\n",
    "    print(i)\n",
    "    print(Vocab[i])\n",
    "    print(env.step(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fq8wx-GIKgNe",
    "outputId": "c2bc22a2-11d0-47fb-ae78-de64f7916297"
   },
   "outputs": [],
   "source": [
    "text = \"input_eq_A A[2]_const_AA AA_eq_out\" \n",
    "c = CalcNode(text)\n",
    "c.calc(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8HvILK6NKgNi",
    "outputId": "b06ec81a-9728-4fb8-e463-764bb2c402d8"
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "#import mcts\n",
    "importlib.reload(mcts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uGE-MtmQKgNm"
   },
   "outputs": [],
   "source": [
    "root_observation = env.reset()\n",
    "root_snapshot = env.get_snapshot()\n",
    "root = mcts.Root(root_snapshot,root_observation)\n",
    "\n",
    "#plan_mcts(root, env, n_iters=10000, t_max=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dcktRK9PKgNr",
    "outputId": "8a97b6ff-9d2b-4f4c-f71f-07ca8ba61cb3"
   },
   "outputs": [],
   "source": [
    "root.is_leaf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dobGrIBhKgNw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z4tbTs7QKgN1"
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    is_done = env.step(env.action_space.sample())[2]\n",
    "    if is_done: \n",
    "        print(\"Whoops! We died!\")\n",
    "        break\n",
    "        \n",
    "print(\"final state:\")\n",
    "plt.imshow(env.render('rgb_array'))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YCfndGRvKgN7"
   },
   "outputs": [],
   "source": [
    "def teach_mcts(root, env, action_seq):\n",
    "    \"\"\"\n",
    "    builds tree with monte-carlo tree search for n_iters iterations\n",
    "    :param root: tree node to plan from\n",
    "    :param n_iters: how many select-expand-simulate-propagete loops to make\n",
    "    \"\"\"\n",
    "    #node = root\n",
    "    #node = mcts.Node(root, action_seq[0], env)\n",
    "    #root.children.add(node)\n",
    "    for action in action_seq:\n",
    "        #print(action)\n",
    "        #print(node.is_done)\n",
    "        \n",
    "        #next_node = mcts.Node(next_node, action, env)\n",
    "        #node.children.add(mcts.Node(node, action, env))\n",
    "        #node = next_node\n",
    "        \n",
    "        #print(node.is_done)\n",
    "        node = root.select_best_leaf()\n",
    "        \n",
    "        #print(Vocab[node.action])\n",
    "        \n",
    "        if node.is_done:\n",
    "            if node.immediate_reward > 0:\n",
    "                print(\"get_reward mcts plan!\", node.immediate_reward)  \n",
    "            \n",
    "            node.propagate(0)\n",
    "            #env.reset()\n",
    "       \n",
    "        else: #node is not terminal\n",
    "            \n",
    "            #print(_)\n",
    "            #env.reset()\n",
    "            #self.env.close()\n",
    "            #self.render()\n",
    "            node.expand(env)\n",
    "            #print(Vocab[node.action])\n",
    "            for i in node.children:\n",
    "                print('dd', )#Vocab[node.action], node.parent.action)\n",
    "            ## value = node.rollout(env, 10)\n",
    "            #if value >0:\n",
    "            #    print('plan after rolout', value, node.action)\n",
    "            ##node.propagate(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9wpJsyD4KgN_",
    "outputId": "b072c7e6-6701-47ce-e7d5-88fb46a0de64"
   },
   "outputs": [],
   "source": [
    "teach_mcts(root, env, text_to_actions(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rDYbBZD1KgOD"
   },
   "outputs": [],
   "source": [
    "p = mcts.Node(root, 2, env)\n",
    "#p.is_leaf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6LmjGfWZKgOI"
   },
   "outputs": [],
   "source": [
    "mcts.plan_mcts(root,env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nHYw3ZLhKgOa",
    "outputId": "f7f5c650-8cdc-4f57-ceff-5b7b0f12f0eb"
   },
   "outputs": [],
   "source": [
    "for i in root.children:\n",
    "    print(Vocab[i.action], i.value_sum, len(i.children))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y4urPh38KgOi",
    "outputId": "4ecbf4f9-e351-4d1e-9710-bbc1c3e504fc"
   },
   "outputs": [],
   "source": [
    "j = root\n",
    "while j.children:\n",
    "    j = j.children.pop()\n",
    "    print(j.action, len(j.children))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cPmBVHd9KgOm"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "AI_env.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
