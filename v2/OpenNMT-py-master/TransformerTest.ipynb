{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    def __getattr__(self, name):\n",
    "        return self[name]\n",
    "\n",
    "opt = dotdict({\n",
    "    'cpuct':0.5, \n",
    "    'iters':1000\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! python  train.py -data data/demo -save_model /tmp/extra         -layers 6  -rnn_size 112 -word_vec_size 112 -transformer_ff 248 -heads 4          -encoder_type transformer -decoder_type transformer -position_encoding         -train_steps 2000  -max_generator_batches 2 -dropout 0.1         -batch_size 16 -batch_type tokens -normalization tokens  -accum_count 2         -optim adam -adam_beta2 0.998 -decay_method noam -warmup_steps 800 -learning_rate 2         -max_grad_norm 0 -param_init 0  -param_init_glorot         -label_smoothing 0.1 -valid_steps 100 -save_checkpoint_steps 10000         -world_size 1 -gpu_ranks 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer attempt to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "opt = pickle.load( open( \"opt.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def _check_save_model_path(opt):\n",
    "    save_model_path = os.path.abspath(opt.save_model)\n",
    "    model_dirname = os.path.dirname(save_model_path)\n",
    "    if not os.path.exists(model_dirname):\n",
    "        os.makedirs(model_dirname)\n",
    "    return model_dirname\n",
    "        \n",
    "print(_check_save_model_path(opt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#? opt.dec_rnn_size=500\n",
    "#? opt.enc_rnn_size=500\n",
    "opt.encoder_type='transformer'\n",
    "\n",
    "# size\n",
    "opt.batch_size = 256 # 4098\n",
    "opt.heads=1 # 8\n",
    "opt.layers=1\n",
    "opt.rnn_size=512  # 512\n",
    "opt.transformer_ff=564#2048\n",
    "opt.valid_batch_size=24 \n",
    "opt.word_vec_size=512\n",
    "opt.learning_rate = 20 #2\n",
    "#? opt.dec_layers=2\n",
    "#? opt.src_word_vec_size=500\n",
    "#? opt.tgt_word_vec_size=500\n",
    "\n",
    "\n",
    "#save load logs and other dirs\n",
    "opt.data='data/demo'\n",
    "opt.log_file='log'\n",
    "opt.tensorboard_log_dir='runs/onmt'\n",
    "opt.save_checkpoint_steps=1000\n",
    "opt.save_model='saved_model/transformer'\n",
    "opt.train_from=''#/home/denis/Program/AI0/AI-General/v2/OpenNMT-py-master/saved_model/transformer_step_20000.pt'\n",
    "\n",
    "\n",
    "opt.start_decay_steps=9000\n",
    "opt.report_every=1000\n",
    "\n",
    "opt.train_steps=40000\n",
    "opt.valid_steps=1000\n",
    "opt.warmup_steps=7000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-01-23 15:02:01,965 INFO]  * src vocab size = 24997\n",
      "[2020-01-23 15:02:01,991 INFO]  * tgt vocab size = 35820\n",
      "[2020-01-23 15:02:01,993 INFO] Building model...\n",
      "[2020-01-23 15:02:10,376 INFO] NMTModel(\n",
      "  (encoder): TransformerEncoder(\n",
      "    (embeddings): Embeddings(\n",
      "      (make_embedding): Sequential(\n",
      "        (emb_luts): Elementwise(\n",
      "          (0): Embedding(24997, 512, padding_idx=1)\n",
      "        )\n",
      "        (pe): PositionalEncoding(\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (transformer): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax()\n",
      "          (dropout): Dropout(p=0.1)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=564, bias=True)\n",
      "          (w_2): Linear(in_features=564, out_features=512, bias=True)\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1)\n",
      "          (relu): ReLU()\n",
      "          (dropout_2): Dropout(p=0.1)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1)\n",
      "      )\n",
      "    )\n",
      "    (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (embeddings): Embeddings(\n",
      "      (make_embedding): Sequential(\n",
      "        (emb_luts): Elementwise(\n",
      "          (0): Embedding(35820, 512, padding_idx=1)\n",
      "        )\n",
      "        (pe): PositionalEncoding(\n",
      "          (dropout): Dropout(p=0.1)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (transformer_layers): ModuleList(\n",
      "      (0): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax()\n",
      "          (dropout): Dropout(p=0.1)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax()\n",
      "          (dropout): Dropout(p=0.1)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=564, bias=True)\n",
      "          (w_2): Linear(in_features=564, out_features=512, bias=True)\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1)\n",
      "          (relu): ReLU()\n",
      "          (dropout_2): Dropout(p=0.1)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)\n",
      "        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1)\n",
      "      )\n",
      "    )\n",
      "    (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (generator): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=35820, bias=True)\n",
      "    (1): Cast()\n",
      "    (2): LogSoftmax()\n",
      "  )\n",
      ")\n",
      "[2020-01-23 15:02:10,379 INFO] encoder: 14430772\n",
      "[2020-01-23 15:02:10,379 INFO] decoder: 39399456\n",
      "[2020-01-23 15:02:10,380 INFO] * number of parameters: 53830228\n",
      "[2020-01-23 15:02:10,383 INFO] Starting training on GPU: [0]\n",
      "[2020-01-23 15:02:10,384 INFO] Start training loop and validate every 1000 steps...\n",
      "[2020-01-23 15:02:10,385 INFO] Loading dataset from data/demo.train.0.pt\n",
      "[2020-01-23 15:02:10,528 INFO] number of examples: 10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sssave saved_model/transformer /home/denis/Program/AI0/AI-General/v2/OpenNMT-py-master/saved_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-01-23 15:03:46,799 INFO] Loading dataset from data/demo.train.0.pt\n",
      "[2020-01-23 15:03:46,941 INFO] number of examples: 10000\n",
      "[2020-01-23 15:05:09,833 INFO] Step 1000/40000; acc:  12.91; ppl: 445.84; xent: 6.10; lr: 0.00151; 2341/2330 tok/s;    179 sec\n",
      "[2020-01-23 15:05:09,835 INFO] Loading dataset from data/demo.valid.0.pt\n",
      "[2020-01-23 15:05:09,884 INFO] number of examples: 3000\n",
      "[2020-01-23 15:05:14,015 INFO] Validation perplexity: 1368.42\n",
      "[2020-01-23 15:05:14,016 INFO] Validation accuracy: 12.6242\n",
      "[2020-01-23 15:05:14,248 INFO] Saving checkpoint saved_model/transformer_step_1000.pt\n",
      "[2020-01-23 15:05:30,611 INFO] Loading dataset from data/demo.train.0.pt\n",
      "[2020-01-23 15:05:30,756 INFO] number of examples: 10000\n",
      "[2020-01-23 15:07:06,224 INFO] Loading dataset from data/demo.train.0.pt\n",
      "[2020-01-23 15:07:06,382 INFO] number of examples: 10000\n",
      "[2020-01-23 15:08:16,086 INFO] Step 2000/40000; acc:  19.91; ppl: 119.90; xent: 4.79; lr: 0.00302; 2257/2245 tok/s;    366 sec\n",
      "[2020-01-23 15:08:16,088 INFO] Loading dataset from data/demo.valid.0.pt\n",
      "[2020-01-23 15:08:16,121 INFO] number of examples: 3000\n",
      "[2020-01-23 15:08:20,169 INFO] Validation perplexity: 1902\n",
      "[2020-01-23 15:08:20,170 INFO] Validation accuracy: 12.2492\n",
      "[2020-01-23 15:08:20,392 INFO] Saving checkpoint saved_model/transformer_step_2000.pt\n",
      "[2020-01-23 15:08:50,998 INFO] Loading dataset from data/demo.train.0.pt\n",
      "[2020-01-23 15:08:51,149 INFO] number of examples: 10000\n",
      "[2020-01-23 15:10:26,638 INFO] Loading dataset from data/demo.train.0.pt\n",
      "[2020-01-23 15:10:26,791 INFO] number of examples: 10000\n",
      "[2020-01-23 15:11:23,968 INFO] Step 3000/40000; acc:  24.47; ppl: 68.54; xent: 4.23; lr: 0.00453; 2237/2229 tok/s;    554 sec\n",
      "[2020-01-23 15:11:23,970 INFO] Loading dataset from data/demo.valid.0.pt\n",
      "[2020-01-23 15:11:24,000 INFO] number of examples: 3000\n",
      "[2020-01-23 15:11:28,053 INFO] Validation perplexity: 2478.24\n",
      "[2020-01-23 15:11:28,054 INFO] Validation accuracy: 10.3769\n",
      "[2020-01-23 15:11:28,279 INFO] Saving checkpoint saved_model/transformer_step_3000.pt\n",
      "[2020-01-23 15:12:12,229 INFO] Loading dataset from data/demo.train.0.pt\n",
      "[2020-01-23 15:12:12,388 INFO] number of examples: 10000\n",
      "[2020-01-23 15:13:47,607 INFO] Loading dataset from data/demo.train.0.pt\n",
      "[2020-01-23 15:13:47,768 INFO] number of examples: 10000\n",
      "[2020-01-23 15:14:33,022 INFO] Step 4000/40000; acc:  26.29; ppl: 55.64; xent: 4.02; lr: 0.00604; 2222/2215 tok/s;    743 sec\n",
      "[2020-01-23 15:14:33,024 INFO] Loading dataset from data/demo.valid.0.pt\n",
      "[2020-01-23 15:14:33,054 INFO] number of examples: 3000\n",
      "[2020-01-23 15:14:37,104 INFO] Validation perplexity: 2541.51\n",
      "[2020-01-23 15:14:37,106 INFO] Validation accuracy: 10.9086\n",
      "[2020-01-23 15:14:37,327 INFO] Saving checkpoint saved_model/transformer_step_4000.pt\n",
      "[2020-01-23 15:15:32,673 INFO] Loading dataset from data/demo.train.0.pt\n",
      "[2020-01-23 15:15:32,833 INFO] number of examples: 10000\n",
      "[2020-01-23 15:17:08,554 INFO] Loading dataset from data/demo.train.0.pt\n",
      "[2020-01-23 15:17:08,719 INFO] number of examples: 10000\n",
      "[2020-01-23 15:17:41,770 INFO] Step 5000/40000; acc:  27.09; ppl: 49.30; xent: 3.90; lr: 0.00755; 2225/2216 tok/s;    931 sec\n",
      "[2020-01-23 15:17:41,772 INFO] Loading dataset from data/demo.valid.0.pt\n",
      "[2020-01-23 15:17:41,806 INFO] number of examples: 3000\n",
      "[2020-01-23 15:17:46,131 INFO] Validation perplexity: 3101.71\n",
      "[2020-01-23 15:17:46,132 INFO] Validation accuracy: 9.75277\n",
      "[2020-01-23 15:17:46,367 INFO] Saving checkpoint saved_model/transformer_step_5000.pt\n",
      "[2020-01-23 15:18:59,430 INFO] Loading dataset from data/demo.train.0.pt\n",
      "[2020-01-23 15:18:59,596 INFO] number of examples: 10000\n",
      "[2020-01-23 15:20:41,376 INFO] Loading dataset from data/demo.train.0.pt\n",
      "[2020-01-23 15:20:41,551 INFO] number of examples: 10000\n",
      "[2020-01-23 15:21:02,741 INFO] Step 6000/40000; acc:  26.65; ppl: 51.60; xent: 3.94; lr: 0.00906; 2093/2081 tok/s;   1132 sec\n",
      "[2020-01-23 15:21:02,744 INFO] Loading dataset from data/demo.valid.0.pt\n",
      "[2020-01-23 15:21:02,772 INFO] number of examples: 3000\n",
      "[2020-01-23 15:21:07,082 INFO] Validation perplexity: 2703.79\n",
      "[2020-01-23 15:21:07,084 INFO] Validation accuracy: 10.8135\n",
      "[2020-01-23 15:21:07,316 INFO] Saving checkpoint saved_model/transformer_step_6000.pt\n",
      "[2020-01-23 15:22:31,082 INFO] Loading dataset from data/demo.train.0.pt\n",
      "[2020-01-23 15:22:31,254 INFO] number of examples: 10000\n",
      "[2020-01-23 15:24:15,977 INFO] Loading dataset from data/demo.train.0.pt\n",
      "[2020-01-23 15:24:16,146 INFO] number of examples: 10000\n",
      "[2020-01-23 15:24:24,364 INFO] Step 7000/40000; acc:  26.21; ppl: 55.18; xent: 4.01; lr: 0.01056; 2087/2074 tok/s;   1334 sec\n",
      "[2020-01-23 15:24:24,366 INFO] Loading dataset from data/demo.valid.0.pt\n",
      "[2020-01-23 15:24:24,399 INFO] number of examples: 3000\n",
      "[2020-01-23 15:24:28,850 INFO] Validation perplexity: 2729.13\n",
      "[2020-01-23 15:24:28,852 INFO] Validation accuracy: 10.409\n",
      "[2020-01-23 15:24:29,079 INFO] Saving checkpoint saved_model/transformer_step_7000.pt\n",
      "[2020-01-23 15:26:09,669 INFO] Loading dataset from data/demo.train.0.pt\n",
      "[2020-01-23 15:26:09,843 INFO] number of examples: 10000\n",
      "[2020-01-23 15:27:48,228 INFO] Step 8000/40000; acc:  26.55; ppl: 54.47; xent: 4.00; lr: 0.00988; 2063/2050 tok/s;   1538 sec\n",
      "[2020-01-23 15:27:48,229 INFO] Loading dataset from data/demo.valid.0.pt\n",
      "[2020-01-23 15:27:48,263 INFO] number of examples: 3000\n",
      "[2020-01-23 15:27:52,806 INFO] Validation perplexity: 2703.14\n",
      "[2020-01-23 15:27:52,807 INFO] Validation accuracy: 10.2724\n",
      "[2020-01-23 15:27:53,035 INFO] Saving checkpoint saved_model/transformer_step_8000.pt\n",
      "[2020-01-23 15:28:04,626 INFO] Loading dataset from data/demo.train.0.pt\n",
      "[2020-01-23 15:28:04,817 INFO] number of examples: 10000\n",
      "[2020-01-23 15:29:49,901 INFO] Loading dataset from data/demo.train.0.pt\n",
      "[2020-01-23 15:29:50,071 INFO] number of examples: 10000\n",
      "[2020-01-23 15:31:14,317 INFO] Step 9000/40000; acc:  27.68; ppl: 50.11; xent: 3.91; lr: 0.00932; 2038/2031 tok/s;   1744 sec\n",
      "[2020-01-23 15:31:14,319 INFO] Loading dataset from data/demo.valid.0.pt\n",
      "[2020-01-23 15:31:14,351 INFO] number of examples: 3000\n",
      "[2020-01-23 15:31:18,864 INFO] Validation perplexity: 4324.88\n",
      "[2020-01-23 15:31:18,865 INFO] Validation accuracy: 10.1304\n",
      "[2020-01-23 15:31:19,093 INFO] Saving checkpoint saved_model/transformer_step_9000.pt\n",
      "[2020-01-23 15:31:44,447 INFO] Loading dataset from data/demo.train.0.pt\n",
      "[2020-01-23 15:31:44,622 INFO] number of examples: 10000\n",
      "[2020-01-23 15:33:27,099 INFO] Loading dataset from data/demo.train.0.pt\n",
      "[2020-01-23 15:33:27,274 INFO] number of examples: 10000\n",
      "[2020-01-23 15:34:37,714 INFO] Step 10000/40000; acc:  28.93; ppl: 43.05; xent: 3.76; lr: 0.00884; 2067/2054 tok/s;   1947 sec\n",
      "[2020-01-23 15:34:37,716 INFO] Loading dataset from data/demo.valid.0.pt\n",
      "[2020-01-23 15:34:37,747 INFO] number of examples: 3000\n",
      "[2020-01-23 15:34:42,244 INFO] Validation perplexity: 4382.5\n",
      "[2020-01-23 15:34:42,245 INFO] Validation accuracy: 10.2296\n",
      "[2020-01-23 15:34:42,473 INFO] Saving checkpoint saved_model/transformer_step_10000.pt\n",
      "[2020-01-23 15:35:21,997 INFO] Loading dataset from data/demo.train.0.pt\n",
      "[2020-01-23 15:35:22,179 INFO] number of examples: 10000\n",
      "[2020-01-23 15:37:08,052 INFO] Loading dataset from data/demo.train.0.pt\n",
      "[2020-01-23 15:37:08,232 INFO] number of examples: 10000\n",
      "[2020-01-23 15:38:04,991 INFO] Step 11000/40000; acc:  29.77; ppl: 38.17; xent: 3.64; lr: 0.00843; 2027/2022 tok/s;   2155 sec\n",
      "[2020-01-23 15:38:04,993 INFO] Loading dataset from data/demo.valid.0.pt\n",
      "[2020-01-23 15:38:05,026 INFO] number of examples: 3000\n",
      "[2020-01-23 15:38:09,516 INFO] Validation perplexity: 3103.27\n",
      "[2020-01-23 15:38:09,517 INFO] Validation accuracy: 10.1479\n",
      "[2020-01-23 15:38:09,746 INFO] Saving checkpoint saved_model/transformer_step_11000.pt\n",
      "[2020-01-23 15:39:02,340 INFO] Loading dataset from data/demo.train.0.pt\n",
      "[2020-01-23 15:39:02,516 INFO] number of examples: 10000\n",
      "[2020-01-23 15:40:48,059 INFO] Loading dataset from data/demo.train.0.pt\n",
      "[2020-01-23 15:40:48,238 INFO] number of examples: 10000\n",
      "[2020-01-23 15:41:31,301 INFO] Step 12000/40000; acc:  30.09; ppl: 35.49; xent: 3.57; lr: 0.00807; 2035/2026 tok/s;   2361 sec\n",
      "[2020-01-23 15:41:31,303 INFO] Loading dataset from data/demo.valid.0.pt\n",
      "[2020-01-23 15:41:31,333 INFO] number of examples: 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-01-23 15:41:35,819 INFO] Validation perplexity: 4488.98\n",
      "[2020-01-23 15:41:35,820 INFO] Validation accuracy: 9.78357\n",
      "[2020-01-23 15:41:36,051 INFO] Saving checkpoint saved_model/transformer_step_12000.pt\n",
      "[2020-01-23 15:42:41,239 INFO] Loading dataset from data/demo.train.0.pt\n",
      "[2020-01-23 15:42:41,426 INFO] number of examples: 10000\n",
      "[2020-01-23 15:44:19,773 INFO] Loading dataset from data/demo.train.0.pt\n",
      "[2020-01-23 15:44:19,953 INFO] number of examples: 10000\n",
      "[2020-01-23 15:44:48,281 INFO] Step 13000/40000; acc:  28.58; ppl: 41.66; xent: 3.73; lr: 0.00775; 2135/2124 tok/s;   2558 sec\n",
      "[2020-01-23 15:44:48,283 INFO] Loading dataset from data/demo.valid.0.pt\n",
      "[2020-01-23 15:44:48,315 INFO] number of examples: 3000\n",
      "[2020-01-23 15:44:52,492 INFO] Validation perplexity: 3021.65\n",
      "[2020-01-23 15:44:52,493 INFO] Validation accuracy: 10.4157\n",
      "[2020-01-23 15:44:52,728 INFO] Saving checkpoint saved_model/transformer_step_13000.pt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4ade2da5cf3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Program/AI0/AI-General/v2/OpenNMT-py-master/test.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(opt)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mnb_gpu\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# case 1 GPU only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0msingle_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m# case only CPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0msingle_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program/AI0/AI-General/v2/OpenNMT-py-master/onmt/train_single.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(opt, device_id, batch_queue, semaphore)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0msave_checkpoint_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_checkpoint_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mvalid_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         valid_steps=opt.valid_steps)\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreport_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorboard_writer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program/AI0/AI-General/v2/OpenNMT-py-master/onmt/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_iter, train_steps, save_checkpoint_steps, valid_iter, valid_steps)\u001b[0m\n\u001b[1;32m    242\u001b[0m             self._gradient_accumulation(\n\u001b[1;32m    243\u001b[0m                 \u001b[0mbatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m                 report_stats)\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage_decay\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program/AI0/AI-General/v2/OpenNMT-py-master/onmt/trainer.py\u001b[0m in \u001b[0;36m_gradient_accumulation\u001b[0;34m(self, true_batches, normalization, total_stats, report_stats)\u001b[0m\n\u001b[1;32m    375\u001b[0m                         \u001b[0mshard_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshard_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m                         \u001b[0mtrunc_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                         trunc_size=trunc_size)\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program/AI0/AI-General/v2/OpenNMT-py-master/onmt/utils/loss.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, batch, output, attns, normalization, shard_size, trunc_start, trunc_size)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mbatch_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatistics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mshard\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mshards\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshard_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshard_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mshard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalization\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0mbatch_stats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program/AI0/AI-General/v2/OpenNMT-py-master/onmt/utils/loss.py\u001b[0m in \u001b[0;36m_compute_loss\u001b[0;34m(self, batch, output, target, std_attn, coverage_attn, align_head, ref_align)\u001b[0m\n\u001b[1;32m    297\u001b[0m                 align_head=align_head, ref_align=ref_align)\n\u001b[1;32m    298\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0malign_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m         \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgtruth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program/AI0/AI-General/v2/OpenNMT-py-master/onmt/utils/loss.py\u001b[0m in \u001b[0;36m_stats\u001b[0;34m(self, loss, scores, target)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mnon_padding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mnum_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_padding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m         \u001b[0mnum_non_padding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnon_padding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0monmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatistics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_non_padding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_correct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import test\n",
    "test.train(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small translator attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py -data data/demo -save_model demo-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.load( open( \"opt_simple_model.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# big question!!! why train donot import or any other function\n",
    "import train\n",
    "tr_cls = train.Train()\n",
    "tr_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"Training on a single process.\"\"\"\n",
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "from onmt.inputters.inputter import build_dataset_iter, \\\n",
    "    load_old_vocab, old_style_vocab, build_dataset_iter_multiple\n",
    "from onmt.model_builder import build_model\n",
    "from onmt.utils.optimizers import Optimizer\n",
    "from onmt.utils.misc import set_random_seed\n",
    "from onmt.trainer import build_trainer\n",
    "from onmt.models import build_model_saver\n",
    "from onmt.utils.logging import init_logger, logger\n",
    "from onmt.utils.parse import ArgumentParser\n",
    "\n",
    "\n",
    "def _check_save_model_path(opt):\n",
    "    save_model_path = os.path.abspath(opt.save_model)\n",
    "    model_dirname = os.path.dirname(save_model_path)\n",
    "    if not os.path.exists(model_dirname):\n",
    "        os.makedirs(model_dirname)\n",
    "\n",
    "\n",
    "def _tally_parameters(model):\n",
    "    enc = 0\n",
    "    dec = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'encoder' in name:\n",
    "            enc += param.nelement()\n",
    "        else:\n",
    "            dec += param.nelement()\n",
    "    return enc + dec, enc, dec\n",
    "\n",
    "\n",
    "def configure_process(opt, device_id):\n",
    "    if device_id >= 0:\n",
    "        torch.cuda.set_device(device_id)\n",
    "    set_random_seed(opt.seed, device_id >= 0)\n",
    "\n",
    "\n",
    "def main(opt, device_id, batch_queue=None, semaphore=None):\n",
    "    # NOTE: It's important that ``opt`` has been validated and updated\n",
    "    # at this point.\n",
    "    configure_process(opt, device_id)\n",
    "    init_logger(opt.log_file)\n",
    "    assert len(opt.accum_count) == len(opt.accum_steps), \\\n",
    "        'Number of accum_count values must match number of accum_steps'\n",
    "    # Load checkpoint if we resume from a previous training.\n",
    "    if opt.train_from:\n",
    "        logger.info('Loading checkpoint from %s' % opt.train_from)\n",
    "        checkpoint = torch.load(opt.train_from,\n",
    "                                map_location=lambda storage, loc: storage)\n",
    "        model_opt = ArgumentParser.ckpt_model_opts(checkpoint[\"opt\"])\n",
    "        ArgumentParser.update_model_opts(model_opt)\n",
    "        ArgumentParser.validate_model_opts(model_opt)\n",
    "        logger.info('Loading vocab from checkpoint at %s.' % opt.train_from)\n",
    "        vocab = checkpoint['vocab']\n",
    "    else:\n",
    "        checkpoint = None\n",
    "        model_opt = opt\n",
    "        vocab = torch.load(opt.data + '.vocab.pt')\n",
    "\n",
    "    # check for code where vocab is saved instead of fields\n",
    "    # (in the future this will be done in a smarter way)\n",
    "    if old_style_vocab(vocab):\n",
    "        fields = load_old_vocab(\n",
    "            vocab, opt.model_type, dynamic_dict=opt.copy_attn)\n",
    "    else:\n",
    "        fields = vocab\n",
    "\n",
    "    # Report src and tgt vocab sizes, including for features\n",
    "    for side in ['src', 'tgt']:\n",
    "        f = fields[side]\n",
    "        try:\n",
    "            f_iter = iter(f)\n",
    "        except TypeError:\n",
    "            f_iter = [(side, f)]\n",
    "        for sn, sf in f_iter:\n",
    "            if sf.use_vocab:\n",
    "                logger.info(' * %s vocab size = %d' % (sn, len(sf.vocab)))\n",
    "\n",
    "    # Build model.\n",
    "    model = build_model(model_opt, opt, fields, checkpoint)\n",
    "    n_params, enc, dec = _tally_parameters(model)\n",
    "    #logger.info('encoder: %d' % enc)\n",
    "    #logger.info('decoder: %d' % dec)\n",
    "    #logger.info('* number of parameters: %d' % n_params)\n",
    "    _check_save_model_path(opt)\n",
    "\n",
    "    # Build optimizer.\n",
    "    optim = Optimizer.from_opt(model, opt, checkpoint=checkpoint)\n",
    "\n",
    "    # Build model saver\n",
    "    model_saver = build_model_saver(model_opt, opt, model, fields, optim)\n",
    "\n",
    "    trainer = build_trainer(\n",
    "        opt, device_id, model, fields, optim, model_saver=model_saver)\n",
    "\n",
    "    if batch_queue is None:\n",
    "        if len(opt.data_ids) > 1:\n",
    "            train_shards = []\n",
    "            for train_id in opt.data_ids:\n",
    "                shard_base = \"train_\" + train_id\n",
    "                train_shards.append(shard_base)\n",
    "            train_iter = build_dataset_iter_multiple(train_shards, fields, opt)\n",
    "        else:\n",
    "            if opt.data_ids[0] is not None:\n",
    "                shard_base = \"train_\" + opt.data_ids[0]\n",
    "            else:\n",
    "                shard_base = \"train\"\n",
    "            train_iter = build_dataset_iter(shard_base, fields, opt)\n",
    "\n",
    "    else:\n",
    "        assert semaphore is not None, \\\n",
    "            \"Using batch_queue requires semaphore as well\"\n",
    "\n",
    "        def _train_iter():\n",
    "            while True:\n",
    "                batch = batch_queue.get()\n",
    "                semaphore.release()\n",
    "                yield batch\n",
    "\n",
    "        train_iter = _train_iter()\n",
    "\n",
    "    valid_iter = build_dataset_iter(\n",
    "        \"valid\", fields, opt, is_train=False)\n",
    "\n",
    "    if len(opt.gpu_ranks):\n",
    "        logger.info('Starting training on GPU: %s' % opt.gpu_ranks)\n",
    "    else:\n",
    "        logger.info('Starting training on CPU, could be very slow')\n",
    "    train_steps = opt.train_steps\n",
    "    if opt.single_pass and train_steps > 0:\n",
    "        logger.warning(\"Option single_pass is enabled, ignoring train_steps.\")\n",
    "        train_steps = 0\n",
    "        \n",
    "    for i, batches in enumerate(train_iter):\n",
    "        print(i, batches)\n",
    "        \n",
    "\"\"\"\n",
    "    trainer.train(\n",
    "        train_iter,\n",
    "        train_steps,\n",
    "        save_checkpoint_steps=opt.save_checkpoint_steps,\n",
    "        valid_iter=valid_iter,\n",
    "        valid_steps=opt.valid_steps)\n",
    "\n",
    "    if trainer.report_manager.tensorboard_writer is not None:\n",
    "        trainer.report_manager.tensorboard_writer.close()\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(opt, 0, batch_queue=None, semaphore=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
