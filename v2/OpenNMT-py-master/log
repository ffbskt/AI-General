[2020-01-22 08:46:38,675 INFO]  * src vocab size = 24997
[2020-01-22 08:46:38,680 INFO]  * tgt vocab size = 35820
[2020-01-22 08:46:38,681 INFO] Building model...
[2020-01-22 08:46:50,354 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(24997, 512, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1)
        )
      )
    )
    (transformer): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
    )
    (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(35820, 512, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1)
        )
      )
    )
    (transformer_layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (4): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (5): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
    )
    (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
  )
  (generator): Sequential(
    (0): Linear(in_features=512, out_features=35820, bias=True)
    (1): Cast()
    (2): LogSoftmax()
  )
)
[2020-01-22 08:46:50,360 INFO] encoder: 22587192
[2020-01-22 08:46:50,361 INFO] decoder: 52814116
[2020-01-22 08:46:50,362 INFO] * number of parameters: 75401308
[2020-01-22 08:46:50,368 INFO] Starting training on GPU: [0]
[2020-01-22 08:46:50,369 INFO] Start training loop and validate every 1000 steps...
[2020-01-22 08:46:50,370 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 08:46:50,521 INFO] number of examples: 10000
[2020-01-22 08:49:08,633 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 08:49:08,773 INFO] number of examples: 10000
[2020-01-22 08:51:07,808 INFO] Step 1000/20000; acc:  10.42; ppl: 857.77; xent: 6.75; lr: 0.00015; 1633/1625 tok/s;    257 sec
[2020-01-22 08:51:07,811 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-22 08:51:07,862 INFO] number of examples: 3000
[2020-01-22 08:53:20,071 INFO]  * src vocab size = 24997
[2020-01-22 08:53:20,073 INFO]  * tgt vocab size = 35820
[2020-01-22 08:53:20,074 INFO] Building model...
[2020-01-22 08:53:23,237 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(24997, 512, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1)
        )
      )
    )
    (transformer): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
    )
    (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(35820, 512, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1)
        )
      )
    )
    (transformer_layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (4): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (5): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
    )
    (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
  )
  (generator): Sequential(
    (0): Linear(in_features=512, out_features=35820, bias=True)
    (1): Cast()
    (2): LogSoftmax()
  )
)
[2020-01-22 08:53:23,273 INFO] encoder: 22587192
[2020-01-22 08:53:23,274 INFO] decoder: 52814116
[2020-01-22 08:53:23,275 INFO] * number of parameters: 75401308
[2020-01-22 08:53:23,279 INFO] Starting training on GPU: [0]
[2020-01-22 08:53:23,280 INFO] Start training loop and validate every 1000 steps...
[2020-01-22 08:53:23,281 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 08:53:23,402 INFO] number of examples: 10000
[2020-01-22 08:55:40,221 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 08:55:40,365 INFO] number of examples: 10000
[2020-01-22 08:57:39,947 INFO] Step 1000/20000; acc:  10.42; ppl: 865.58; xent: 6.76; lr: 0.00015; 1636/1630 tok/s;    257 sec
[2020-01-22 08:57:39,949 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-22 08:57:40,006 INFO] number of examples: 3000
[2020-01-22 08:59:01,941 INFO]  * src vocab size = 24997
[2020-01-22 08:59:01,946 INFO]  * tgt vocab size = 35820
[2020-01-22 08:59:01,947 INFO] Building model...
[2020-01-22 08:59:05,094 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(24997, 512, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1)
        )
      )
    )
    (transformer): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
    )
    (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(35820, 512, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1)
        )
      )
    )
    (transformer_layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (4): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (5): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
    )
    (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
  )
  (generator): Sequential(
    (0): Linear(in_features=512, out_features=35820, bias=True)
    (1): Cast()
    (2): LogSoftmax()
  )
)
[2020-01-22 08:59:05,101 INFO] encoder: 22587192
[2020-01-22 08:59:05,102 INFO] decoder: 52814116
[2020-01-22 08:59:05,103 INFO] * number of parameters: 75401308
[2020-01-22 08:59:05,109 INFO] Starting training on GPU: [0]
[2020-01-22 08:59:05,110 INFO] Start training loop and validate every 100 steps...
[2020-01-22 08:59:05,111 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 08:59:05,224 INFO] number of examples: 10000
[2020-01-22 08:59:31,161 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-22 08:59:31,281 INFO] number of examples: 3000
[2020-01-22 08:59:40,441 INFO] Validation perplexity: 18939.5
[2020-01-22 08:59:40,442 INFO] Validation accuracy: 6.08309
[2020-01-22 09:00:06,053 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-22 09:00:06,089 INFO] number of examples: 3000
[2020-01-22 09:00:15,207 INFO] Validation perplexity: 8191.79
[2020-01-22 09:00:15,208 INFO] Validation accuracy: 6.08443
[2020-01-22 09:00:41,132 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-22 09:00:41,164 INFO] number of examples: 3000
[2020-01-22 09:00:50,336 INFO] Validation perplexity: 3318.77
[2020-01-22 09:00:50,337 INFO] Validation accuracy: 7.23087
[2020-01-22 09:01:23,788 INFO]  * src vocab size = 24997
[2020-01-22 09:01:23,789 INFO]  * tgt vocab size = 35820
[2020-01-22 09:01:23,790 INFO] Building model...
[2020-01-22 09:01:25,039 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(24997, 512, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1)
        )
      )
    )
    (transformer): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
    )
    (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(35820, 512, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1)
        )
      )
    )
    (transformer_layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (4): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (5): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
    )
    (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
  )
  (generator): Sequential(
    (0): Linear(in_features=512, out_features=35820, bias=True)
    (1): Cast()
    (2): LogSoftmax()
  )
)
[2020-01-22 09:01:25,046 INFO] encoder: 22587192
[2020-01-22 09:01:25,047 INFO] decoder: 52814116
[2020-01-22 09:01:25,047 INFO] * number of parameters: 75401308
[2020-01-22 09:01:25,052 INFO] Starting training on GPU: [0]
[2020-01-22 09:01:25,053 INFO] Start training loop and validate every 1000 steps...
[2020-01-22 09:01:25,053 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 09:01:25,252 INFO] number of examples: 10000
[2020-01-22 09:01:49,854 INFO]  * src vocab size = 24997
[2020-01-22 09:01:49,859 INFO]  * tgt vocab size = 35820
[2020-01-22 09:01:49,860 INFO] Building model...
[2020-01-22 09:01:52,971 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(24997, 512, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1)
        )
      )
    )
    (transformer): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
    )
    (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(35820, 512, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1)
        )
      )
    )
    (transformer_layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (4): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (5): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
    )
    (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
  )
  (generator): Sequential(
    (0): Linear(in_features=512, out_features=35820, bias=True)
    (1): Cast()
    (2): LogSoftmax()
  )
)
[2020-01-22 09:01:52,978 INFO] encoder: 22587192
[2020-01-22 09:01:52,980 INFO] decoder: 52814116
[2020-01-22 09:01:52,981 INFO] * number of parameters: 75401308
[2020-01-22 09:01:52,986 INFO] Starting training on GPU: [0]
[2020-01-22 09:01:52,987 INFO] Start training loop and validate every 1000 steps...
[2020-01-22 09:01:52,988 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 09:01:53,108 INFO] number of examples: 10000
[2020-01-22 09:04:10,708 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 09:04:10,854 INFO] number of examples: 10000
[2020-01-22 09:06:09,737 INFO] Step 1000/20000; acc:  10.27; ppl: 870.32; xent: 6.77; lr: 0.00015; 1638/1629 tok/s;    257 sec
[2020-01-22 09:06:09,739 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-22 09:06:09,769 INFO] number of examples: 3000
[2020-01-22 09:06:18,916 INFO] Validation perplexity: 1383.56
[2020-01-22 09:06:18,917 INFO] Validation accuracy: 13.5524
[2020-01-22 09:06:37,695 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 09:06:37,840 INFO] number of examples: 10000
[2020-01-22 09:08:55,023 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 09:08:55,180 INFO] number of examples: 10000
[2020-01-22 09:10:35,523 INFO] Step 2000/20000; acc:  16.81; ppl: 225.66; xent: 5.42; lr: 0.00030; 1581/1571 tok/s;    523 sec
[2020-01-22 09:10:35,526 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-22 09:10:35,555 INFO] number of examples: 3000
[2020-01-22 09:17:26,005 INFO]  * src vocab size = 24997
[2020-01-22 09:17:26,006 INFO]  * tgt vocab size = 35820
[2020-01-22 09:17:26,006 INFO] Building model...
[2020-01-22 09:19:20,799 INFO]  * src vocab size = 24997
[2020-01-22 09:19:20,821 INFO]  * tgt vocab size = 35820
[2020-01-22 09:19:20,821 INFO] Building model...
[2020-01-22 09:19:57,853 INFO]  * src vocab size = 24997
[2020-01-22 09:19:57,854 INFO]  * tgt vocab size = 35820
[2020-01-22 09:19:57,854 INFO] Building model...
[2020-01-22 09:20:41,330 INFO]  * src vocab size = 24997
[2020-01-22 09:20:41,330 INFO]  * tgt vocab size = 35820
[2020-01-22 09:20:41,330 INFO] Building model...
[2020-01-22 09:20:45,820 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(24997, 512, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1)
        )
      )
    )
    (transformer): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
    )
    (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(35820, 512, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1)
        )
      )
    )
    (transformer_layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (4): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (5): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
    )
    (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
  )
  (generator): Sequential(
    (0): Linear(in_features=512, out_features=35820, bias=True)
    (1): Cast()
    (2): LogSoftmax()
  )
)
[2020-01-22 09:20:45,831 INFO] encoder: 22587192
[2020-01-22 09:20:45,831 INFO] decoder: 52814116
[2020-01-22 09:20:45,831 INFO] * number of parameters: 75401308
[2020-01-22 09:20:45,881 INFO] Starting training on GPU: [0]
[2020-01-22 09:20:45,881 INFO] Start training loop and validate every 1000 steps...
[2020-01-22 09:20:45,881 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 09:20:46,013 INFO] number of examples: 10000
[2020-01-22 09:23:03,091 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 09:23:03,167 INFO] number of examples: 10000
[2020-01-22 09:25:02,007 INFO] Step 1000/20000; acc:  10.85; ppl: 857.64; xent: 6.75; lr: 0.00015; 1642/1633 tok/s;    256 sec
[2020-01-22 09:25:02,008 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-22 09:25:02,116 INFO] number of examples: 3000
[2020-01-22 09:25:11,283 INFO] Validation perplexity: 1362.58
[2020-01-22 09:25:11,283 INFO] Validation accuracy: 13.7131
[2020-01-22 09:25:30,180 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 09:25:30,252 INFO] number of examples: 10000
[2020-01-22 09:27:48,030 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 09:27:48,101 INFO] number of examples: 10000
[2020-01-22 09:29:28,970 INFO] Step 2000/20000; acc:  17.07; ppl: 218.88; xent: 5.39; lr: 0.00030; 1574/1565 tok/s;    523 sec
[2020-01-22 09:29:28,971 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-22 09:29:29,062 INFO] number of examples: 3000
[2020-01-22 09:29:38,247 INFO] Validation perplexity: 1143.56
[2020-01-22 09:29:38,247 INFO] Validation accuracy: 12.9282
[2020-01-22 09:30:14,964 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 09:30:15,036 INFO] number of examples: 10000
[2020-01-22 09:32:32,788 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 09:32:32,923 INFO] number of examples: 10000
[2020-01-22 09:33:56,433 INFO] Step 3000/20000; acc:  20.74; ppl: 108.07; xent: 4.68; lr: 0.00045; 1572/1566 tok/s;    791 sec
[2020-01-22 09:33:56,434 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-22 09:33:56,534 INFO] number of examples: 3000
[2020-01-22 09:34:05,705 INFO] Validation perplexity: 1241.73
[2020-01-22 09:34:05,705 INFO] Validation accuracy: 14.1684
[2020-01-22 09:34:59,673 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 09:34:59,743 INFO] number of examples: 10000
[2020-01-22 09:37:17,892 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 09:37:18,030 INFO] number of examples: 10000
[2020-01-22 09:38:23,147 INFO] Step 4000/20000; acc:  24.23; ppl: 60.34; xent: 4.10; lr: 0.00060; 1577/1569 tok/s;   1057 sec
[2020-01-22 09:38:23,148 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-22 09:38:23,172 INFO] number of examples: 3000
[2020-01-22 09:38:32,510 INFO] Validation perplexity: 1756.22
[2020-01-22 09:38:32,510 INFO] Validation accuracy: 12.2599
[2020-01-22 09:39:45,239 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 09:39:45,375 INFO] number of examples: 10000
[2020-01-22 09:42:03,056 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 09:42:03,192 INFO] number of examples: 10000
[2020-01-22 09:42:50,706 INFO] Step 5000/20000; acc:  27.99; ppl: 38.44; xent: 3.65; lr: 0.00075; 1572/1563 tok/s;   1325 sec
[2020-01-22 09:42:50,708 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-22 09:42:50,733 INFO] number of examples: 3000
[2020-01-22 09:42:59,886 INFO] Validation perplexity: 2447.48
[2020-01-22 09:42:59,886 INFO] Validation accuracy: 12.7153
[2020-01-22 09:43:00,112 INFO] Saving checkpoint /tmp/extra_step_5000.pt
[2020-01-22 09:44:33,433 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 09:44:33,569 INFO] number of examples: 10000
[2020-01-22 09:46:51,247 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 09:46:51,384 INFO] number of examples: 10000
[2020-01-22 09:47:19,474 INFO] Step 6000/20000; acc:  32.12; ppl: 29.85; xent: 3.40; lr: 0.00091; 1563/1555 tok/s;   1594 sec
[2020-01-22 09:47:19,476 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-22 09:47:19,500 INFO] number of examples: 3000
[2020-01-22 18:34:00,366 INFO]  * src vocab size = 24997
[2020-01-22 18:34:00,379 INFO]  * tgt vocab size = 35820
[2020-01-22 18:34:00,380 INFO] Building model...
[2020-01-22 18:34:11,043 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(24997, 512, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1)
        )
      )
    )
    (transformer): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
    )
    (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(35820, 512, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1)
        )
      )
    )
    (transformer_layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (4): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (5): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
    )
    (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
  )
  (generator): Sequential(
    (0): Linear(in_features=512, out_features=35820, bias=True)
    (1): Cast()
    (2): LogSoftmax()
  )
)
[2020-01-22 18:34:11,049 INFO] encoder: 22587192
[2020-01-22 18:34:11,050 INFO] decoder: 52814116
[2020-01-22 18:34:11,051 INFO] * number of parameters: 75401308
[2020-01-22 18:34:11,058 INFO] Starting training on GPU: [0]
[2020-01-22 18:34:11,059 INFO] Start training loop and validate every 1000 steps...
[2020-01-22 18:34:11,059 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 18:34:11,230 INFO] number of examples: 10000
[2020-01-22 18:36:19,604 INFO] Saving checkpoint saved_model_step_500.pt
[2020-01-22 18:36:31,381 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 18:36:31,552 INFO] number of examples: 10000
[2020-01-22 18:38:32,004 INFO] Step 1000/20000; acc:  10.33; ppl: 862.08; xent: 6.76; lr: 0.00015; 1613/1604 tok/s;    261 sec
[2020-01-22 18:38:32,007 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-22 18:38:32,064 INFO] number of examples: 3000
[2020-01-22 18:38:41,226 INFO] Validation perplexity: 1334.64
[2020-01-22 18:38:41,227 INFO] Validation accuracy: 13.6849
[2020-01-22 18:38:41,445 INFO] Saving checkpoint saved_model_step_1000.pt
[2020-01-22 18:39:02,639 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 18:39:02,812 INFO] number of examples: 10000
[2020-01-22 18:40:53,057 INFO] Saving checkpoint saved_model_step_1500.pt
[2020-01-22 18:41:22,626 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 18:41:22,813 INFO] number of examples: 10000
[2020-01-22 18:43:03,606 INFO] Step 2000/20000; acc:  17.05; ppl: 218.82; xent: 5.39; lr: 0.00030; 1547/1540 tok/s;    533 sec
[2020-01-22 18:43:03,609 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-22 18:43:03,661 INFO] number of examples: 3000
[2020-01-22 18:43:12,736 INFO] Validation perplexity: 1053.49
[2020-01-22 18:43:12,737 INFO] Validation accuracy: 14.3399
[2020-01-22 18:43:12,958 INFO] Saving checkpoint saved_model_step_2000.pt
[2020-01-22 18:43:52,472 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 18:43:52,653 INFO] number of examples: 10000
[2020-01-22 19:16:33,920 INFO]  * src vocab size = 24997
[2020-01-22 19:16:33,928 INFO]  * tgt vocab size = 35820
[2020-01-22 19:16:33,929 INFO] Building model...
[2020-01-22 19:16:37,236 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(24997, 512, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1)
        )
      )
    )
    (transformer): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
    )
    (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(35820, 512, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1)
        )
      )
    )
    (transformer_layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (4): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (5): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
    )
    (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
  )
  (generator): Sequential(
    (0): Linear(in_features=512, out_features=35820, bias=True)
    (1): Cast()
    (2): LogSoftmax()
  )
)
[2020-01-22 19:16:37,244 INFO] encoder: 22587192
[2020-01-22 19:16:37,245 INFO] decoder: 52814116
[2020-01-22 19:16:37,246 INFO] * number of parameters: 75401308
[2020-01-22 19:16:37,274 INFO] Starting training on GPU: [0]
[2020-01-22 19:16:37,276 INFO] Start training loop and validate every 1000 steps...
[2020-01-22 19:16:37,277 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 19:16:37,407 INFO] number of examples: 10000
[2020-01-22 19:18:57,832 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 19:18:57,979 INFO] number of examples: 10000
[2020-01-22 19:21:00,721 INFO] Step 1000/20000; acc:  10.55; ppl: 859.66; xent: 6.76; lr: 0.00015; 1595/1590 tok/s;    263 sec
[2020-01-22 19:21:00,724 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-22 19:21:00,782 INFO] number of examples: 3000
[2020-01-22 19:21:10,061 INFO] Validation perplexity: 1406.31
[2020-01-22 19:21:10,062 INFO] Validation accuracy: 12.5974
[2020-01-22 19:21:10,292 INFO] Saving checkpoint saved_model/transformer_step_1000.pt
[2020-01-22 19:21:32,114 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 19:21:32,194 INFO] number of examples: 10000
[2020-01-22 19:23:51,765 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 19:23:51,917 INFO] number of examples: 10000
[2020-01-22 19:25:33,428 INFO] Step 2000/20000; acc:  16.92; ppl: 222.63; xent: 5.41; lr: 0.00030; 1541/1534 tok/s;    536 sec
[2020-01-22 19:25:33,431 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-22 19:25:33,460 INFO] number of examples: 3000
[2020-01-22 19:25:42,615 INFO] Validation perplexity: 1131.44
[2020-01-22 19:25:42,616 INFO] Validation accuracy: 13.2309
[2020-01-22 19:25:42,841 INFO] Saving checkpoint saved_model/transformer_step_2000.pt
[2020-01-22 19:26:22,345 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 19:26:22,500 INFO] number of examples: 10000
[2020-01-22 19:28:41,118 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 19:28:41,265 INFO] number of examples: 10000
[2020-01-22 19:30:05,265 INFO] Step 3000/20000; acc:  20.85; ppl: 106.87; xent: 4.67; lr: 0.00045; 1548/1538 tok/s;    808 sec
[2020-01-22 19:30:05,268 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-22 19:30:05,298 INFO] number of examples: 3000
[2020-01-22 19:30:14,390 INFO] Validation perplexity: 1470.29
[2020-01-22 19:30:14,391 INFO] Validation accuracy: 13.4814
[2020-01-22 19:30:14,613 INFO] Saving checkpoint saved_model/transformer_step_3000.pt
[2020-01-22 19:31:12,314 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 19:31:12,464 INFO] number of examples: 10000
[2020-01-22 19:33:30,869 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 19:33:31,023 INFO] number of examples: 10000
[2020-01-22 19:34:35,851 INFO] Step 4000/20000; acc:  24.59; ppl: 58.58; xent: 4.07; lr: 0.00060; 1554/1547 tok/s;   1079 sec
[2020-01-22 19:34:35,853 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-22 19:34:35,889 INFO] number of examples: 3000
[2020-01-22 19:34:45,413 INFO] Validation perplexity: 1452.8
[2020-01-22 19:34:45,414 INFO] Validation accuracy: 13.9421
[2020-01-22 19:34:45,652 INFO] Saving checkpoint saved_model/transformer_step_4000.pt
[2020-01-22 19:36:02,021 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 19:36:02,170 INFO] number of examples: 10000
[2020-01-22 19:38:20,578 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 19:38:20,734 INFO] number of examples: 10000
[2020-01-22 19:39:06,914 INFO] Step 5000/20000; acc:  28.64; ppl: 36.44; xent: 3.60; lr: 0.00075; 1551/1544 tok/s;   1350 sec
[2020-01-22 19:39:06,916 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-22 19:39:06,945 INFO] number of examples: 3000
[2020-01-22 19:39:16,044 INFO] Validation perplexity: 2374
[2020-01-22 19:39:16,045 INFO] Validation accuracy: 12.414
[2020-01-22 19:39:16,273 INFO] Saving checkpoint saved_model/transformer_step_5000.pt
[2020-01-22 19:40:52,349 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 19:40:52,508 INFO] number of examples: 10000
[2020-01-22 19:43:10,141 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 19:43:10,295 INFO] number of examples: 10000
[2020-01-22 19:43:38,835 INFO] Step 6000/20000; acc:  31.76; ppl: 30.37; xent: 3.41; lr: 0.00091; 1545/1536 tok/s;   1622 sec
[2020-01-22 19:43:38,838 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-22 19:43:38,870 INFO] number of examples: 3000
[2020-01-22 19:43:48,009 INFO] Validation perplexity: 2917.5
[2020-01-22 19:43:48,010 INFO] Validation accuracy: 11.9197
[2020-01-22 19:43:48,232 INFO] Saving checkpoint saved_model/transformer_step_6000.pt
[2020-01-22 19:45:41,501 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 19:45:41,659 INFO] number of examples: 10000
[2020-01-22 19:47:59,982 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 19:48:00,138 INFO] number of examples: 10000
[2020-01-22 19:48:10,424 INFO] Step 7000/20000; acc:  28.94; ppl: 38.21; xent: 3.64; lr: 0.00106; 1548/1539 tok/s;   1893 sec
[2020-01-22 19:48:10,426 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-22 19:48:10,462 INFO] number of examples: 3000
[2020-01-22 19:48:19,711 INFO] Validation perplexity: 2316.6
[2020-01-22 19:48:19,712 INFO] Validation accuracy: 12.4126
[2020-01-22 19:48:19,952 INFO] Saving checkpoint saved_model/transformer_step_7000.pt
[2020-01-22 19:50:36,412 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 19:50:36,605 INFO] number of examples: 10000
[2020-01-22 19:52:47,071 INFO] Step 8000/20000; acc:  27.99; ppl: 41.58; xent: 3.73; lr: 0.00099; 1516/1513 tok/s;   2170 sec
[2020-01-22 19:52:47,073 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-22 19:52:47,100 INFO] number of examples: 3000
[2020-01-22 19:52:56,986 INFO] Validation perplexity: 2780.87
[2020-01-22 19:52:56,987 INFO] Validation accuracy: 11.5675
[2020-01-22 19:52:57,220 INFO] Saving checkpoint saved_model/transformer_step_8000.pt
[2020-01-22 19:53:11,746 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 19:53:11,838 INFO] number of examples: 10000
[2020-01-22 19:55:32,230 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 19:55:32,378 INFO] number of examples: 10000
[2020-01-22 19:57:23,904 INFO] Step 9000/20000; acc:  26.83; ppl: 46.19; xent: 3.83; lr: 0.00093; 1519/1512 tok/s;   2447 sec
[2020-01-22 19:57:23,906 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-22 19:57:23,935 INFO] number of examples: 3000
[2020-01-22 19:57:33,015 INFO] Validation perplexity: 2297.37
[2020-01-22 19:57:33,016 INFO] Validation accuracy: 11.9465
[2020-01-22 19:57:33,239 INFO] Saving checkpoint saved_model/transformer_step_9000.pt
[2020-01-22 19:58:04,242 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 19:58:04,316 INFO] number of examples: 10000
[2020-01-22 20:00:24,174 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 20:00:24,330 INFO] number of examples: 10000
[2020-01-22 20:02:00,940 INFO] Step 10000/20000; acc:  28.01; ppl: 42.87; xent: 3.76; lr: 0.00088; 1518/1510 tok/s;   2724 sec
[2020-01-22 20:02:01,078 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-22 20:02:01,112 INFO] number of examples: 3000
[2020-01-22 20:02:10,220 INFO] Validation perplexity: 2537.26
[2020-01-22 20:02:10,221 INFO] Validation accuracy: 11.9747
[2020-01-22 20:02:10,449 INFO] Saving checkpoint saved_model/transformer_step_10000.pt
[2020-01-22 20:03:02,114 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 20:03:02,334 INFO] number of examples: 10000
[2020-01-22 20:05:20,560 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 20:05:20,734 INFO] number of examples: 10000
[2020-01-22 20:06:35,608 INFO] Step 11000/20000; acc:  29.16; ppl: 39.66; xent: 3.68; lr: 0.00084; 1533/1525 tok/s;   2998 sec
[2020-01-22 20:06:35,611 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-22 20:06:35,642 INFO] number of examples: 3000
[2020-01-22 20:06:44,749 INFO] Validation perplexity: 2844.19
[2020-01-22 20:06:44,750 INFO] Validation accuracy: 11.8675
[2020-01-22 20:06:44,977 INFO] Saving checkpoint saved_model/transformer_step_11000.pt
[2020-01-22 20:07:55,159 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 20:07:55,320 INFO] number of examples: 10000
[2020-01-22 20:10:13,577 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 20:10:13,738 INFO] number of examples: 10000
[2020-01-22 20:11:09,784 INFO] Step 12000/20000; acc:  30.33; ppl: 36.70; xent: 3.60; lr: 0.00081; 1533/1525 tok/s;   3273 sec
[2020-01-22 20:11:09,786 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-22 20:11:09,819 INFO] number of examples: 3000
[2020-01-22 20:11:18,918 INFO] Validation perplexity: 2900.85
[2020-01-22 20:11:18,920 INFO] Validation accuracy: 11.6439
[2020-01-22 20:11:19,138 INFO] Saving checkpoint saved_model/transformer_step_12000.pt
[2020-01-22 20:12:45,850 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 20:12:46,014 INFO] number of examples: 10000
[2020-01-22 20:15:03,813 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 20:15:03,966 INFO] number of examples: 10000
[2020-01-22 20:15:42,491 INFO] Step 13000/20000; acc:  31.69; ppl: 33.22; xent: 3.50; lr: 0.00078; 1542/1533 tok/s;   3545 sec
[2020-01-22 20:15:42,493 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-22 20:15:42,522 INFO] number of examples: 3000
[2020-01-22 20:15:51,633 INFO] Validation perplexity: 2753.89
[2020-01-22 20:15:51,633 INFO] Validation accuracy: 12.1769
[2020-01-22 20:15:51,864 INFO] Saving checkpoint saved_model/transformer_step_13000.pt
[2020-01-22 20:17:36,049 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 20:17:36,203 INFO] number of examples: 10000
[2020-01-22 20:19:53,898 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 20:19:54,059 INFO] number of examples: 10000
[2020-01-22 20:20:14,248 INFO] Step 14000/20000; acc:  30.79; ppl: 35.28; xent: 3.56; lr: 0.00075; 1546/1537 tok/s;   3817 sec
[2020-01-22 20:20:14,251 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-22 20:20:14,286 INFO] number of examples: 3000
[2020-01-22 20:20:23,379 INFO] Validation perplexity: 2999.49
[2020-01-22 20:20:23,380 INFO] Validation accuracy: 12.0617
[2020-01-22 20:20:23,610 INFO] Saving checkpoint saved_model/transformer_step_14000.pt
[2020-01-22 20:22:25,047 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 20:22:25,217 INFO] number of examples: 10000
[2020-01-22 20:24:42,251 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 20:24:42,407 INFO] number of examples: 10000
[2020-01-22 20:24:44,000 INFO] Step 15000/20000; acc:  31.46; ppl: 33.86; xent: 3.52; lr: 0.00072; 1558/1551 tok/s;   4087 sec
[2020-01-22 20:24:44,002 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-22 20:24:44,033 INFO] number of examples: 3000
[2020-01-22 20:24:53,119 INFO] Validation perplexity: 3155.76
[2020-01-22 20:24:53,120 INFO] Validation accuracy: 11.8314
[2020-01-22 20:24:53,346 INFO] Saving checkpoint saved_model/transformer_step_15000.pt
[2020-01-22 20:27:13,991 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 20:27:14,154 INFO] number of examples: 10000
[2020-01-22 20:29:15,292 INFO] Step 16000/20000; acc:  31.69; ppl: 33.28; xent: 3.50; lr: 0.00070; 1548/1544 tok/s;   4358 sec
[2020-01-22 20:29:15,296 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-22 20:29:15,338 INFO] number of examples: 3000
[2020-01-22 20:29:24,441 INFO] Validation perplexity: 3126.94
[2020-01-22 20:29:24,442 INFO] Validation accuracy: 11.6867
[2020-01-22 20:29:24,665 INFO] Saving checkpoint saved_model/transformer_step_16000.pt
[2020-01-22 20:29:45,318 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 20:29:45,398 INFO] number of examples: 10000
[2020-01-22 20:32:02,946 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 20:32:03,107 INFO] number of examples: 10000
[2020-01-22 20:33:45,952 INFO] Step 17000/20000; acc:  31.63; ppl: 33.50; xent: 3.51; lr: 0.00068; 1553/1545 tok/s;   4629 sec
[2020-01-22 20:33:45,955 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-22 20:33:45,994 INFO] number of examples: 3000
[2020-01-22 20:33:55,098 INFO] Validation perplexity: 3213.41
[2020-01-22 20:33:55,099 INFO] Validation accuracy: 11.2608
[2020-01-22 20:33:55,327 INFO] Saving checkpoint saved_model/transformer_step_17000.pt
[2020-01-22 20:34:33,665 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 20:34:33,748 INFO] number of examples: 10000
[2020-01-22 20:36:51,625 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 20:36:51,780 INFO] number of examples: 10000
[2020-01-22 20:38:17,365 INFO] Step 18000/20000; acc:  33.14; ppl: 30.20; xent: 3.41; lr: 0.00066; 1550/1541 tok/s;   4900 sec
[2020-01-22 20:38:17,367 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-22 20:38:17,396 INFO] number of examples: 3000
[2020-01-22 20:38:26,492 INFO] Validation perplexity: 2998.91
[2020-01-22 20:38:26,494 INFO] Validation accuracy: 12.3282
[2020-01-22 20:38:26,733 INFO] Saving checkpoint saved_model/transformer_step_18000.pt
[2020-01-22 20:39:23,030 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 20:39:23,196 INFO] number of examples: 10000
[2020-01-22 20:41:40,814 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 20:41:40,975 INFO] number of examples: 10000
[2020-01-22 20:42:48,218 INFO] Step 19000/20000; acc:  32.73; ppl: 30.84; xent: 3.43; lr: 0.00064; 1553/1546 tok/s;   5171 sec
[2020-01-22 20:42:48,220 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-22 20:42:48,255 INFO] number of examples: 3000
[2020-01-22 20:42:57,359 INFO] Validation perplexity: 3195.44
[2020-01-22 20:42:57,360 INFO] Validation accuracy: 11.7041
[2020-01-22 20:42:57,586 INFO] Saving checkpoint saved_model/transformer_step_19000.pt
[2020-01-22 20:44:12,512 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 20:44:12,672 INFO] number of examples: 10000
[2020-01-22 20:46:31,338 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 20:46:31,502 INFO] number of examples: 10000
[2020-01-22 20:47:20,707 INFO] Step 20000/20000; acc:  33.16; ppl: 29.94; xent: 3.40; lr: 0.00062; 1543/1535 tok/s;   5443 sec
[2020-01-22 20:47:20,710 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-22 20:47:20,744 INFO] number of examples: 3000
[2020-01-22 20:47:29,874 INFO] Validation perplexity: 2876.01
[2020-01-22 20:47:29,875 INFO] Validation accuracy: 11.98
[2020-01-22 20:47:30,105 INFO] Saving checkpoint saved_model/transformer_step_20000.pt
[2020-01-22 22:12:19,739 INFO] Loading checkpoint from saved_model/transformer
[2020-01-22 22:15:53,597 INFO]  * src vocab size = 24997
[2020-01-22 22:15:53,598 INFO]  * tgt vocab size = 35820
[2020-01-22 22:15:53,598 INFO] Building model...
[2020-01-22 22:15:56,811 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(24997, 512, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1)
        )
      )
    )
    (transformer): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
    )
    (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(35820, 512, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1)
        )
      )
    )
    (transformer_layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (4): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (5): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
    )
    (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
  )
  (generator): Sequential(
    (0): Linear(in_features=512, out_features=35820, bias=True)
    (1): Cast()
    (2): LogSoftmax()
  )
)
[2020-01-22 22:15:56,818 INFO] encoder: 22587192
[2020-01-22 22:15:56,819 INFO] decoder: 52814116
[2020-01-22 22:15:56,820 INFO] * number of parameters: 75401308
[2020-01-22 22:15:56,825 INFO] Starting training on GPU: [0]
[2020-01-22 22:15:56,826 INFO] Start training loop and validate every 1000 steps...
[2020-01-22 22:15:56,826 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 22:15:56,940 INFO] number of examples: 10000
[2020-01-22 22:19:44,888 INFO] Loading checkpoint from /home/denis/Program/AI0/AI-General/v2/OpenNMT-py-master/saved_model/transformer_step_20000.pt
[2020-01-22 22:19:45,265 INFO] Loading vocab from checkpoint at /home/denis/Program/AI0/AI-General/v2/OpenNMT-py-master/saved_model/transformer_step_20000.pt.
[2020-01-22 22:19:45,266 INFO]  * src vocab size = 24997
[2020-01-22 22:19:45,266 INFO]  * tgt vocab size = 35820
[2020-01-22 22:19:45,267 INFO] Building model...
[2020-01-22 22:20:05,621 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(24997, 512, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1)
        )
      )
    )
    (transformer): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
    )
    (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(35820, 512, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1)
        )
      )
    )
    (transformer_layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (4): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (5): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
    )
    (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
  )
  (generator): Sequential(
    (0): Linear(in_features=512, out_features=35820, bias=True)
    (1): Cast()
    (2): LogSoftmax()
  )
)
[2020-01-22 22:20:05,777 INFO] encoder: 22587192
[2020-01-22 22:20:05,778 INFO] decoder: 52814116
[2020-01-22 22:20:05,779 INFO] * number of parameters: 75401308
[2020-01-22 22:20:28,420 INFO] Starting training on GPU: [0]
[2020-01-22 22:20:28,853 INFO] Start training loop and validate every 1000 steps...
[2020-01-22 22:20:28,855 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 22:20:29,686 INFO] number of examples: 10000
[2020-01-22 22:20:32,261 INFO] Saving checkpoint saved_model/transformer_step_20001.pt
[2020-01-22 22:26:07,541 INFO] Loading checkpoint from /home/denis/Program/AI0/AI-General/v2/OpenNMT-py-master/saved_model/transformer_step_20000.pt
[2020-01-22 22:26:07,941 INFO] Loading vocab from checkpoint at /home/denis/Program/AI0/AI-General/v2/OpenNMT-py-master/saved_model/transformer_step_20000.pt.
[2020-01-22 22:26:07,942 INFO]  * src vocab size = 24997
[2020-01-22 22:26:07,943 INFO]  * tgt vocab size = 35820
[2020-01-22 22:26:07,944 INFO] Building model...
[2020-01-22 22:26:33,545 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(24997, 512, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1)
        )
      )
    )
    (transformer): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
    )
    (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(35820, 512, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1)
        )
      )
    )
    (transformer_layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (4): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
      (5): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
    )
    (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
  )
  (generator): Sequential(
    (0): Linear(in_features=512, out_features=35820, bias=True)
    (1): Cast()
    (2): LogSoftmax()
  )
)
[2020-01-22 22:26:33,777 INFO] encoder: 22587192
[2020-01-22 22:26:33,779 INFO] decoder: 52814116
[2020-01-22 22:26:33,780 INFO] * number of parameters: 75401308
[2020-01-22 22:26:38,039 INFO] Starting training on GPU: [0]
[2020-01-22 22:26:38,060 INFO] Start training loop and validate every 1000 steps...
[2020-01-22 22:26:38,062 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 22:26:38,485 INFO] number of examples: 10000
[2020-01-22 22:28:59,455 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 22:28:59,739 INFO] number of examples: 10000
[2020-01-22 22:30:58,839 INFO] Step 21000/40000; acc:  29.66; ppl: 37.87; xent: 3.63; lr: 0.00061; 1611/1605 tok/s;    261 sec
[2020-01-22 22:30:58,841 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-22 22:30:58,961 INFO] number of examples: 3000
[2020-01-22 22:31:08,163 INFO] Validation perplexity: 2782.1
[2020-01-22 22:31:08,164 INFO] Validation accuracy: 11.9747
[2020-01-22 22:31:08,386 INFO] Saving checkpoint saved_model/transformer_step_21000.pt
[2020-01-22 22:31:34,392 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 22:31:34,477 INFO] number of examples: 10000
[2020-01-22 22:33:51,791 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 22:33:51,945 INFO] number of examples: 10000
[2020-01-22 22:35:32,955 INFO] Step 22000/40000; acc:  31.88; ppl: 33.66; xent: 3.52; lr: 0.00060; 1533/1525 tok/s;    535 sec
[2020-01-22 22:35:32,957 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-22 22:35:33,098 INFO] number of examples: 3000
[2020-01-22 22:35:42,288 INFO] Validation perplexity: 2780.09
[2020-01-22 22:35:42,289 INFO] Validation accuracy: 12.1769
[2020-01-22 22:35:42,507 INFO] Saving checkpoint saved_model/transformer_step_22000.pt
[2020-01-22 22:36:26,214 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 22:36:26,320 INFO] number of examples: 10000
[2020-01-22 22:38:44,879 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 22:38:45,028 INFO] number of examples: 10000
[2020-01-22 22:40:08,374 INFO] Step 23000/40000; acc:  34.05; ppl: 29.06; xent: 3.37; lr: 0.00058; 1528/1517 tok/s;    810 sec
[2020-01-22 22:40:08,376 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-22 22:40:08,515 INFO] number of examples: 3000
[2020-01-22 22:40:17,612 INFO] Validation perplexity: 2843.89
[2020-01-22 22:40:17,613 INFO] Validation accuracy: 11.9867
[2020-01-22 22:40:17,836 INFO] Saving checkpoint saved_model/transformer_step_23000.pt
[2020-01-22 22:41:20,235 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 22:41:20,311 INFO] number of examples: 10000
[2020-01-22 22:43:38,838 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 22:43:38,990 INFO] number of examples: 10000
[2020-01-22 22:44:42,852 INFO] Step 24000/40000; acc:  34.53; ppl: 27.90; xent: 3.33; lr: 0.00057; 1532/1523 tok/s;   1085 sec
[2020-01-22 22:44:42,855 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-22 22:44:42,907 INFO] number of examples: 3000
[2020-01-22 22:44:52,062 INFO] Validation perplexity: 2859.66
[2020-01-22 22:44:52,063 INFO] Validation accuracy: 11.7336
[2020-01-22 22:44:52,279 INFO] Saving checkpoint saved_model/transformer_step_24000.pt
[2020-01-22 22:46:14,354 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-22 22:46:14,450 INFO] number of examples: 10000
[2020-01-23 14:58:02,470 INFO] Loading checkpoint from /home/denis/Program/AI0/AI-General/v2/OpenNMT-py-master/saved_model/transformer_step_20000.pt
[2020-01-23 14:58:02,972 INFO] Loading vocab from checkpoint at /home/denis/Program/AI0/AI-General/v2/OpenNMT-py-master/saved_model/transformer_step_20000.pt.
[2020-01-23 14:58:02,973 INFO]  * src vocab size = 24997
[2020-01-23 14:58:02,974 INFO]  * tgt vocab size = 35820
[2020-01-23 14:58:02,974 INFO] Building model...
[2020-01-23 15:02:01,965 INFO]  * src vocab size = 24997
[2020-01-23 15:02:01,991 INFO]  * tgt vocab size = 35820
[2020-01-23 15:02:01,993 INFO] Building model...
[2020-01-23 15:02:10,376 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(24997, 512, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1)
        )
      )
    )
    (transformer): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
    )
    (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(35820, 512, padding_idx=1)
        )
        (pe): PositionalEncoding(
          (dropout): Dropout(p=0.1)
        )
      )
    )
    (transformer_layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=512, out_features=512, bias=True)
          (linear_values): Linear(in_features=512, out_features=512, bias=True)
          (linear_query): Linear(in_features=512, out_features=512, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=512, out_features=512, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=512, out_features=564, bias=True)
          (w_2): Linear(in_features=564, out_features=512, bias=True)
          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (relu): ReLU()
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
        (drop): Dropout(p=0.1)
      )
    )
    (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)
  )
  (generator): Sequential(
    (0): Linear(in_features=512, out_features=35820, bias=True)
    (1): Cast()
    (2): LogSoftmax()
  )
)
[2020-01-23 15:02:10,379 INFO] encoder: 14430772
[2020-01-23 15:02:10,379 INFO] decoder: 39399456
[2020-01-23 15:02:10,380 INFO] * number of parameters: 53830228
[2020-01-23 15:02:10,383 INFO] Starting training on GPU: [0]
[2020-01-23 15:02:10,384 INFO] Start training loop and validate every 1000 steps...
[2020-01-23 15:02:10,385 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-23 15:02:10,528 INFO] number of examples: 10000
[2020-01-23 15:03:46,799 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-23 15:03:46,941 INFO] number of examples: 10000
[2020-01-23 15:05:09,833 INFO] Step 1000/40000; acc:  12.91; ppl: 445.84; xent: 6.10; lr: 0.00151; 2341/2330 tok/s;    179 sec
[2020-01-23 15:05:09,835 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-23 15:05:09,884 INFO] number of examples: 3000
[2020-01-23 15:05:14,015 INFO] Validation perplexity: 1368.42
[2020-01-23 15:05:14,016 INFO] Validation accuracy: 12.6242
[2020-01-23 15:05:14,248 INFO] Saving checkpoint saved_model/transformer_step_1000.pt
[2020-01-23 15:05:30,611 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-23 15:05:30,756 INFO] number of examples: 10000
[2020-01-23 15:07:06,224 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-23 15:07:06,382 INFO] number of examples: 10000
[2020-01-23 15:08:16,086 INFO] Step 2000/40000; acc:  19.91; ppl: 119.90; xent: 4.79; lr: 0.00302; 2257/2245 tok/s;    366 sec
[2020-01-23 15:08:16,088 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-23 15:08:16,121 INFO] number of examples: 3000
[2020-01-23 15:08:20,169 INFO] Validation perplexity: 1902
[2020-01-23 15:08:20,170 INFO] Validation accuracy: 12.2492
[2020-01-23 15:08:20,392 INFO] Saving checkpoint saved_model/transformer_step_2000.pt
[2020-01-23 15:08:50,998 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-23 15:08:51,149 INFO] number of examples: 10000
[2020-01-23 15:10:26,638 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-23 15:10:26,791 INFO] number of examples: 10000
[2020-01-23 15:11:23,968 INFO] Step 3000/40000; acc:  24.47; ppl: 68.54; xent: 4.23; lr: 0.00453; 2237/2229 tok/s;    554 sec
[2020-01-23 15:11:23,970 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-23 15:11:24,000 INFO] number of examples: 3000
[2020-01-23 15:11:28,053 INFO] Validation perplexity: 2478.24
[2020-01-23 15:11:28,054 INFO] Validation accuracy: 10.3769
[2020-01-23 15:11:28,279 INFO] Saving checkpoint saved_model/transformer_step_3000.pt
[2020-01-23 15:12:12,229 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-23 15:12:12,388 INFO] number of examples: 10000
[2020-01-23 15:13:47,607 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-23 15:13:47,768 INFO] number of examples: 10000
[2020-01-23 15:14:33,022 INFO] Step 4000/40000; acc:  26.29; ppl: 55.64; xent: 4.02; lr: 0.00604; 2222/2215 tok/s;    743 sec
[2020-01-23 15:14:33,024 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-23 15:14:33,054 INFO] number of examples: 3000
[2020-01-23 15:14:37,104 INFO] Validation perplexity: 2541.51
[2020-01-23 15:14:37,106 INFO] Validation accuracy: 10.9086
[2020-01-23 15:14:37,327 INFO] Saving checkpoint saved_model/transformer_step_4000.pt
[2020-01-23 15:15:32,673 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-23 15:15:32,833 INFO] number of examples: 10000
[2020-01-23 15:17:08,554 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-23 15:17:08,719 INFO] number of examples: 10000
[2020-01-23 15:17:41,770 INFO] Step 5000/40000; acc:  27.09; ppl: 49.30; xent: 3.90; lr: 0.00755; 2225/2216 tok/s;    931 sec
[2020-01-23 15:17:41,772 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-23 15:17:41,806 INFO] number of examples: 3000
[2020-01-23 15:17:46,131 INFO] Validation perplexity: 3101.71
[2020-01-23 15:17:46,132 INFO] Validation accuracy: 9.75277
[2020-01-23 15:17:46,367 INFO] Saving checkpoint saved_model/transformer_step_5000.pt
[2020-01-23 15:18:59,430 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-23 15:18:59,596 INFO] number of examples: 10000
[2020-01-23 15:20:41,376 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-23 15:20:41,551 INFO] number of examples: 10000
[2020-01-23 15:21:02,741 INFO] Step 6000/40000; acc:  26.65; ppl: 51.60; xent: 3.94; lr: 0.00906; 2093/2081 tok/s;   1132 sec
[2020-01-23 15:21:02,744 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-23 15:21:02,772 INFO] number of examples: 3000
[2020-01-23 15:21:07,082 INFO] Validation perplexity: 2703.79
[2020-01-23 15:21:07,084 INFO] Validation accuracy: 10.8135
[2020-01-23 15:21:07,316 INFO] Saving checkpoint saved_model/transformer_step_6000.pt
[2020-01-23 15:22:31,082 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-23 15:22:31,254 INFO] number of examples: 10000
[2020-01-23 15:24:15,977 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-23 15:24:16,146 INFO] number of examples: 10000
[2020-01-23 15:24:24,364 INFO] Step 7000/40000; acc:  26.21; ppl: 55.18; xent: 4.01; lr: 0.01056; 2087/2074 tok/s;   1334 sec
[2020-01-23 15:24:24,366 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-23 15:24:24,399 INFO] number of examples: 3000
[2020-01-23 15:24:28,850 INFO] Validation perplexity: 2729.13
[2020-01-23 15:24:28,852 INFO] Validation accuracy: 10.409
[2020-01-23 15:24:29,079 INFO] Saving checkpoint saved_model/transformer_step_7000.pt
[2020-01-23 15:26:09,669 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-23 15:26:09,843 INFO] number of examples: 10000
[2020-01-23 15:27:48,228 INFO] Step 8000/40000; acc:  26.55; ppl: 54.47; xent: 4.00; lr: 0.00988; 2063/2050 tok/s;   1538 sec
[2020-01-23 15:27:48,229 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-23 15:27:48,263 INFO] number of examples: 3000
[2020-01-23 15:27:52,806 INFO] Validation perplexity: 2703.14
[2020-01-23 15:27:52,807 INFO] Validation accuracy: 10.2724
[2020-01-23 15:27:53,035 INFO] Saving checkpoint saved_model/transformer_step_8000.pt
[2020-01-23 15:28:04,626 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-23 15:28:04,817 INFO] number of examples: 10000
[2020-01-23 15:29:49,901 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-23 15:29:50,071 INFO] number of examples: 10000
[2020-01-23 15:31:14,317 INFO] Step 9000/40000; acc:  27.68; ppl: 50.11; xent: 3.91; lr: 0.00932; 2038/2031 tok/s;   1744 sec
[2020-01-23 15:31:14,319 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-23 15:31:14,351 INFO] number of examples: 3000
[2020-01-23 15:31:18,864 INFO] Validation perplexity: 4324.88
[2020-01-23 15:31:18,865 INFO] Validation accuracy: 10.1304
[2020-01-23 15:31:19,093 INFO] Saving checkpoint saved_model/transformer_step_9000.pt
[2020-01-23 15:31:44,447 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-23 15:31:44,622 INFO] number of examples: 10000
[2020-01-23 15:33:27,099 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-23 15:33:27,274 INFO] number of examples: 10000
[2020-01-23 15:34:37,714 INFO] Step 10000/40000; acc:  28.93; ppl: 43.05; xent: 3.76; lr: 0.00884; 2067/2054 tok/s;   1947 sec
[2020-01-23 15:34:37,716 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-23 15:34:37,747 INFO] number of examples: 3000
[2020-01-23 15:34:42,244 INFO] Validation perplexity: 4382.5
[2020-01-23 15:34:42,245 INFO] Validation accuracy: 10.2296
[2020-01-23 15:34:42,473 INFO] Saving checkpoint saved_model/transformer_step_10000.pt
[2020-01-23 15:35:21,997 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-23 15:35:22,179 INFO] number of examples: 10000
[2020-01-23 15:37:08,052 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-23 15:37:08,232 INFO] number of examples: 10000
[2020-01-23 15:38:04,991 INFO] Step 11000/40000; acc:  29.77; ppl: 38.17; xent: 3.64; lr: 0.00843; 2027/2022 tok/s;   2155 sec
[2020-01-23 15:38:04,993 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-23 15:38:05,026 INFO] number of examples: 3000
[2020-01-23 15:38:09,516 INFO] Validation perplexity: 3103.27
[2020-01-23 15:38:09,517 INFO] Validation accuracy: 10.1479
[2020-01-23 15:38:09,746 INFO] Saving checkpoint saved_model/transformer_step_11000.pt
[2020-01-23 15:39:02,340 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-23 15:39:02,516 INFO] number of examples: 10000
[2020-01-23 15:40:48,059 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-23 15:40:48,238 INFO] number of examples: 10000
[2020-01-23 15:41:31,301 INFO] Step 12000/40000; acc:  30.09; ppl: 35.49; xent: 3.57; lr: 0.00807; 2035/2026 tok/s;   2361 sec
[2020-01-23 15:41:31,303 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-23 15:41:31,333 INFO] number of examples: 3000
[2020-01-23 15:41:35,819 INFO] Validation perplexity: 4488.98
[2020-01-23 15:41:35,820 INFO] Validation accuracy: 9.78357
[2020-01-23 15:41:36,051 INFO] Saving checkpoint saved_model/transformer_step_12000.pt
[2020-01-23 15:42:41,239 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-23 15:42:41,426 INFO] number of examples: 10000
[2020-01-23 15:44:19,773 INFO] Loading dataset from data/demo.train.0.pt
[2020-01-23 15:44:19,953 INFO] number of examples: 10000
[2020-01-23 15:44:48,281 INFO] Step 13000/40000; acc:  28.58; ppl: 41.66; xent: 3.73; lr: 0.00775; 2135/2124 tok/s;   2558 sec
[2020-01-23 15:44:48,283 INFO] Loading dataset from data/demo.valid.0.pt
[2020-01-23 15:44:48,315 INFO] number of examples: 3000
[2020-01-23 15:44:52,492 INFO] Validation perplexity: 3021.65
[2020-01-23 15:44:52,493 INFO] Validation accuracy: 10.4157
[2020-01-23 15:44:52,728 INFO] Saving checkpoint saved_model/transformer_step_13000.pt
