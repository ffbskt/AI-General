{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 583,
     "status": "ok",
     "timestamp": 1566885518185,
     "user": {
      "displayName": "Денис Волконский",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCa88QtBa4ugmPsmDvN8iDihIvOioJ15g-G0Qpx=s64",
      "userId": "09425448476864996625"
     },
     "user_tz": -180
    },
    "id": "cSytdP8poSs2",
    "outputId": "50030209-d46e-48eb-f5cc-6acbc35f57c9"
   },
   "outputs": [],
   "source": [
    "# for colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "znp4kWzNoS2L"
   },
   "outputs": [],
   "source": [
    "project_dir = '/content/gdrive/My Drive/ColabNotebooks/AI'\n",
    "import sys\n",
    "sys.path.insert(0, project_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step by step mcts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from models import Model, Trainer\n",
    "from env_test import Env\n",
    "from mcts import MCTS\n",
    "\n",
    "class dotdict(dict):\n",
    "    def __getattr__(self, name):\n",
    "        return self[name]\n",
    "\n",
    "model =Model()# LSTMTagger()#Model()\n",
    "env = Env(1,1)\n",
    "\n",
    "args = dotdict({'cpuct':0.5, 'iters':1000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ii1i ii1i1 0\n",
      "ii1i1 ii1i1i 0\n",
      "1945\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mcts2 = MCTS(env, model, args)\n",
    "val = list(mcts2.sampling())\n",
    "print(len(val))\n",
    "#val = [v for v in val if v.parent and v.parent.times_visited > 2]\n",
    "#print(len(val))\n",
    "t = Trainer(env, batch_size=5)\n",
    "#t.train_model(val, model, batch_size=10, net_iters=300)\n",
    "#examples = deque([], maxlen=1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = t.get_batch(val, batch_size=5)\n",
    "b = t.transform_bach_as_input(batch, model)\n",
    "print(b[0])#'dataX\\n', b[0].shape)#, '\\n rew, prob, result\\n', b[1:])\n",
    "#    print(b[0])\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "#plt.plot(t.loss_backet)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def env_high_dificult(Env, agent, Trainer):\n",
    "    \n",
    "    epoch = iter_lim = 10\n",
    "    stat = {}\n",
    "    ind_dificult = 1\n",
    "    env = Env(1, ind_dificult)\n",
    "    while epoch:\n",
    "        epoch -= 1\n",
    "        print(stat)\n",
    "        if agent.sum_reward > 10:\n",
    "            stat[ind_dificult] = [iter_lim - epoch, agent.sum_reward]\n",
    "            agent.sum_reward = 0\n",
    "            ind_dificult += 1\n",
    "            epoch = iter_lim\n",
    "            env = Env(1, ind_dificult)\n",
    "            agent.env = env\n",
    "        \n",
    "        val = list(agent.sampling())\n",
    "        val = Trainer.clean_unpredict_node(val)\n",
    "        X, yv, yp = get_linear_out(val)\n",
    "        lossb = train_model(X, yv, yp, agent.model, net_iters=500)\n",
    "        plt.plot(lossb)\n",
    "        plt.show()\n",
    "        \n",
    "    return stat\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "mcts2 = MCTS(env, model, args)\n",
    "env_high_dificult(Env, mcts2, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train = {'1o1':[]}#, '1o2':[], '1o3':[]}\n",
    "test = {'1o1':[]}#, '1o2':[], '1o3':[]}\n",
    "for k in train:\n",
    "    env = Env(1,int(k[2]))\n",
    "    mcts2 = MCTS(env, model, args)\n",
    "    X = list(mcts2.sampling())\n",
    "    val = t.clean_unpredict_node(X)\n",
    "    print(len(X), len(val))\n",
    "    train_cur, test_cur = train_test_split(val)\n",
    "    train[k] = train_cur\n",
    "    test[k] = test_cur\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_linear_out(samples):\n",
    "    X, yv, yp, cresult = t.transform_bach_as_input(samples, model)\n",
    "    return X, yv, yp\n",
    "\n",
    "k = '1o1'\n",
    "X, yv, yp = get_linear_out(train[k])\n",
    "Xt, yvt, ypt = get_linear_out(test[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_rew(tr, pr):\n",
    "    return np.sum((tr - pr)**2) / len(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression().fit(X, yv)\n",
    "loss_rew(yvt, reg.predict(Xt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_rew(yvt, model.predict(Xt)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_rew(yvt, np.mean(yv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regr = RandomForestRegressor(max_depth=5, random_state=0, n_estimators=300)#, criterion='mae')\n",
    "regr.fit(X, yv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_rew(yvt, regr.predict(Xt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "clf = KNeighborsRegressor()\n",
    "clf.fit(X, yv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_rew(yvt, clf.predict(Xt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor, nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.cnv1 = nn.Conv1d(1,6,8)\n",
    "        self.fc1 = nn.Linear(18, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.action_prob_out = nn.Linear(64, 8)\n",
    "        #self.val0 = nn.Linear(40, 80)\n",
    "        self.val = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        #x = x.view(-1,17)\n",
    "        #x = self.cnv1(x.view(1, 1,-1))\n",
    "        # print(x.shape)\n",
    "        #x = torch.flatten(x, start_dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        act_prob = F.softmax(self.action_prob_out(x), dim=-1)\n",
    "        #val = F.tanh(self.val(x))\n",
    "        val = self.val(x)\n",
    "        #val_sum = self.val_sum_out(val)\n",
    "\n",
    "        return act_prob, val\n",
    "\n",
    "    def predict(self, x):\n",
    "        self.eval()\n",
    "        #x = Variable(Tensor(x))\n",
    "        act_prob, val = self.forward(x)\n",
    "        return act_prob.data.numpy(), val.data.numpy()\n",
    "\n",
    "\n",
    "def get_batch(nodes_buc, batch_size=20):\n",
    "    \"\"\"remove all nodes that have not history\"\"\"\n",
    "    n = len(nodes_buc)\n",
    "    index = [\n",
    "        np.random.randint(0, n - 1)\n",
    "        for _ in range(batch_size)\n",
    "    ]\n",
    "    #print(len(self.replay), index, [self.replay[i] for i in index]   )\n",
    "    return index#[nodes_buc[i] for i in index]\n",
    "\n",
    "\n",
    "def train_model(Xa,yr,yp, model, batch_size=10, net_iters=200):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.1)#, momentum=0.03, weight_decay=0.1)\n",
    "    loss_backet = []\n",
    "    for i in range(net_iters):\n",
    "        #batch = #self.get_batch(nodes_buc, batch_size=batch_size or self.batch_size)\n",
    "        # print(batch)\n",
    "        ind = get_batch(Xa)\n",
    "\n",
    "        X, real_reward, real_prob = Xa[ind], yr[ind], yp[ind]#self.transform_bach_as_input(batch, model)\n",
    "\n",
    "\n",
    "        #print(i, real_prob.shape)\n",
    "        model.train()\n",
    "        #for x, rr, rp in zip(X, real_reward, real_prob):\n",
    "            #print(xx, rrr,rpp)\n",
    "        optimizer.zero_grad()\n",
    "        #print(X)\n",
    "        p_pred, v_pred = model(X)\n",
    "        # print('pr  ', probability, 'pp  ', p_pred)\n",
    "        val_loss = torch.mean((Variable(Tensor(real_reward)) - v_pred) ** 2)  # , Variable(Tensor([10]))\n",
    "        loss = val_loss - torch.mean(Variable(Tensor(real_prob)) * torch.log(p_pred))\n",
    "        #loss = - torch.mean(Variable(Tensor(real_prob)) * torch.log(p_pred))\n",
    "        #print(loss, rpp, p_pred)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_backet.append(loss.data.numpy())\n",
    "        \n",
    "    return loss_backet\n",
    "\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossb = train_model(X, yv, yp, model, net_iters=500)\n",
    "plt.plot(lossb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import LSTMmodel\n",
    "#from  import LSTMModel, mctsTrainer\n",
    "model = LSTMmodel.LSTMModel(32, 64, 8, 8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = LSTMmodel.mctsTrainer(env, mcts2, batch_size=20)\n",
    "trainer.train_model(train[k], model, net_iters=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trainer.loss_backet)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lstm, _, _, _ = trainer.transform_bach_as_input(test[k], model)\n",
    "test_lstm = test_lstm.view(-1, len(test_lstm))\n",
    "loss_rew(yvt, model(test_lstm)[1].data.numpy())\n",
    "#get_loss_from(test_lstm, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "#importlib.reload(LSTMmodel)\n",
    "importlib.reload(env_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeding actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "treegramm_count = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "treegramm_count\n",
    "\n",
    "def delta(dict1, dict2):\n",
    "    #print(np.sum(list(dict1.values()), dict1.values())\n",
    "    return np.sum(list(dict1.values())) - np.sum(list(dict2.values()))\n",
    "\n",
    "def betreegrams(val, env, treegramm_count):\n",
    "    results = {}\n",
    "    treegramm_count = defaultdict(lambda: defaultdict(int))\n",
    "    for v in val[:100]:\n",
    "        #print(env.result, v.formula)\n",
    "        env.calc_formula(v.formula)\n",
    "        results[v.formula] = env.result.copy()\n",
    "        if env.result['o'] == env.out: print(v.formula)\n",
    "    #print(results)\n",
    "    for v in val[:100]:\n",
    "        # beegram\n",
    "        for i in range(len(v.formula)-2):\n",
    "            # beegram\n",
    "            #print(i, results[v.formula[:i]], v.formula[:i])\n",
    "            if i > 0 and delta(results[v.formula[:i]], results[v.formula[:i + 1]]) != 0:\n",
    "                \n",
    "                treegramm_count[v.formula[i-1]][v.formula[i]] += 1\n",
    "                treegramm_count[v.formula[i-1:i+1]][v.formula[i+1]] += 1\n",
    "            if i > 0 and delta(results[v.formula[:i]], results[v.formula[:i + 2]]) != 0:\n",
    "                # ?? peace of sheet!! eB1 in 1ABCieB1e we could remove it...\n",
    "                #print('aa', v.formula, v.formula[:i+1], results[v.formula[:i]], results[v.formula[:i+2]],\n",
    "                #      v.formula[i-1], v.formula[i-1:i+2]\n",
    "                #     )\n",
    "                treegramm_count[v.formula[i-1]][v.formula[i]] += 1\n",
    "                treegramm_count[v.formula[i-1:i+1]][v.formula[i+1]] += 1\n",
    "        i = len(v.formula) - 1\n",
    "        if i >= 0 and delta(results[v.formula[:i]], results[v.formula[:i + 1]]) != 0:\n",
    "            treegramm_count[v.formula[i-1]][v.formula[i]] += 1\n",
    "    return treegramm_count, results\n",
    "    \n",
    "            \n",
    "t, r = betreegrams(val, env, treegramm_count)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_grams(val, env, treegramm_count):\n",
    "    results = {}\n",
    "    treegramm_count = defaultdict(lambda: defaultdict(int))\n",
    "    treegramm_list = []\n",
    "    for v in val:\n",
    "        #print(env.result, v.formula)\n",
    "        env.calc_formula(v.formula)\n",
    "        results[v.formula] = env.result.copy()\n",
    "        if env.result['o'] == env.out: print(v.formula)\n",
    "    #print(results)\n",
    "    for v in val:\n",
    "        # beegram\n",
    "        for i in range(len(v.formula)-2):\n",
    "            if i>0 and delta(results[v.formula[:i+1]], results[v.formula[:i+2]]):\n",
    "                #print(v.formula)\n",
    "                #treegramm_count[v.formula[i:i+1]][v.formula[i+1:i+2]] += 1\n",
    "                treegramm_count[v.formula[i-1:i+1]][v.formula[i+1:i+2]] += 1\n",
    "                #treegramm_list.append([list(v.formula[i-1:i+1]), v.formula[i+1:i+2]])\n",
    "                treegramm_list.append([list(v.formula[i-1:i]), v.formula[i:i+1]])\n",
    "                treegramm_list.append([list(v.formula[i:i+1]), v.formula[i+1:i+2]])\n",
    "            # beegram\n",
    "            \n",
    "        #i = len(v.formula) - 1\n",
    "        #if i >= 0 and delta(results[v.formula[:i]], results[v.formula[:i + 1]]) != 0:\n",
    "            #treegramm_count[v.formula[i-1]][v.formula[i]] += 1\n",
    "    return treegramm_count, treegramm_list, results\n",
    "\n",
    "t, tl, r = count_grams(val, env, treegramm_count)   \n",
    "#tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_SIZE = 1\n",
    "EMBEDDING_DIM = 10\n",
    "trigrams = tl#[([test_sentence[i], test_sentence[i + 1]], test_sentence[i + 2])\n",
    "           # for i in range(len(test_sentence) - 2)]\n",
    "# print the first 3, just so you can see what they look like\n",
    "print(trigrams[:3])\n",
    "\n",
    "vocab = set(env.action_space)\n",
    "word_to_ix = {word: i for i, word in enumerate(env.action_space)}\n",
    "\n",
    "\n",
    "class NGramLanguageModeler(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(NGramLanguageModeler, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).view((1, -1))\n",
    "        out = F.relu(self.linear1(embeds))\n",
    "        out = self.linear2(out)\n",
    "        log_probs = F.log_softmax(out, dim=1)\n",
    "        return log_probs\n",
    "\n",
    "\n",
    "losses = []\n",
    "loss_function = nn.NLLLoss()\n",
    "model = NGramLanguageModeler(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    for context, target in trigrams:\n",
    "\n",
    "        # Step 1. Prepare the inputs to be passed to the model (i.e, turn the words\n",
    "        # into integer indices and wrap them in tensors)\n",
    "        context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
    "\n",
    "        # Step 2. Recall that torch *accumulates* gradients. Before passing in a\n",
    "        # new instance, you need to zero out the gradients from the old\n",
    "        # instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 3. Run the forward pass, getting log probabilities over next\n",
    "        # words\n",
    "        log_probs = model(context_idxs)\n",
    "\n",
    "        # Step 4. Compute your loss function. (Again, Torch wants the target\n",
    "        # word wrapped in a tensor)\n",
    "        loss = loss_function(log_probs, torch.tensor([word_to_ix[target]], dtype=torch.long))\n",
    "\n",
    "        # Step 5. Do the backward pass and update the gradient\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Get the Python number from a 1-element Tensor by calling tensor.item()\n",
    "        total_loss += loss.item()\n",
    "    losses.append(total_loss)\n",
    "print(losses)  # The loss decreased every iteration over the training data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = np.vstack([model.embeddings(torch.tensor([i])).data.numpy() for i in range(8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "#dataframe = np.concatenate([samples, test], axis=0)#[train, test, samples], axis=0)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_feature_reduced = pca.fit(dataframe).transform(dataframe)\n",
    "# map word vectors onto 2d plane with PCA. Use good old sklearn api (fit, transform)\n",
    "# after that, normalize vectors to make sure they have zero mean and unit variance\n",
    "#word_vectors_pca = # YOUR CODE\n",
    "\n",
    "# and maybe MORE OF YOUR CODE here :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=X_feature_reduced[:,0], y=X_feature_reduced[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bokeh.models as bm, bokeh.plotting as pl\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()\n",
    "\n",
    "def draw_vectors(x, y, radius=10, alpha=0.25, color='blue',\n",
    "                 width=600, height=400, show=True, **kwargs):\n",
    "    \"\"\" draws an interactive plot for data points with auxilirary info on hover \"\"\"\n",
    "    if isinstance(color, str): color = [color] * len(x)\n",
    "    data_source = bm.ColumnDataSource({ 'x' : x, 'y' : y, 'color': color, **kwargs })\n",
    "\n",
    "    fig = pl.figure(active_scroll='wheel_zoom', width=width, height=height)\n",
    "    fig.scatter('x', 'y', size=radius, color='color', alpha=alpha, source=data_source)\n",
    "\n",
    "    fig.add_tools(bm.HoverTool(tooltips=[(key, \"@\" + key) for key in kwargs.keys()]))\n",
    "    if show: pl.show(fig)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_vectors(X_feature_reduced[:, 0], X_feature_reduced[:, 1], token=list(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class def_zer():\n",
    "    def __init__(self):\n",
    "        return np.zeros([8])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "j= defaultdict(int)\n",
    "prj = np.zeros([8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clval = t.clean_unpredict_node(val)\n",
    "sm.train(clval)\n",
    "for f in clval:\n",
    "    last = -1\n",
    "    if f.formula and f.formula[-1:]=='e' and len(f.history_data['next_node_ind']) > last:\n",
    "        print(f.times_visited, f.formula, f.history_data['next_node_ind'][last])                                       \n",
    "        j[f.history_data['next_node_ind'][last]] += 1\n",
    "        x = model.get_observation(f.formula, env)\n",
    "        prj += model.predict(x)[0].reshape([8])\n",
    "        \n",
    "\n",
    "#[(f.formula, f.history_data['next_node_ind'][0], j[f.history_data['next_node_ind'][0]] += 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[f.formula for f in val]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class StModel:\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        self.stat = np.random.rand(8, 8)\n",
    "        self.vstat = np.random.rand(8)\n",
    "        \n",
    "    def train(self, val):\n",
    "        self.stat = np.zeros([8, 8])\n",
    "        self.predvst = defaultdict(list)\n",
    "        self.vstat = np.zeros([8])\n",
    "        for node in val:\n",
    "            if node.formula:\n",
    "                v = self.env.action_space.index(node.formula[0])\n",
    "                nv = node.history_data['next_node_ind'][-1]\n",
    "                nr = node.history_data['next_node_val'][-1]\n",
    "                self.stat[v][nv] += 1\n",
    "                self.predvst[v].append(nr)\n",
    "        self.stat /= np.sum(self.stat, axis=0) + 0.0001\n",
    "        for i, k in enumerate(self.predvst):\n",
    "            self.vstat[i] = sum(self.predvst[k]) / len(self.predvst[k])\n",
    "         \n",
    "            \n",
    "    def predict(self, formula):\n",
    "        v = self.env.action_space.index(formula[-1])\n",
    "        return self.stat[:, v], self.vstat[v]\n",
    "    \n",
    "    def get_observation(self, formula, env, time=0):\n",
    "        return formula\n",
    "            \n",
    "sm = StModel(env)\n",
    "#sm.train(val)\n",
    "sm.predict('Ai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.train(train[k][0])\n",
    "sm.predict('Ai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss_from(test, model):\n",
    "    ans = np.zeros_like(yvt)\n",
    "    for i, f in enumerate(test):\n",
    "    #print('===', f.formula)    \n",
    "        if f.formula:\n",
    "            ans[i] = model.predict(f.formula)[1]\n",
    "        else:\n",
    "            ans[i] = 1\n",
    "    return loss_rew(yvt, ans)\n",
    "\n",
    "get_loss_from(test[k][0], sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_rew(yvt, ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = mctsTrainer(env, mcts, batch_size=20)\n",
    "\n",
    "def get_sorted_batch(val, batch_size=20):\n",
    "    sort_val = sorted(val, key=lambda x: len(x.formula))\n",
    "    i = np.random.randint(len(val) - batch_size)\n",
    "    yield sort_val[i:i + batch_size]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sbach = list(get_sorted_batch(val))\n",
    "#print(sbach[0])\n",
    "#for i in sbach[0]: \n",
    "#    print(i.formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    batch = list(get_sorted_batch(val))\n",
    "    \n",
    "    torch.cat([model.get_observation(n.formula, env) for n in batch]).view(t.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_SIZE = 1\n",
    "EMBEDDING_DIM = 10\n",
    "trigrams = [([test_sentence[i], test_sentence[i + 1]], test_sentence[i + 2])\n",
    "            for i in range(len(test_sentence) - 2)]\n",
    "# print the first 3, just so you can see what they look like\n",
    "print(trigrams[:3])\n",
    "\n",
    "vocab = set(env.action_space)\n",
    "word_to_ix = {word: i for i, word in enumerate(env.action_space)}\n",
    "\n",
    "\n",
    "class NGramLanguageModeler(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(NGramLanguageModeler, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).view((1, -1))\n",
    "        out = F.relu(self.linear1(embeds))\n",
    "        out = self.linear2(out)\n",
    "        log_probs = F.log_softmax(out, dim=1)\n",
    "        return log_probs\n",
    "\n",
    "\n",
    "losses = []\n",
    "loss_function = nn.NLLLoss()\n",
    "model = NGramLanguageModeler(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    for context, target in trigrams:\n",
    "\n",
    "        # Step 1. Prepare the inputs to be passed to the model (i.e, turn the words\n",
    "        # into integer indices and wrap them in tensors)\n",
    "        context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
    "\n",
    "        # Step 2. Recall that torch *accumulates* gradients. Before passing in a\n",
    "        # new instance, you need to zero out the gradients from the old\n",
    "        # instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 3. Run the forward pass, getting log probabilities over next\n",
    "        # words\n",
    "        log_probs = model(context_idxs)\n",
    "\n",
    "        # Step 4. Compute your loss function. (Again, Torch wants the target\n",
    "        # word wrapped in a tensor)\n",
    "        loss = loss_function(log_probs, torch.tensor([word_to_ix[target]], dtype=torch.long))\n",
    "\n",
    "        # Step 5. Do the backward pass and update the gradient\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Get the Python number from a 1-element Tensor by calling tensor.item()\n",
    "        total_loss += loss.item()\n",
    "    losses.append(total_loss)\n",
    "print(losses)  # The loss decreased every iteration over the training data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_data(val):\n",
    "    print(val.formula, val.fin_prob, val.ucb_score())\n",
    "\n",
    "shuffle(val)\n",
    "for i in range(30):\n",
    "    val_data(val[i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcts.Nodes['i1iBo'].times_visited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.transform_bach_as_input(t.get_batch(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = {'1': 1, 'i': 0, 'o': 0, 'A': 0, 'B': 0, 'C': 0}\n",
    "keys=list(values) + ['s', 'e']\n",
    "\n",
    "dd = {'formula':[], 'val_sum':[]}\n",
    "for i in replay_buffer.replay:\n",
    "    dd['formula'].append(i[2])\n",
    "    dd['val_sum'].append(i[3].value_sum)\n",
    "    \n",
    "    for j, k in enumerate(keys):\n",
    "        #print('j', j, i[4])\n",
    "        #print(i, i[4][j])\n",
    "        dd[k] = i[4][j]\n",
    "\n",
    "df = pd.DataFrame(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['formula']=='']#['ucb'].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['formula']=='ie']#['ucb'].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer.get_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "F.softmax(Tensor([0,0,0])).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FHT8MKGkKgMZ"
   },
   "outputs": [],
   "source": [
    "test_env.reset()\n",
    "Vocab, Vocab[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vF4aIxxZKgMd"
   },
   "outputs": [],
   "source": [
    "j.select_best_leaf().action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FOQXFnS1KgMi"
   },
   "outputs": [],
   "source": [
    "j.select_best_leaf().rollout(env, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JIrncnZsKgMm"
   },
   "outputs": [],
   "source": [
    "test_env.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e-cTCUZ1KgMs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NidVAYKCKgMw"
   },
   "outputs": [],
   "source": [
    "test_env.step(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JMg5FKlQKgM4"
   },
   "outputs": [],
   "source": [
    "test_env.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bkCYSESeKgM_"
   },
   "outputs": [],
   "source": [
    "test_env.step(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aI3S4cplKgNJ"
   },
   "outputs": [],
   "source": [
    "test_env.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X0cm_RpRKgNN"
   },
   "outputs": [],
   "source": [
    "test_env.step(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TeL1SNw8KgNQ"
   },
   "source": [
    "# Imetation learning \n",
    "### if we already know answer we should show it to mcts tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M3OmftFqKgNS",
    "outputId": "ce5b2f36-6702-4124-b61e-3ac00cdc1b79"
   },
   "outputs": [],
   "source": [
    "#text = \"input_eq_A A[2]_eq_out\"\n",
    "def text_to_actions(text, vocab=Vocab):\n",
    "    action_seq = []\n",
    "    i = 0\n",
    "    operator = ''\n",
    "    while i < len(text):\n",
    "        if text[i] in Vocab:\n",
    "            action_seq.append(Vocab.index(text[i]))\n",
    "        else:\n",
    "            operator += text[i]\n",
    "            #print('ss', text[i], operator)\n",
    "            if operator == 'input':\n",
    "                operator = ''\n",
    "                \n",
    "            if operator in Vocab:\n",
    "                action_seq.append(Vocab.index(operator))\n",
    "                operator = ''\n",
    "\n",
    "\n",
    "        i += 1\n",
    "    return action_seq\n",
    "\n",
    "for i in text_to_actions(text):\n",
    "    print(Vocab[i])\n",
    "text_to_actions(text)\n",
    "        #print(Vocab.index(i))\n",
    "        #print(env.step(1))\n",
    "        #print(env.step(Vocab.index(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dVYXJY8CKgNX"
   },
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SyISzsg9KgNa"
   },
   "outputs": [],
   "source": [
    "#text = \"input_sum_A\" \n",
    "for i in text_to_actions(text):\n",
    "    print(i)\n",
    "    print(Vocab[i])\n",
    "    print(env.step(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fq8wx-GIKgNe",
    "outputId": "c2bc22a2-11d0-47fb-ae78-de64f7916297"
   },
   "outputs": [],
   "source": [
    "text = \"input_eq_A A[2]_const_AA AA_eq_out\" \n",
    "c = CalcNode(text)\n",
    "c.calc(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8HvILK6NKgNi",
    "outputId": "b06ec81a-9728-4fb8-e463-764bb2c402d8"
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "#import mcts\n",
    "importlib.reload(mcts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uGE-MtmQKgNm"
   },
   "outputs": [],
   "source": [
    "root_observation = env.reset()\n",
    "root_snapshot = env.get_snapshot()\n",
    "root = mcts.Root(root_snapshot,root_observation)\n",
    "\n",
    "#plan_mcts(root, env, n_iters=10000, t_max=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dcktRK9PKgNr",
    "outputId": "8a97b6ff-9d2b-4f4c-f71f-07ca8ba61cb3"
   },
   "outputs": [],
   "source": [
    "root.is_leaf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dobGrIBhKgNw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z4tbTs7QKgN1"
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    is_done = env.step(env.action_space.sample())[2]\n",
    "    if is_done: \n",
    "        print(\"Whoops! We died!\")\n",
    "        break\n",
    "        \n",
    "print(\"final state:\")\n",
    "plt.imshow(env.render('rgb_array'))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YCfndGRvKgN7"
   },
   "outputs": [],
   "source": [
    "def teach_mcts(root, env, action_seq):\n",
    "    \"\"\"\n",
    "    builds tree with monte-carlo tree search for n_iters iterations\n",
    "    :param root: tree node to plan from\n",
    "    :param n_iters: how many select-expand-simulate-propagete loops to make\n",
    "    \"\"\"\n",
    "    #node = root\n",
    "    #node = mcts.Node(root, action_seq[0], env)\n",
    "    #root.children.add(node)\n",
    "    for action in action_seq:\n",
    "        #print(action)\n",
    "        #print(node.is_done)\n",
    "        \n",
    "        #next_node = mcts.Node(next_node, action, env)\n",
    "        #node.children.add(mcts.Node(node, action, env))\n",
    "        #node = next_node\n",
    "        \n",
    "        #print(node.is_done)\n",
    "        node = root.select_best_leaf()\n",
    "        \n",
    "        #print(Vocab[node.action])\n",
    "        \n",
    "        if node.is_done:\n",
    "            if node.immediate_reward > 0:\n",
    "                print(\"get_reward mcts plan!\", node.immediate_reward)  \n",
    "            \n",
    "            node.propagate(0)\n",
    "            #env.reset()\n",
    "       \n",
    "        else: #node is not terminal\n",
    "            \n",
    "            #print(_)\n",
    "            #env.reset()\n",
    "            #self.env.close()\n",
    "            #self.render()\n",
    "            node.expand(env)\n",
    "            #print(Vocab[node.action])\n",
    "            for i in node.children:\n",
    "                print('dd', )#Vocab[node.action], node.parent.action)\n",
    "            ## value = node.rollout(env, 10)\n",
    "            #if value >0:\n",
    "            #    print('plan after rolout', value, node.action)\n",
    "            ##node.propagate(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9wpJsyD4KgN_",
    "outputId": "b072c7e6-6701-47ce-e7d5-88fb46a0de64"
   },
   "outputs": [],
   "source": [
    "teach_mcts(root, env, text_to_actions(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rDYbBZD1KgOD"
   },
   "outputs": [],
   "source": [
    "p = mcts.Node(root, 2, env)\n",
    "#p.is_leaf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6LmjGfWZKgOI"
   },
   "outputs": [],
   "source": [
    "mcts.plan_mcts(root,env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nHYw3ZLhKgOa",
    "outputId": "f7f5c650-8cdc-4f57-ceff-5b7b0f12f0eb"
   },
   "outputs": [],
   "source": [
    "for i in root.children:\n",
    "    print(Vocab[i.action], i.value_sum, len(i.children))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y4urPh38KgOi",
    "outputId": "4ecbf4f9-e351-4d1e-9710-bbc1c3e504fc"
   },
   "outputs": [],
   "source": [
    "j = root\n",
    "while j.children:\n",
    "    j = j.children.pop()\n",
    "    print(j.action, len(j.children))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cPmBVHd9KgOm"
   },
   "source": [
    "# Try learn something again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<mcts.Node object at 0x7ff08f0e0400>, <mcts.Node object at 0x7ff08f206e10>, <mcts.Node object at 0x7ff08f028a20>, <mcts.Node object at 0x7ff08f553828>, <mcts.Node object at 0x7ff08f297c18>]\n"
     ]
    }
   ],
   "source": [
    "batch = t.get_batch(val, batch_size=5)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch[0].history_data, batch[0].formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_nodes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ff158e64bb5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mplt_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-ff158e64bb5e>\u001b[0m in \u001b[0;36mplt_history\u001b[0;34m(node_formula)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplt_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_formula\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mNODE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_nodes\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformula\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnode_formula\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_nodes' is not defined"
     ]
    }
   ],
   "source": [
    "values = {'1': 1, 'i': 0, 'o': 0, 'A': 0, 'B': 0, 'C': 0}\n",
    "actions = list(values) + ['s', 'e']\n",
    "\n",
    "def plt_history(node_formula=''):\n",
    "    NODE = [i for i in all_nodes if i.formula == node_formula][0]\n",
    "    for k in range(8):\n",
    "        dt = []\n",
    "        for i, t in enumerate(NODE.history_data['time']):\n",
    "\n",
    "            if NODE.history_data['next_node_ind'][i] == k:\n",
    "                dt.append(NODE.history_data['next_node_val'][i])\n",
    "        print(len(dt), end=',')\n",
    "        plt.plot(range(len(dt)), dt, label=actions[k])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "plt_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_nodes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-bc8e7df480af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mplt_historyP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-bc8e7df480af>\u001b[0m in \u001b[0;36mplt_historyP\u001b[0;34m(node_formula)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplt_historyP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_formula\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mNODE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_nodes\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformula\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnode_formula\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_nodes' is not defined"
     ]
    }
   ],
   "source": [
    "fprob = np.zeros(8)\n",
    "def plt_historyP(node_formula=''):\n",
    "    NODE = [i for i in all_nodes if i.formula == node_formula][0]\n",
    "    for k in range(8):\n",
    "        dt = [0]\n",
    "        tt = [0]\n",
    "        for i, t in enumerate(NODE.history_data['time']):\n",
    "\n",
    "            if NODE.history_data['next_node_ind'][i] == k:\n",
    "                dt.append(dt[-1]+1)\n",
    "                tt.append(t)\n",
    "        print(len(dt), end=',')\n",
    "        fprob[k] = dt[-1]\n",
    "        plt.plot(tt, dt, label=actions[k])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "plt_historyP('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_nodes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d8897b088317>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformula\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfin_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_nodes' is not defined"
     ]
    }
   ],
   "source": [
    "for i in all_nodes[:10]:\n",
    "    print(i.formula, i.fin_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denis/anaconda3/envs/tourch_gym/lib/python3.7/site-packages/ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([nan, nan, nan, nan, nan, nan, nan, nan]), nan)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fprob /= np.sum(fprob)\n",
    "fprob, np.sum(fprob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_nodes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-6feacf5c2d83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt_historyP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-bc8e7df480af>\u001b[0m in \u001b[0;36mplt_historyP\u001b[0;34m(node_formula)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplt_historyP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_formula\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mNODE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_nodes\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformula\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnode_formula\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_nodes' is not defined"
     ]
    }
   ],
   "source": [
    "plt_historyP('i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_nodes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-b58a007fa6e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt_historyP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ie'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-bc8e7df480af>\u001b[0m in \u001b[0;36mplt_historyP\u001b[0;34m(node_formula)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplt_historyP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_formula\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mNODE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_nodes\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformula\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnode_formula\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_nodes' is not defined"
     ]
    }
   ],
   "source": [
    "plt_historyP('ie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play adverserial game\n",
    "try to solve problem with big value for loosing formulas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    " def sampling(self):\n",
    "        i, r = 0, 0\n",
    "        while (self.args.iters > i and not r) or 2 * self.args.iters > i:\n",
    "            node = self.select_best_leaf()\n",
    "            #if node.parent is not None: print(node.formula, node.immediate_reward)\n",
    "            r = node.immediate_reward\n",
    "            #if r: print('R', node.formula)\n",
    "            self.Nodes[node.formula] = node\n",
    "            if r:\n",
    "                self.propagate(node)\n",
    "            else:\n",
    "\n",
    "                pred_P, pred_R = self.model.predict(self.model.get_observation(node.formula, self.env, self.iter_timer)) # if simple model self.env.observation\n",
    "                self.expand(node, pred_P)\n",
    "\n",
    "            r = max(0, r)\n",
    "            i += 1\n",
    "\n",
    "        self.compute_p_real()\n",
    "        return  self.Nodes.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 =Model()# LSTMTagger()#Model()\n",
    "model2 =Model()\n",
    "env1 = Env(1,1)\n",
    "env2 = Env(1,1)\n",
    "\n",
    "args = dotdict({'cpuct':0.5, 'iters':1000})\n",
    "mcts1 = MCTS(env1, model, args)\n",
    "mcts2 = MCTS(env2, model, args)\n",
    "\n",
    "\n",
    "def play_game(mcts1, mcts2):\n",
    "    game_end = 0\n",
    "    score = [0, 0]\n",
    "    while not game_end:\n",
    "        node1 = mcts1.select_best_leaf()\n",
    "        r1 = node1.immediate_reward\n",
    "\n",
    "        node2 = mcts2.select_best_leaf()\n",
    "        r2 = node2.immediate_reward\n",
    "        #print(len(mcts1.Nodes) == len(mcts2.Nodes))\n",
    "        \n",
    "\n",
    "        \n",
    "        if r1 < 0 or r2 < 0:\n",
    "            mcts1.propagate(node1)\n",
    "            mcts2.propagate(node2)\n",
    "        elif r1 > 0 and r2 > 0:\n",
    "            mcts1.propagate(node1)\n",
    "            mcts2.propagate(node2)\n",
    "        elif r1 > 0:\n",
    "            node2.immediate_reward = -1\n",
    "            mcts1.propagate(node1)\n",
    "            mcts2.propagate(node2)\n",
    "        elif r2 > 0:\n",
    "            node1.immediate_reward = -1\n",
    "            mcts1.propagate(node1)\n",
    "            mcts2.propagate(node2)\n",
    "        if r1 != 0 or r2 != 0:\n",
    "            score[0] += node1.immediate_reward\n",
    "            score[1] += node2.immediate_reward\n",
    "            game_end = 1\n",
    "        \n",
    "        #if r1>0 or r2>0:\n",
    "        #    print(node1.formula, game_end)\n",
    "        #    print(node2.formula, game_end)\n",
    "\n",
    "        mcts1.Nodes[node1.formula] = node1\n",
    "        mcts2.Nodes[node2.formula] = node2\n",
    "\n",
    "        pred_P, pred_R = mcts1.model.predict(mcts1.model.get_observation(node1.formula, mcts1.env, mcts1.iter_timer)) # if simple model self.env.observation\n",
    "        mcts1.expand(node1, pred_P)\n",
    "\n",
    "        pred_P, pred_R = mcts2.model.predict(mcts2.model.get_observation(node2.formula, mcts2.env, mcts2.iter_timer)) # if simple model self.env.observation\n",
    "        mcts2.expand(node2, pred_P)\n",
    "    \n",
    "    return score, r1, r2\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "#val = list(mcts2.sampling())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 "
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-5, -14]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_nodes = []\n",
    "v = [0,0]\n",
    "for i in range(1):\n",
    "    mcts1 = MCTS(env1, model1, args)\n",
    "    mcts2 = MCTS(env2, model2, args)\n",
    "    score = [0, 0]\n",
    "    for j in range(20):\n",
    "        print(j, end=' ')\n",
    "\n",
    "        res = play_game(mcts1, mcts2)[0]\n",
    "        #print('s')\n",
    "        score[0] += res[0]\n",
    "        score[1] += res[1]\n",
    "    #if score[0] > score[1]:\n",
    "    all_nodes += list(mcts1.Nodes.values())\n",
    "    #else:\n",
    "    all_nodes += list(mcts2.Nodes.values())\n",
    "    v[0] += (score[0]-score[1])\n",
    "    v[1] += score[0]\n",
    "\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-5, -14]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#val1 = list(all_nodes.values())\n",
    "#val2 = list(mcts2.Nodes.values())\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(all_nodes))\n",
    "for i in all_nodes:\n",
    "    if i.parent:\n",
    "        if np.max(i.parent.history_data['next_node_val']) > 0:\n",
    "            print(i.parent.history_data['next_node_val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1 learn values&probs by NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in all_nodes:\n",
    "    act_count = np.zeros(8)\n",
    "    i.fin_prob = act_count + 1/8\n",
    "    #print(i.formula, len(i.history_data['next_node_ind']))\n",
    "    for act in i.history_data['next_node_ind']:\n",
    "        act_count[act] += 1\n",
    "    if len(i.history_data['next_node_ind']):\n",
    "        i.fin_prob = act_count / len(i.history_data['next_node_ind'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "val = t.clean_unpredict_node(all_nodes) # from deep down\n",
    "print(len(all_nodes), len(val))\n",
    "train_cur, test_cur = val, val#train_test_split(val, shuffle=True)\n",
    "#train[k] = train_cur\n",
    "#test[k] = test_cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batching most recent nodes\n",
    "def get_node_probs(all_nodes):\n",
    "    n_node_entrances = 0\n",
    "    prob_of_node = np.zeros(len(all_nodes))\n",
    "    for i in all_nodes:\n",
    "        n_node_entrances += len(i.history_data['next_node_ind'])\n",
    "    for i, node in enumerate(all_nodes):\n",
    "        prob_of_node[i] = len(node.history_data['next_node_ind']) / n_node_entrances\n",
    "        if node.formula == 'B1ieCe1BC1i':\n",
    "            print(node.formula, node.fin_prob, len(node.history_data['next_node_ind']), prob_of_node[i])\n",
    "    return prob_of_node\n",
    "prob_of_node = get_node_probs(val)\n",
    "\n",
    "def get_batch(nodes_buc, batch_size=20):\n",
    "    indexes = range(len(nodes_buc))\n",
    "    return np.random.choice(indexes, batch_size, replace=True, p=prob_of_node)\n",
    "#for i in np.random.choice(all_nodes, 20, replace=True, p=prob_of_node):\n",
    "#    print(i.formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_linear_out(samples):\n",
    "    X, yv, yp, cresult = t.transform_bach_as_input(samples, model)\n",
    "    return X, yv, yp\n",
    "\n",
    "k = '1o1'\n",
    "X, yv, yp = get_linear_out(train_cur)\n",
    "Xt, yvt, ypt = get_linear_out(test_cur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 42]), (64, 1), (64, 8), 0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, yv.shape, yp.shape, np.max(yv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff08cfb3b38>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def loss_rew(tr, pr):\n",
    "    return np.sum((tr - pr)**2) / len(tr)\n",
    "\n",
    "plt.plot(yp[:200,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.462219760730309e-15, 8.462219760730309e-15, 0.0302734375)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression().fit(X, yv)\n",
    "loss_rew(yvt, reg.predict(Xt)), loss_rew(yv, reg.predict(X)), loss_rew(yvt, np.mean(yv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric on Prob!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-7a1cf09d5103>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#nmodel = Model()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlossb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlossb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_model' is not defined"
     ]
    }
   ],
   "source": [
    "#nmodel = Model()\n",
    "lossb = train_model(X, yv, yp, nmodel, net_iters=500)\n",
    "plt.plot(lossb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nmodel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-e360a4f6e0a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss_rew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myvt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_rew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'nmodel' is not defined"
     ]
    }
   ],
   "source": [
    "loss_rew(yvt, nmodel.predict(Xt)[1]), loss_rew(yv, nmodel.predict(X)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.030401125486437634, 0.030401125486437634)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_rew(yvt, model1.predict(Xt)[1]), loss_rew(yv, model1.predict(X)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nmodel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-6657a74ac642>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmcts1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMCTS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mmcts2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMCTS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nmodel' is not defined"
     ]
    }
   ],
   "source": [
    "fin_score = 0\n",
    "points = 0\n",
    "dopp = 0\n",
    "games = 30\n",
    "for i in range(games):\n",
    "    mcts1 = MCTS(env1, nmodel, args)\n",
    "    mcts2 = MCTS(env2, model1, args)\n",
    "    score = [0, 0]\n",
    "    for j in range(100):\n",
    "        \n",
    "\n",
    "        res, r1, r2 = play_game(mcts1, mcts2)\n",
    "        score[0] += res[0]\n",
    "        score[1] += res[1]\n",
    "        dopp += r1 - r2\n",
    "    #all_nodes ={**mcts1.Nodes, **mcts2.Nodes}\n",
    "    #print(score)\n",
    "    points += score[0] - score[1]\n",
    "    fin_score += score[0] > score[1]\n",
    "    games -= score[0] == score[1]\n",
    "    \n",
    "print('old vs new', fin_score, games - fin_score, 'points=', points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model1 = nmodel\n",
    "#model2 = nmodel\n",
    "nmodel = Model()\n",
    "#dopp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor, nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Modelx(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.cnv1 = nn.Conv1d(1,6,8)\n",
    "        self.fc1 = nn.Linear(18, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.action_prob_out = nn.Linear(64, 8)\n",
    "        #self.val0 = nn.Linear(40, 80)\n",
    "        self.val = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        #x = x.view(-1,17)\n",
    "        #x = self.cnv1(x.view(1, 1,-1))\n",
    "        # print(x.shape)\n",
    "        #x = torch.flatten(x, start_dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        act_prob = F.softmax(self.action_prob_out(x), dim=-1)\n",
    "        #val = F.tanh(self.val(x))\n",
    "        val = self.val(x)\n",
    "        #val_sum = self.val_sum_out(val)\n",
    "\n",
    "        return act_prob, val\n",
    "\n",
    "    def predict(self, x):\n",
    "        self.eval()\n",
    "        #x = Variable(Tensor(x))\n",
    "        act_prob, val = self.forward(x)\n",
    "        return act_prob.data.numpy(), val.data.numpy()\n",
    "\n",
    "\n",
    "def get_batchX(nodes_buc, batch_size=20):\n",
    "    \"\"\"remove all nodes that have not history\"\"\"\n",
    "    n = len(nodes_buc)\n",
    "    index = [\n",
    "        np.random.randint(0, n - 1)\n",
    "        for _ in range(batch_size)\n",
    "    ]\n",
    "    #print(len(self.replay), index, [self.replay[i] for i in index]   )\n",
    "    return index#[nodes_buc[i] for i in index]\n",
    "\n",
    "\n",
    "def train_model(Xa,yr,yp, model, batch_size=30, net_iters=200):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.1)#, momentum=0.03, weight_decay=0.1)\n",
    "    loss_backet = []\n",
    "    #validate_back = []\n",
    "    for i in range(net_iters):\n",
    "        #batch = #self.get_batch(nodes_buc, batch_size=batch_size or self.batch_size)\n",
    "        # print(batch)\n",
    "        ind = get_batch(Xa)\n",
    "\n",
    "        X, real_reward, real_prob = Xa[ind], yr[ind], yp[ind]#self.transform_bach_as_input(batch, model)\n",
    "\n",
    "\n",
    "        #print(i, real_prob.shape)\n",
    "        model.train()\n",
    "        #for x, rr, rp in zip(X, real_reward, real_prob):\n",
    "            #print(xx, rrr,rpp)\n",
    "        optimizer.zero_grad()\n",
    "        #print(X)\n",
    "        p_pred, v_pred = model(X)\n",
    "        # print('pr  ', probability, 'pp  ', p_pred)\n",
    "        val_loss = torch.mean((Variable(Tensor(real_reward)) - v_pred) ** 2)  # , Variable(Tensor([10]))\n",
    "        #loss = val_loss - torch.mean(Variable(Tensor(real_prob)) * torch.log(p_pred))\n",
    "        loss = - torch.mean(Variable(Tensor(real_prob)) * torch.log(p_pred))\n",
    "        #print(loss, rpp, p_pred)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_backet.append(loss.data.numpy())\n",
    "        \n",
    "    return loss_backet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i [0.5 0.  0.  0.  0.  0.  0.  0.5] 4 0.015384615384615385\n",
      "i [0.33333333 0.         0.         0.         0.         0.16666667\n",
      " 0.         0.5       ] 6 0.023076923076923078\n"
     ]
    }
   ],
   "source": [
    "for i, node in enumerate(val):\n",
    "    if node.formula == 'i':\n",
    "        print(node.formula, node.fin_prob, len(node.history_data['next_node_ind']), prob_of_node[i])#, i.ucb_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, node in enumerate(val):\n",
    "    if node.formula == 'i':\n",
    "        print(node.formula, node.fin_prob, len(node.history_data['next_node_ind']), prob_of_node[i])#, i.ucb_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = nmodel.get_observation('ie', env1, 500)\n",
    "nmodel.predict(X0), model1.predict(X0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in get_batch(val):\n",
    "    print(val[ind].formula, val[ind].fin_prob, val[ind].immediate_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nodes = list(mcts1.sampling())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in Nodes:\n",
    "    if node.immediate_reward > 0:\n",
    "        print(node.formula, node.immediate_reward)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN from deeplearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.5000, 0.5000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.5000, 0.5000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.5000, 0.5000, 0.0000,  ..., 0.0000, 0.0000, 1.0000],\n",
       "         ...,\n",
       "         [0.5000, 0.5000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.5000, 0.5000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.5000, 0.5000, 0.0000,  ..., 1.0000, 0.0000, 0.0000]]), array([[ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [-1],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [-1],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0]]), array([[0.26530612, 0.10204082, 0.04081633, 0.10204082, 0.10204082,\n",
       "         0.10204082, 0.10204082, 0.18367347],\n",
       "        [0.        , 0.        , 0.25      , 0.        , 0.25      ,\n",
       "         0.        , 0.        , 0.5       ],\n",
       "        [0.        , 0.        , 0.125     , 0.        , 0.625     ,\n",
       "         0.        , 0.        , 0.25      ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         1.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 1.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.5       , 0.5       ],\n",
       "        [0.        , 0.25      , 0.        , 0.        , 0.33333333,\n",
       "         0.        , 0.        , 0.41666667],\n",
       "        [0.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         1.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.5       ,\n",
       "         0.        , 0.        , 0.5       ],\n",
       "        [0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.25      , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.75      ],\n",
       "        [0.5       , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.5       ],\n",
       "        [0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 1.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         1.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 1.        , 0.        ],\n",
       "        [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 1.        ],\n",
       "        [1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.16326531, 0.14285714, 0.04081633, 0.10204082, 0.14285714,\n",
       "         0.16326531, 0.10204082, 0.14285714],\n",
       "        [0.33333333, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.16666667, 0.        , 0.5       ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.33333333,\n",
       "         0.33333333, 0.        , 0.33333333],\n",
       "        [0.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.28571429, 0.        , 0.71428571],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 1.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.57142857, 0.        , 0.42857143],\n",
       "        [1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.5       , 0.        , 0.        , 0.        ,\n",
       "         0.25      , 0.        , 0.25      ],\n",
       "        [0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.16666667, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.83333333],\n",
       "        [0.        , 0.5       , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.5       ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 1.        ],\n",
       "        [0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         1.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         1.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 1.        ],\n",
       "        [0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         1.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ]]), 0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, yv, yp, np.max(yv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AGAIN STAT MODEL AND DEEPLEARNING BOOK bless me!\n",
    "\n",
    "Run first 3 cells from \"Step by step mcts\"\n",
    "Run all sampling 3 cells from \"Play adverserial game\" Run4 cells from \"Step1 learn values&probs by NN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class stat_model():\n",
    "    def __init__(self, X_tr, y_vtr, y_ptr):\n",
    "        self.all_X = defaultdict(int)\n",
    "        self.ypX = defaultdict(lambda: defaultdict(int))\n",
    "        self.yvX = defaultdict(lambda: defaultdict(int))\n",
    "        for x, yv, yp in zip(X_tr, y_vtr, y_ptr):\n",
    "            #yv, yp = map(str, [yv, yp])\n",
    "            #print(yv, yp)\n",
    "            x = tuple(x.data.numpy())\n",
    "            self.all_X[x] += 1\n",
    "            self.ypX[x][tuple(yp)] += 1\n",
    "            self.yvX[x][yv[0]] += 1\n",
    "        \n",
    "    def predict(self, x):\n",
    "        x = str(list(x.data.numpy()))\n",
    "        yv_pred = self.yvX[x][1]/self.all_X[x] # prob of 1\n",
    "        \n",
    "        return yv_pred\n",
    "        \n",
    "        \n",
    "SM = stat_model(X, yv, yp)\n",
    "SM.all_X[X[0]], X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SM.predict(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SM.all_X[X[0]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuple(X[0].data.numpy())#.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SM.all_X[str(list(X[0].data.numpy()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = 0\n",
    "for x, y, yp in zip(X, yv, yp):\n",
    "    err += (y + 1) / 2 * np.log(SM.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "AI_env.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
