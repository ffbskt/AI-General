{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from models import Model, Trainer\n",
    "from env_test import Env\n",
    "from mcts import MCTS\n",
    "\n",
    "class dotdict(dict):\n",
    "    def __getattr__(self, name):\n",
    "        return self[name]\n",
    "\n",
    "model =Model()# LSTMTagger()#Model()\n",
    "env = Env(1,1)\n",
    "\n",
    "args = dotdict({'cpuct':0.5, 'iters':1000})\n",
    "mcts2 = MCTS(env, model, args)\n",
    "#val = list(mcts2.sampling())\n",
    "#print(len(val))\n",
    "#val = [v for v in val if v.parent and v.parent.times_visited > 2]\n",
    "#print(len(val))\n",
    "t = Trainer(env, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor, nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def get_batch(nodes_buc, batch_size=20):\n",
    "    \"\"\"remove all nodes that have not history\"\"\"\n",
    "    n = len(nodes_buc)\n",
    "    index = [\n",
    "        np.random.randint(0, n - 1)\n",
    "        for _ in range(batch_size)\n",
    "    ]\n",
    "    #print(len(self.replay), index, [self.replay[i] for i in index]   )\n",
    "    return index#[nodes_buc[i] for i in index]\n",
    "\n",
    "\n",
    "def train_model(Xa,yr,yp, model, batch_size=10, net_iters=200):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.1)#, momentum=0.03, weight_decay=0.1)\n",
    "    loss_backet = []\n",
    "    for i in range(net_iters):\n",
    "        ind = get_batch(Xa)\n",
    "\n",
    "        X, real_reward, real_prob = Xa[ind], yr[ind], yp[ind]#self.transform_bach_as_input(batch, model)\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        #print(X)\n",
    "        p_pred, v_pred = model(X)\n",
    "        # print('pr  ', probability, 'pp  ', p_pred)\n",
    "        val_loss = torch.mean((Variable(Tensor(real_reward)) - v_pred) ** 2)  # , Variable(Tensor([10]))\n",
    "        loss = val_loss - torch.mean(Variable(Tensor(real_prob)) * torch.log(p_pred))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_backet.append(loss.data.numpy())\n",
    "        \n",
    "    return loss_backet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{} 1\n",
      "{} 1799\n",
      "new env 0\n",
      "{1: [2, 64]} 3417\n",
      "{1: [2, 64]} 3862\n",
      "{1: [2, 64]} 4137\n",
      "{1: [2, 64]} 4359\n",
      "{1: [2, 64]} 4515\n",
      "{1: [2, 64]} 4625\n",
      "{1: [2, 64]} 4787\n",
      "{1: [2, 64]} 4887\n",
      "{1: [2, 64]} 4982\n",
      "{1: [2, 64]} 5061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: [2, 64]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_linear_out(samples):\n",
    "    X, yv, yp, cresult = t.transform_bach_as_input(samples, model)\n",
    "    return X, yv, yp\n",
    "\n",
    "def env_high_dificult(Env, agent, Trainer):\n",
    "    \n",
    "    epoch = iter_lim = 10\n",
    "    stat = {}\n",
    "    ind_dificult = 1\n",
    "    env = Env(1, ind_dificult)\n",
    "    while epoch:\n",
    "        epoch -= 1\n",
    "        print(stat, len(mcts2.Nodes))\n",
    "        if agent.sum_reward > 10:\n",
    "            stat[ind_dificult] = [iter_lim - epoch, agent.sum_reward]\n",
    "            agent.sum_reward = 0\n",
    "            ind_dificult += 1\n",
    "            epoch = iter_lim\n",
    "            env = Env(1, ind_dificult)\n",
    "            agent.env = env\n",
    "            print('new env', agent.sum_reward)\n",
    "        \n",
    "        val = list(agent.sampling())\n",
    "        val = Trainer.clean_unpredict_node(val)\n",
    "        X, yv, yp = get_linear_out(val)\n",
    "        lossb = train_model(X, yv, yp, agent.model, net_iters=500)\n",
    "        #plt.plot(lossb)\n",
    "        #plt.show()\n",
    "        \n",
    "    return stat\n",
    "\n",
    "mcts2 = MCTS(env, model, args)\n",
    "env_high_dificult(Env, mcts2, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneralActionModel(nn.Module):\n",
    "    \"\"\"\n",
    "        predict general action:\n",
    "          ChoseLetter\n",
    "          SeeDif\n",
    "          CreateObj\n",
    "          EditObj\n",
    "          ExpectObj\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, env, task, vocab_size, args, internal_mes_size=32, hidden=64):\n",
    "        super(GeneralActionModel, self).__init__()\n",
    "        self.env = env\n",
    "        mcts = MCTS(env, self, args)\n",
    "        self.task = Variable(Tensor(list(range(vocab_size)) + task))\n",
    "        \n",
    "        self.inp_layer = nn.Linear(self.task.shape[0], hidden)\n",
    "        #self.internal = nn.RNNCell(internal_mes, vocab_size + task_size)\n",
    "        self.internal = nn.Linear(internal_mes_size, self.task.shape[0])\n",
    "        self.act = nn.Linear(hidden, 5)\n",
    "        self.message = nn.Linear(hidden, internal_mes_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mes = self.internal(x)\n",
    "        \n",
    "        x = mes * self.task #/ torch.sqrt(torch.max(1 + torch.sum(mes)))\n",
    "        #print(x, mes * self.task, torch.sqrt(1 + torch.sum(mes)))\n",
    "        x = F.relu(self.inp_layer(x))\n",
    "        act_prob = F.softmax(self.act(x))\n",
    "        out_mes = F.tanh(self.message(x))\n",
    "        return act_prob, out_mes\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "class ChoseLetter(nn.Module):\n",
    "    def __init__(self, env, internal_mes_size=32, hidden=64, ):\n",
    "        super(ChoseLetter, self).__init__()\n",
    "        self.chl_model = Model()\n",
    "        mcts = MCTS(env, self.chl_model, args)\n",
    "        \n",
    "        self.inp_layer = nn.Linear(internal_mes_size, hidden)\n",
    "        \n",
    "        \n",
    "    def get_action(self):\n",
    "        return a, sup_vec, back_vec\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denis/anaconda3/envs/tourch_gym/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0.1845, 0.2545, 0.1178, 0.2528, 0.1904],\n",
       "         [0.1539, 0.3197, 0.1697, 0.1890, 0.1677]], grad_fn=<SoftmaxBackward>),\n",
       " tensor([[-0.0843, -0.3319,  0.0319, -0.1858,  0.3311, -0.2201, -0.0689,  0.0198,\n",
       "          -0.2517, -0.2049,  0.0265,  0.1109, -0.3542,  0.1263, -0.0981,  0.1656,\n",
       "          -0.3662, -0.0779,  0.0835,  0.0142, -0.2712, -0.3484, -0.0005, -0.3935,\n",
       "          -0.3414, -0.1377, -0.4148, -0.1733, -0.0391, -0.2754, -0.0613, -0.0202],\n",
       "         [-0.0980, -0.2806,  0.0192,  0.0239,  0.2604, -0.1483,  0.0228,  0.3852,\n",
       "          -0.2252, -0.0396, -0.1163,  0.1580,  0.1632,  0.0867,  0.2128,  0.0624,\n",
       "          -0.3019, -0.0999, -0.1019, -0.1456, -0.1890, -0.3970,  0.1320, -0.1090,\n",
       "          -0.2721, -0.2288, -0.2160, -0.1942,  0.1088, -0.2711,  0.2129, -0.3104]],\n",
       "        grad_fn=<TanhBackward>))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = dotdict({'cpuct':0.5, 'iters':1000})\n",
    "model = GeneralActionModel(env=HigerEnv(), task=[1,1], vocab_size=8, internal_mes_size=32, args=args)\n",
    "model(torch.randn([2,32]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HigerEnv:\n",
    "    def __init__(self):\n",
    "        models = []\n",
    "        self.actions = range(len(models))\n",
    "    \n",
    "    def do_move(self, a, mes):\n",
    "        return models[a].get_action(mes) # immediate_reward, out_mes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
